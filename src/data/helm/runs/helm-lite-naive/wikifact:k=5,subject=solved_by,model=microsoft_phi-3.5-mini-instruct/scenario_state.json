{
  "adapter_spec": {
    "method": "generation",
    "global_prefix": "",
    "global_suffix": "",
    "instructions": "",
    "input_prefix": "",
    "input_suffix": "",
    "reference_prefix": "A. ",
    "reference_suffix": "\n",
    "chain_of_thought_prefix": "",
    "chain_of_thought_suffix": "\n",
    "output_prefix": " ",
    "output_suffix": "\n",
    "instance_prefix": "\n",
    "substitutions": [],
    "max_train_instances": 5,
    "max_eval_instances": 100,
    "num_outputs": 5,
    "num_train_trials": 1,
    "num_trials": 1,
    "sample_train": true,
    "model_deployment": "huggingface/phi-3.5-mini-instruct",
    "model": "microsoft/phi-3.5-mini-instruct",
    "temperature": 1.0,
    "max_tokens": 8,
    "stop_sequences": [
      "\n"
    ],
    "multi_label": false
  },
  "request_states": [
    {
      "instance": {
        "input": {
          "text": "Plateau's problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Tibor Rad\u00f3"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Tibor Rado"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Jesse Douglas"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id10"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nPlateau's problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Plateau's problem was solved",
            "logprob": -1.2497483792976425,
            "tokens": [
              {
                "text": "Pl",
                "logprob": -0.27106741070747375
              },
              {
                "text": "ate",
                "logprob": 0.0
              },
              {
                "text": "au",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "'",
                "logprob": -0.00014423283573705703
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0006170752458274364
              },
              {
                "text": "was",
                "logprob": -0.8539114594459534
              },
              {
                "text": "solved",
                "logprob": -0.12400796264410019
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15621855942845642,
              "max_token_negative_log_likelihood": 0.8539114594459534,
              "predictive_entropy": 0.08507034280955494,
              "shannon_entropy": 0.30536016812740696
            }
          },
          {
            "text": "Plateau's problem was solved",
            "logprob": -1.2497483792976425,
            "tokens": [
              {
                "text": "Pl",
                "logprob": -0.27106741070747375
              },
              {
                "text": "ate",
                "logprob": 0.0
              },
              {
                "text": "au",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "'",
                "logprob": -0.00014423283573705703
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0006170752458274364
              },
              {
                "text": "was",
                "logprob": -0.8539114594459534
              },
              {
                "text": "solved",
                "logprob": -0.12400796264410019
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15621855942845642,
              "max_token_negative_log_likelihood": 0.8539114594459534,
              "predictive_entropy": 0.08507034280955494,
              "shannon_entropy": 0.30536016812740696
            }
          },
          {
            "text": "Plateau's problem, which",
            "logprob": -1.1779219585732505,
            "tokens": [
              {
                "text": "Pl",
                "logprob": -0.27106741070747375
              },
              {
                "text": "ate",
                "logprob": 0.0
              },
              {
                "text": "au",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "'",
                "logprob": -0.00014423283573705703
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0006170752458274364
              },
              {
                "text": ",",
                "logprob": -0.6039114594459534
              },
              {
                "text": "which",
                "logprob": -0.30218154191970825
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1472402503186494,
              "max_token_negative_log_likelihood": 0.6039114594459534,
              "predictive_entropy": 0.09512266056298913,
              "shannon_entropy": 0.34878285965143574
            }
          },
          {
            "text": "Plateau's problem was solved",
            "logprob": -1.2497483792976425,
            "tokens": [
              {
                "text": "Pl",
                "logprob": -0.27106741070747375
              },
              {
                "text": "ate",
                "logprob": 0.0
              },
              {
                "text": "au",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "'",
                "logprob": -0.00014423283573705703
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0006170752458274364
              },
              {
                "text": "was",
                "logprob": -0.8539114594459534
              },
              {
                "text": "solved",
                "logprob": -0.12400796264410019
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15621855942845642,
              "max_token_negative_log_likelihood": 0.8539114594459534,
              "predictive_entropy": 0.08507034280955494,
              "shannon_entropy": 0.30536016812740696
            }
          },
          {
            "text": "Plateau's problem in the",
            "logprob": -4.766253598339944,
            "tokens": [
              {
                "text": "Pl",
                "logprob": -0.27106741070747375
              },
              {
                "text": "ate",
                "logprob": 0.0
              },
              {
                "text": "au",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "'",
                "logprob": -0.00014423283573705703
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0006170752458274364
              },
              {
                "text": "in",
                "logprob": -4.260161399841309
              },
              {
                "text": "the",
                "logprob": -0.23426324129104614
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5957815860801965,
              "max_token_negative_log_likelihood": 4.260160446166992,
              "predictive_entropy": 0.05661993665307463,
              "shannon_entropy": 0.3284747823160781
            }
          }
        ],
        "cached": false,
        "request_time": 1.0337779521942139,
        "request_datetime": 1755801555
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Eberlein\u2013\u0160mulian theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Vitold Shmulyan"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Vitold Lvovich Shmulyan"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id11"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nEberlein\u2013\u0160mulian theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Eberlein\u2013\u0160mulian",
            "logprob": -0.006678816168459889,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005691750440746546
              },
              {
                "text": "E",
                "logprob": -0.00026901919045485556
              },
              {
                "text": "ber",
                "logprob": 0.0
              },
              {
                "text": "lein",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0006073060794733465
              },
              {
                "text": "\u0160",
                "logprob": -9.905801562126726e-05
              },
              {
                "text": "mul",
                "logprob": 0.0
              },
              {
                "text": "ian",
                "logprob": -1.168244216387393e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0008348526529289302,
              "max_token_negative_log_likelihood": 0.005691721569746733,
              "predictive_entropy": 0.0008307582862698837,
              "shannon_entropy": 0.00723251067657249
            }
          },
          {
            "text": "The Eberlein\u2013\u0160mulian",
            "logprob": -0.006678816168459889,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005691750440746546
              },
              {
                "text": "E",
                "logprob": -0.00026901919045485556
              },
              {
                "text": "ber",
                "logprob": 0.0
              },
              {
                "text": "lein",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0006073060794733465
              },
              {
                "text": "\u0160",
                "logprob": -9.905801562126726e-05
              },
              {
                "text": "mul",
                "logprob": 0.0
              },
              {
                "text": "ian",
                "logprob": -1.168244216387393e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0008348526529289302,
              "max_token_negative_log_likelihood": 0.005691721569746733,
              "predictive_entropy": 0.0008307582862698837,
              "shannon_entropy": 0.00723251067657249
            }
          },
          {
            "text": "The Eberlein\u2013\u0160mulian",
            "logprob": -0.006678816168459889,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005691750440746546
              },
              {
                "text": "E",
                "logprob": -0.00026901919045485556
              },
              {
                "text": "ber",
                "logprob": 0.0
              },
              {
                "text": "lein",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0006073060794733465
              },
              {
                "text": "\u0160",
                "logprob": -9.905801562126726e-05
              },
              {
                "text": "mul",
                "logprob": 0.0
              },
              {
                "text": "ian",
                "logprob": -1.168244216387393e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0008348526529289302,
              "max_token_negative_log_likelihood": 0.005691721569746733,
              "predictive_entropy": 0.0008307582862698837,
              "shannon_entropy": 0.00723251067657249
            }
          },
          {
            "text": "The Eberlein\u2013\u0160mulian",
            "logprob": -0.006678816168459889,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005691750440746546
              },
              {
                "text": "E",
                "logprob": -0.00026901919045485556
              },
              {
                "text": "ber",
                "logprob": 0.0
              },
              {
                "text": "lein",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0006073060794733465
              },
              {
                "text": "\u0160",
                "logprob": -9.905801562126726e-05
              },
              {
                "text": "mul",
                "logprob": 0.0
              },
              {
                "text": "ian",
                "logprob": -1.168244216387393e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0008348526529289302,
              "max_token_negative_log_likelihood": 0.005691721569746733,
              "predictive_entropy": 0.0008307582862698837,
              "shannon_entropy": 0.00723251067657249
            }
          },
          {
            "text": "The Eberlein\u2013\u0160mulian",
            "logprob": -0.006678816168459889,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005691750440746546
              },
              {
                "text": "E",
                "logprob": -0.00026901919045485556
              },
              {
                "text": "ber",
                "logprob": 0.0
              },
              {
                "text": "lein",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0006073060794733465
              },
              {
                "text": "\u0160",
                "logprob": -9.905801562126726e-05
              },
              {
                "text": "mul",
                "logprob": 0.0
              },
              {
                "text": "ian",
                "logprob": -1.168244216387393e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0008348526529289302,
              "max_token_negative_log_likelihood": 0.005691721569746733,
              "predictive_entropy": 0.0008307582862698837,
              "shannon_entropy": 0.00723251067657249
            }
          }
        ],
        "cached": false,
        "request_time": 1.034386396408081,
        "request_datetime": 1755801555
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Linnik's theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Yuri Linnik"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Yuri Vladimirovich Linnik"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id12"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nLinnik's theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Linnik's theorem was solved",
            "logprob": -0.37753950148771054,
            "tokens": [
              {
                "text": "L",
                "logprob": -0.009066365659236908
              },
              {
                "text": "inn",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ik",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "'",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -7.509902934543788e-05
              },
              {
                "text": "was",
                "logprob": -0.3543604016304016
              },
              {
                "text": "solved",
                "logprob": -0.014032509177923203
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04719243280595897,
              "max_token_negative_log_likelihood": 0.3543603718280792,
              "predictive_entropy": 0.033941096622413625,
              "shannon_entropy": 0.1269980511586022
            }
          },
          {
            "text": "Linnik's theorem, concerning",
            "logprob": -2.80027522608588,
            "tokens": [
              {
                "text": "L",
                "logprob": -0.009066365659236908
              },
              {
                "text": "inn",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ik",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "'",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -7.509902934543788e-05
              },
              {
                "text": ",",
                "logprob": -1.4168603420257568
              },
              {
                "text": "concerning",
                "logprob": -1.3742682933807373
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3500344045507422,
              "max_token_negative_log_likelihood": 1.4168603420257568,
              "predictive_entropy": 0.08754256413868688,
              "shannon_entropy": 0.2891865420113158
            }
          },
          {
            "text": "Linnik's theorem was solved",
            "logprob": -0.37753950148771054,
            "tokens": [
              {
                "text": "L",
                "logprob": -0.009066365659236908
              },
              {
                "text": "inn",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ik",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "'",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -7.509902934543788e-05
              },
              {
                "text": "was",
                "logprob": -0.3543604016304016
              },
              {
                "text": "solved",
                "logprob": -0.014032509177923203
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04719243280595897,
              "max_token_negative_log_likelihood": 0.3543603718280792,
              "predictive_entropy": 0.033941096622413625,
              "shannon_entropy": 0.1269980511586022
            }
          },
          {
            "text": "Linnik's theorem, which",
            "logprob": -2.14402522608588,
            "tokens": [
              {
                "text": "L",
                "logprob": -0.009066365659236908
              },
              {
                "text": "inn",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ik",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "'",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -7.509902934543788e-05
              },
              {
                "text": ",",
                "logprob": -1.4168603420257568
              },
              {
                "text": "which",
                "logprob": -0.7180182933807373
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2680031545507422,
              "max_token_negative_log_likelihood": 1.4168603420257568,
              "predictive_entropy": 0.08785088033965849,
              "shannon_entropy": 0.2891865420113158
            }
          },
          {
            "text": "Linnik's theorem, which",
            "logprob": -2.14402522608588,
            "tokens": [
              {
                "text": "L",
                "logprob": -0.009066365659236908
              },
              {
                "text": "inn",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ik",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "'",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -7.509902934543788e-05
              },
              {
                "text": ",",
                "logprob": -1.4168603420257568
              },
              {
                "text": "which",
                "logprob": -0.7180182933807373
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2680031545507422,
              "max_token_negative_log_likelihood": 1.4168603420257568,
              "predictive_entropy": 0.08785088033965849,
              "shannon_entropy": 0.2891865420113158
            }
          }
        ],
        "cached": false,
        "request_time": 1.030268907546997,
        "request_datetime": 1755801555
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Gelfand\u2013Mazur theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Israel Gelfand"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gelfand, Izrail M."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gel'fand Izrail Moiseevich"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Israil Moiseivich Gelfand"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Izrail Moiseevich Gel'fand"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "I. M. Gel'fand"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Israel M. Gelfand"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Israel Moiseevich Gelfand"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "\u30a4\u30ba\u30e9\u30a4\u30ea\u30fb\u30e2\u30a4\u30bb\u30fc\u30a8\u30f4\u30a3\u30c1\u30fb\u30b2\u30ea\u30d5\u30a1\u30f3\u30c8"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id13"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nGelfand\u2013Mazur theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Gelfand\u2013Mazur",
            "logprob": -0.028911273035816976,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.028278248384594917
              },
              {
                "text": "G",
                "logprob": -0.00014995403762441128
              },
              {
                "text": "elf",
                "logprob": 0.0
              },
              {
                "text": "and",
                "logprob": -1.7881377516459906e-06
              },
              {
                "text": "\u2013",
                "logprob": -0.00040451448876410723
              },
              {
                "text": "M",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "az",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "ur",
                "logprob": -7.4741430580616e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003613910512662244,
              "max_token_negative_log_likelihood": 0.028278246521949768,
              "predictive_entropy": 0.0035153293407041986,
              "shannon_entropy": 0.017708778347507947
            }
          },
          {
            "text": "The Gelfand\u2013Mazur",
            "logprob": -0.028911273035816976,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.028278248384594917
              },
              {
                "text": "G",
                "logprob": -0.00014995403762441128
              },
              {
                "text": "elf",
                "logprob": 0.0
              },
              {
                "text": "and",
                "logprob": -1.7881377516459906e-06
              },
              {
                "text": "\u2013",
                "logprob": -0.00040451448876410723
              },
              {
                "text": "M",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "az",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "ur",
                "logprob": -7.4741430580616e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003613910512662244,
              "max_token_negative_log_likelihood": 0.028278246521949768,
              "predictive_entropy": 0.0035153293407041986,
              "shannon_entropy": 0.017708778347507947
            }
          },
          {
            "text": "The Gelfand\u2013Mazur",
            "logprob": -0.028911273035816976,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.028278248384594917
              },
              {
                "text": "G",
                "logprob": -0.00014995403762441128
              },
              {
                "text": "elf",
                "logprob": 0.0
              },
              {
                "text": "and",
                "logprob": -1.7881377516459906e-06
              },
              {
                "text": "\u2013",
                "logprob": -0.00040451448876410723
              },
              {
                "text": "M",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "az",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "ur",
                "logprob": -7.4741430580616e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003613910512662244,
              "max_token_negative_log_likelihood": 0.028278246521949768,
              "predictive_entropy": 0.0035153293407041986,
              "shannon_entropy": 0.017708778347507947
            }
          },
          {
            "text": "The Gelfand\u2013Mazur",
            "logprob": -0.028911273035816976,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.028278248384594917
              },
              {
                "text": "G",
                "logprob": -0.00014995403762441128
              },
              {
                "text": "elf",
                "logprob": 0.0
              },
              {
                "text": "and",
                "logprob": -1.7881377516459906e-06
              },
              {
                "text": "\u2013",
                "logprob": -0.00040451448876410723
              },
              {
                "text": "M",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "az",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "ur",
                "logprob": -7.4741430580616e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003613910512662244,
              "max_token_negative_log_likelihood": 0.028278246521949768,
              "predictive_entropy": 0.0035153293407041986,
              "shannon_entropy": 0.017708778347507947
            }
          },
          {
            "text": "The Gelfand\u2013Mazur",
            "logprob": -0.028911273035816976,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.028278248384594917
              },
              {
                "text": "G",
                "logprob": -0.00014995403762441128
              },
              {
                "text": "elf",
                "logprob": 0.0
              },
              {
                "text": "and",
                "logprob": -1.7881377516459906e-06
              },
              {
                "text": "\u2013",
                "logprob": -0.00040451448876410723
              },
              {
                "text": "M",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "az",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "ur",
                "logprob": -7.4741430580616e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003613910512662244,
              "max_token_negative_log_likelihood": 0.028278246521949768,
              "predictive_entropy": 0.0035153293407041986,
              "shannon_entropy": 0.017708778347507947
            }
          }
        ],
        "cached": false,
        "request_time": 1.026829481124878,
        "request_datetime": 1755801555
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Berry\u2013Robbins problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Michael Atiyah"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Michael Francis Atiyah"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Michael F. Atiyah"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sir Michael Francis Atiyah"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Michael Atiyah"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id14"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nBerry\u2013Robbins problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Berry\u2013Robbins problem",
            "logprob": -0.02789801641480949,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.024645717814564705
              },
              {
                "text": "Ber",
                "logprob": -0.000537727726623416
              },
              {
                "text": "ry",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.002555915853008628
              },
              {
                "text": "R",
                "logprob": 0.0
              },
              {
                "text": "obb",
                "logprob": 0.0
              },
              {
                "text": "ins",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.00015841660206206143
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003487252737617297,
              "max_token_negative_log_likelihood": 0.02464573085308075,
              "predictive_entropy": 0.0034113994734035202,
              "shannon_entropy": 0.019854196689672865
            }
          },
          {
            "text": "The Berry\u2013Robbins problem",
            "logprob": -0.02789801641480949,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.024645717814564705
              },
              {
                "text": "Ber",
                "logprob": -0.000537727726623416
              },
              {
                "text": "ry",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.002555915853008628
              },
              {
                "text": "R",
                "logprob": 0.0
              },
              {
                "text": "obb",
                "logprob": 0.0
              },
              {
                "text": "ins",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.00015841660206206143
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003487252737617297,
              "max_token_negative_log_likelihood": 0.02464573085308075,
              "predictive_entropy": 0.0034113994734035202,
              "shannon_entropy": 0.019854196689672865
            }
          },
          {
            "text": "The Berry\u2013Robbins problem",
            "logprob": -0.02789801641480949,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.024645717814564705
              },
              {
                "text": "Ber",
                "logprob": -0.000537727726623416
              },
              {
                "text": "ry",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.002555915853008628
              },
              {
                "text": "R",
                "logprob": 0.0
              },
              {
                "text": "obb",
                "logprob": 0.0
              },
              {
                "text": "ins",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.00015841660206206143
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003487252737617297,
              "max_token_negative_log_likelihood": 0.02464573085308075,
              "predictive_entropy": 0.0034113994734035202,
              "shannon_entropy": 0.019854196689672865
            }
          },
          {
            "text": "The Berry\u2013Robbins problem",
            "logprob": -0.02789801641480949,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.024645717814564705
              },
              {
                "text": "Ber",
                "logprob": -0.000537727726623416
              },
              {
                "text": "ry",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.002555915853008628
              },
              {
                "text": "R",
                "logprob": 0.0
              },
              {
                "text": "obb",
                "logprob": 0.0
              },
              {
                "text": "ins",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.00015841660206206143
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003487252737617297,
              "max_token_negative_log_likelihood": 0.02464573085308075,
              "predictive_entropy": 0.0034113994734035202,
              "shannon_entropy": 0.019854196689672865
            }
          },
          {
            "text": "The Berry\u2013Robbins problem",
            "logprob": -0.02789801641480949,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.024645717814564705
              },
              {
                "text": "Ber",
                "logprob": -0.000537727726623416
              },
              {
                "text": "ry",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.002555915853008628
              },
              {
                "text": "R",
                "logprob": 0.0
              },
              {
                "text": "obb",
                "logprob": 0.0
              },
              {
                "text": "ins",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.00015841660206206143
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003487252737617297,
              "max_token_negative_log_likelihood": 0.02464573085308075,
              "predictive_entropy": 0.0034113994734035202,
              "shannon_entropy": 0.019854196689672865
            }
          }
        ],
        "cached": false,
        "request_time": 1.0487046241760254,
        "request_datetime": 1755801556
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Kolmogorov's three-series theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Andrey Kolmogorov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrey Nikolaevich Kolmogorov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrey Kolmogoroff"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrey N. Kolmogorov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "A. N. Kolmogorov"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id15"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nKolmogorov's three-series theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Kolmogorov's three",
            "logprob": -0.5995550641642922,
            "tokens": [
              {
                "text": "Kol",
                "logprob": -0.5927689671516418
              },
              {
                "text": "m",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "og",
                "logprob": 0.0
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "'",
                "logprob": -2.4199192921514623e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "three",
                "logprob": -0.006759752053767443
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07494437284952227,
              "max_token_negative_log_likelihood": 0.5927689075469971,
              "predictive_entropy": 0.04180249131566427,
              "shannon_entropy": 0.18399135437045988
            }
          },
          {
            "text": "Vladimir V. Steklov is cred",
            "logprob": -5.150671754032373,
            "tokens": [
              {
                "text": "Vladimir",
                "logprob": -1.811518907546997
              },
              {
                "text": "V",
                "logprob": -0.5249109268188477
              },
              {
                "text": ".",
                "logprob": -0.009257841855287552
              },
              {
                "text": "Ste",
                "logprob": -0.41275426745414734
              },
              {
                "text": "k",
                "logprob": -1.2150682210922241
              },
              {
                "text": "lov",
                "logprob": -0.032539188861846924
              },
              {
                "text": "is",
                "logprob": -0.2434144765138626
              },
              {
                "text": "cred",
                "logprob": -0.9012079238891602
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6438339618034661,
              "max_token_negative_log_likelihood": 1.811518907546997,
              "predictive_entropy": 0.22970986331347376,
              "shannon_entropy": 1.0667466893792152
            }
          },
          {
            "text": "Vladimir A. Alekseenko,",
            "logprob": -10.270900179480122,
            "tokens": [
              {
                "text": "Vladimir",
                "logprob": -1.811518907546997
              },
              {
                "text": "A",
                "logprob": -2.2749109268188477
              },
              {
                "text": ".",
                "logprob": -0.05520069971680641
              },
              {
                "text": "Ale",
                "logprob": -3.185438632965088
              },
              {
                "text": "k",
                "logprob": -0.00038378025055862963
              },
              {
                "text": "seen",
                "logprob": -1.6327486038208008
              },
              {
                "text": "ko",
                "logprob": -1.1324817933200393e-05
              },
              {
                "text": ",",
                "logprob": -1.3106873035430908
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.2838624821896474,
              "max_token_negative_log_likelihood": 3.185438394546509,
              "predictive_entropy": 0.1733375988944772,
              "shannon_entropy": 1.1861530028436391
            }
          },
          {
            "text": "Kolmogorov's three",
            "logprob": -0.5995550641642922,
            "tokens": [
              {
                "text": "Kol",
                "logprob": -0.5927689671516418
              },
              {
                "text": "m",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "og",
                "logprob": 0.0
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "'",
                "logprob": -2.4199192921514623e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "three",
                "logprob": -0.006759752053767443
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07494437284952227,
              "max_token_negative_log_likelihood": 0.5927689075469971,
              "predictive_entropy": 0.04180249131566427,
              "shannon_entropy": 0.18399135437045988
            }
          },
          {
            "text": "Kolmogorov's three",
            "logprob": -0.5995550641642922,
            "tokens": [
              {
                "text": "Kol",
                "logprob": -0.5927689671516418
              },
              {
                "text": "m",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "og",
                "logprob": 0.0
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "'",
                "logprob": -2.4199192921514623e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "three",
                "logprob": -0.006759752053767443
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07494437284952227,
              "max_token_negative_log_likelihood": 0.5927689075469971,
              "predictive_entropy": 0.04180249131566427,
              "shannon_entropy": 0.18399135437045988
            }
          }
        ],
        "cached": false,
        "request_time": 1.047178030014038,
        "request_datetime": 1755801556
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Converse theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Ilya Piatetski-Shapiro"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ilya Iosifovich Pyatetsky-Shapiro"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id16"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nConverse theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Converse theorem is a broad term",
            "logprob": -4.901763789355755,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.039411164820194244
              },
              {
                "text": "Con",
                "logprob": -0.10675551742315292
              },
              {
                "text": "verse",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.26223915815353394
              },
              {
                "text": "is",
                "logprob": -3.136870861053467
              },
              {
                "text": "a",
                "logprob": -0.603073000907898
              },
              {
                "text": "broad",
                "logprob": -0.6594175696372986
              },
              {
                "text": "term",
                "logprob": -0.09399651736021042
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6127204350195825,
              "max_token_negative_log_likelihood": 3.1368706226348877,
              "predictive_entropy": 0.153540117200464,
              "shannon_entropy": 0.8374692035528284
            }
          },
          {
            "text": "The Converse theorem, as it might",
            "logprob": -8.22307950258255,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.039411164820194244
              },
              {
                "text": "Con",
                "logprob": -0.10675551742315292
              },
              {
                "text": "verse",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.26223915815353394
              },
              {
                "text": ",",
                "logprob": -0.7931209802627563
              },
              {
                "text": "as",
                "logprob": -3.149768114089966
              },
              {
                "text": "it",
                "logprob": -0.6065016984939575
              },
              {
                "text": "might",
                "logprob": -3.2652828693389893
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.027884857263416,
              "max_token_negative_log_likelihood": 3.265282392501831,
              "predictive_entropy": 0.16060077166184783,
              "shannon_entropy": 1.113973597219811
            }
          },
          {
            "text": "The Converse theorem may refer to various",
            "logprob": -6.111017903975153,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.039411164820194244
              },
              {
                "text": "Con",
                "logprob": -0.10675551742315292
              },
              {
                "text": "verse",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.26223915815353394
              },
              {
                "text": "may",
                "logprob": -4.918120861053467
              },
              {
                "text": "refer",
                "logprob": -0.12142177671194077
              },
              {
                "text": "to",
                "logprob": -4.8993817472364753e-05
              },
              {
                "text": "various",
                "logprob": -0.6630204319953918
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.763877117690754,
              "max_token_negative_log_likelihood": 4.91811990737915,
              "predictive_entropy": 0.10259803648932575,
              "shannon_entropy": 0.6766813509917853
            }
          },
          {
            "text": "The Converse theorem, depending on the",
            "logprob": -2.107926386408508,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.039411164820194244
              },
              {
                "text": "Con",
                "logprob": -0.10675551742315292
              },
              {
                "text": "verse",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.26223915815353394
              },
              {
                "text": ",",
                "logprob": -0.7931209802627563
              },
              {
                "text": "depending",
                "logprob": -0.774768054485321
              },
              {
                "text": "on",
                "logprob": -0.009865927509963512
              },
              {
                "text": "the",
                "logprob": -0.12176558375358582
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2634908140171319,
              "max_token_negative_log_likelihood": 0.7931210398674011,
              "predictive_entropy": 0.1461262956727296,
              "shannon_entropy": 0.7201337187240284
            }
          },
          {
            "text": "The Converse theorem, depending on the",
            "logprob": -2.107926386408508,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.039411164820194244
              },
              {
                "text": "Con",
                "logprob": -0.10675551742315292
              },
              {
                "text": "verse",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.26223915815353394
              },
              {
                "text": ",",
                "logprob": -0.7931209802627563
              },
              {
                "text": "depending",
                "logprob": -0.774768054485321
              },
              {
                "text": "on",
                "logprob": -0.009865927509963512
              },
              {
                "text": "the",
                "logprob": -0.12176558375358582
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2634908140171319,
              "max_token_negative_log_likelihood": 0.7931210398674011,
              "predictive_entropy": 0.1461262956727296,
              "shannon_entropy": 0.7201337187240284
            }
          }
        ],
        "cached": false,
        "request_time": 1.043466329574585,
        "request_datetime": 1755801556
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "van der Waerden Permanent Conjecture was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Georgy Petrovich Egorychev"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "G. P. Egorychev"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id17"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nvan der Waerden Permanent Conjecture was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Van der Waerden Perman",
            "logprob": -1.219008479150375,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09197991341352463
              },
              {
                "text": "Van",
                "logprob": -1.1112914085388184
              },
              {
                "text": "der",
                "logprob": -0.0007325111655518413
              },
              {
                "text": "Wa",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "er",
                "logprob": 0.0
              },
              {
                "text": "den",
                "logprob": 0.0
              },
              {
                "text": "P",
                "logprob": -0.015003573149442673
              },
              {
                "text": "erman",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15237606165472073,
              "max_token_negative_log_likelihood": 1.1112914085388184,
              "predictive_entropy": 0.05814670457759519,
              "shannon_entropy": 0.16784267178118473
            }
          },
          {
            "text": "Van der Waerden Permanent",
            "logprob": -4.883322353329191,
            "tokens": [
              {
                "text": "Van",
                "logprob": -2.52947998046875
              },
              {
                "text": "der",
                "logprob": -9.178694017464295e-05
              },
              {
                "text": "Wa",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "er",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "den",
                "logprob": 0.0
              },
              {
                "text": "P",
                "logprob": -2.353715658187866
              },
              {
                "text": "erman",
                "logprob": 0.0
              },
              {
                "text": "ent",
                "logprob": -3.433168603805825e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6104152953667032,
              "max_token_negative_log_likelihood": 2.52947998046875,
              "predictive_entropy": 0.053170848037538576,
              "shannon_entropy": 0.08687374342654053
            }
          },
          {
            "text": "The van der Waerden Perman",
            "logprob": -0.5837705143748053,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09197991341352463
              },
              {
                "text": "van",
                "logprob": -0.48629140853881836
              },
              {
                "text": "der",
                "logprob": -1.3470558769768104e-05
              },
              {
                "text": "Wa",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "er",
                "logprob": 0.0
              },
              {
                "text": "den",
                "logprob": 0.0
              },
              {
                "text": "P",
                "logprob": -0.005485245026648045
              },
              {
                "text": "erman",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07297132398208817,
              "max_token_negative_log_likelihood": 0.48629146814346313,
              "predictive_entropy": 0.04854851331354837,
              "shannon_entropy": 0.1603798990236759
            }
          },
          {
            "text": "The van der Waerden Perman",
            "logprob": -0.5837705143748053,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09197991341352463
              },
              {
                "text": "van",
                "logprob": -0.48629140853881836
              },
              {
                "text": "der",
                "logprob": -1.3470558769768104e-05
              },
              {
                "text": "Wa",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "er",
                "logprob": 0.0
              },
              {
                "text": "den",
                "logprob": 0.0
              },
              {
                "text": "P",
                "logprob": -0.005485245026648045
              },
              {
                "text": "erman",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07297132398208817,
              "max_token_negative_log_likelihood": 0.48629146814346313,
              "predictive_entropy": 0.04854851331354837,
              "shannon_entropy": 0.1603798990236759
            }
          },
          {
            "text": "The van der Waerden Perman",
            "logprob": -0.5837705143748053,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09197991341352463
              },
              {
                "text": "van",
                "logprob": -0.48629140853881836
              },
              {
                "text": "der",
                "logprob": -1.3470558769768104e-05
              },
              {
                "text": "Wa",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "er",
                "logprob": 0.0
              },
              {
                "text": "den",
                "logprob": 0.0
              },
              {
                "text": "P",
                "logprob": -0.005485245026648045
              },
              {
                "text": "erman",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07297132398208817,
              "max_token_negative_log_likelihood": 0.48629146814346313,
              "predictive_entropy": 0.04854851331354837,
              "shannon_entropy": 0.1603798990236759
            }
          }
        ],
        "cached": false,
        "request_time": 1.0476148128509521,
        "request_datetime": 1755801556
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Glivenko\u2013Cantelli theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Valery Glivenko"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Valery Ivanovich Glivenko"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id18"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nGlivenko\u2013Cantelli theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Glivenko\u2013Cantelli",
            "logprob": -0.020381812413511113,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01575181819498539
              },
              {
                "text": "Gl",
                "logprob": -0.0002356490003876388
              },
              {
                "text": "iven",
                "logprob": 0.0
              },
              {
                "text": "ko",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.003489478724077344
              },
              {
                "text": "C",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ant",
                "logprob": 0.0
              },
              {
                "text": "elli",
                "logprob": -0.0009041512385010719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0025477249073677655,
              "max_token_negative_log_likelihood": 0.015751808881759644,
              "predictive_entropy": 0.002515324465981905,
              "shannon_entropy": 0.016524393324539588
            }
          },
          {
            "text": "The Glivenko\u2013Cantelli",
            "logprob": -0.020381812413511113,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01575181819498539
              },
              {
                "text": "Gl",
                "logprob": -0.0002356490003876388
              },
              {
                "text": "iven",
                "logprob": 0.0
              },
              {
                "text": "ko",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.003489478724077344
              },
              {
                "text": "C",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ant",
                "logprob": 0.0
              },
              {
                "text": "elli",
                "logprob": -0.0009041512385010719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0025477249073677655,
              "max_token_negative_log_likelihood": 0.015751808881759644,
              "predictive_entropy": 0.002515324465981905,
              "shannon_entropy": 0.016524393324539588
            }
          },
          {
            "text": "The Glivenko\u2013Cantelli",
            "logprob": -0.020381812413511113,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01575181819498539
              },
              {
                "text": "Gl",
                "logprob": -0.0002356490003876388
              },
              {
                "text": "iven",
                "logprob": 0.0
              },
              {
                "text": "ko",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.003489478724077344
              },
              {
                "text": "C",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ant",
                "logprob": 0.0
              },
              {
                "text": "elli",
                "logprob": -0.0009041512385010719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0025477249073677655,
              "max_token_negative_log_likelihood": 0.015751808881759644,
              "predictive_entropy": 0.002515324465981905,
              "shannon_entropy": 0.016524393324539588
            }
          },
          {
            "text": "The Glivenko\u2013Cantelli",
            "logprob": -0.020381812413511113,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01575181819498539
              },
              {
                "text": "Gl",
                "logprob": -0.0002356490003876388
              },
              {
                "text": "iven",
                "logprob": 0.0
              },
              {
                "text": "ko",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.003489478724077344
              },
              {
                "text": "C",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ant",
                "logprob": 0.0
              },
              {
                "text": "elli",
                "logprob": -0.0009041512385010719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0025477249073677655,
              "max_token_negative_log_likelihood": 0.015751808881759644,
              "predictive_entropy": 0.002515324465981905,
              "shannon_entropy": 0.016524393324539588
            }
          },
          {
            "text": "The Glivenko\u2013Cantelli",
            "logprob": -0.020381812413511113,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01575181819498539
              },
              {
                "text": "Gl",
                "logprob": -0.0002356490003876388
              },
              {
                "text": "iven",
                "logprob": 0.0
              },
              {
                "text": "ko",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.003489478724077344
              },
              {
                "text": "C",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ant",
                "logprob": 0.0
              },
              {
                "text": "elli",
                "logprob": -0.0009041512385010719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0025477249073677655,
              "max_token_negative_log_likelihood": 0.015751808881759644,
              "predictive_entropy": 0.002515324465981905,
              "shannon_entropy": 0.016524393324539588
            }
          }
        ],
        "cached": false,
        "request_time": 1.0239827632904053,
        "request_datetime": 1755801557
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Casorati\u2013Weierstrass theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Yulian Sokhotski"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Julian Sochocki"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Yulian Vasilievich Sokhotski"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Julian Karol Sochocki"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id19"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nCasorati\u2013Weierstrass theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Casorati\u2013Weierstr",
            "logprob": -0.09322696718345469,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09239812195301056
              },
              {
                "text": "Cas",
                "logprob": -7.533743337262422e-05
              },
              {
                "text": "or",
                "logprob": -3.576272320060525e-06
              },
              {
                "text": "ati",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0007098776986822486
              },
              {
                "text": "We",
                "logprob": 0.0
              },
              {
                "text": "ier",
                "logprob": -3.015949550899677e-05
              },
              {
                "text": "str",
                "logprob": -8.940656698541716e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011653375123330534,
              "max_token_negative_log_likelihood": 0.09239812195301056,
              "predictive_entropy": 0.010633953611488778,
              "shannon_entropy": 0.04104992021218834
            }
          },
          {
            "text": "The Casorati\u2013Weierstr",
            "logprob": -0.09322696718345469,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09239812195301056
              },
              {
                "text": "Cas",
                "logprob": -7.533743337262422e-05
              },
              {
                "text": "or",
                "logprob": -3.576272320060525e-06
              },
              {
                "text": "ati",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0007098776986822486
              },
              {
                "text": "We",
                "logprob": 0.0
              },
              {
                "text": "ier",
                "logprob": -3.015949550899677e-05
              },
              {
                "text": "str",
                "logprob": -8.940656698541716e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011653375123330534,
              "max_token_negative_log_likelihood": 0.09239812195301056,
              "predictive_entropy": 0.010633953611488778,
              "shannon_entropy": 0.04104992021218834
            }
          },
          {
            "text": "The Casorati\u2013Weierstr",
            "logprob": -0.09322696718345469,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09239812195301056
              },
              {
                "text": "Cas",
                "logprob": -7.533743337262422e-05
              },
              {
                "text": "or",
                "logprob": -3.576272320060525e-06
              },
              {
                "text": "ati",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0007098776986822486
              },
              {
                "text": "We",
                "logprob": 0.0
              },
              {
                "text": "ier",
                "logprob": -3.015949550899677e-05
              },
              {
                "text": "str",
                "logprob": -8.940656698541716e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011653375123330534,
              "max_token_negative_log_likelihood": 0.09239812195301056,
              "predictive_entropy": 0.010633953611488778,
              "shannon_entropy": 0.04104992021218834
            }
          },
          {
            "text": "The Casorati\u2013Weierstr",
            "logprob": -0.09322696718345469,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09239812195301056
              },
              {
                "text": "Cas",
                "logprob": -7.533743337262422e-05
              },
              {
                "text": "or",
                "logprob": -3.576272320060525e-06
              },
              {
                "text": "ati",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0007098776986822486
              },
              {
                "text": "We",
                "logprob": 0.0
              },
              {
                "text": "ier",
                "logprob": -3.015949550899677e-05
              },
              {
                "text": "str",
                "logprob": -8.940656698541716e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011653375123330534,
              "max_token_negative_log_likelihood": 0.09239812195301056,
              "predictive_entropy": 0.010633953611488778,
              "shannon_entropy": 0.04104992021218834
            }
          },
          {
            "text": "The Casorati\u2013Weierstr",
            "logprob": -0.09322696718345469,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09239812195301056
              },
              {
                "text": "Cas",
                "logprob": -7.533743337262422e-05
              },
              {
                "text": "or",
                "logprob": -3.576272320060525e-06
              },
              {
                "text": "ati",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0007098776986822486
              },
              {
                "text": "We",
                "logprob": 0.0
              },
              {
                "text": "ier",
                "logprob": -3.015949550899677e-05
              },
              {
                "text": "str",
                "logprob": -8.940656698541716e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011653375123330534,
              "max_token_negative_log_likelihood": 0.09239812195301056,
              "predictive_entropy": 0.010633953611488778,
              "shannon_entropy": 0.04104992021218834
            }
          }
        ],
        "cached": false,
        "request_time": 1.0241930484771729,
        "request_datetime": 1755801557
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Lagrange, Euler and Kovalevskaya tops was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Sofia Kovalevskaya"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofya Kovalevskaya"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofya Kovalevskaia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofya Kovalevskaja"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofya Kovalevsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofia Kovalevskaya"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofia Kovalevskaia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofia Kovalevskaja"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofia Kovalevsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofja Kovalevskaya"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofja Kovalevskaja"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofja Kovalevskaia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofja Kovalevsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofya Vasilyevna Kovalevskaya"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Leonhard Euler"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Euler, Leonhard"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "L. Euler"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id20"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nLagrange, Euler and Kovalevskaya tops was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The \"Lagrange, Euler",
            "logprob": -0.49704764934904233,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01249662134796381
              },
              {
                "text": "\"",
                "logprob": -0.40890735387802124
              },
              {
                "text": "L",
                "logprob": -0.07306163758039474
              },
              {
                "text": "ag",
                "logprob": -0.0001248043408850208
              },
              {
                "text": "range",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.002452225424349308
              },
              {
                "text": "E",
                "logprob": -5.006777428206988e-06
              },
              {
                "text": "uler",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.062130954945814665,
              "max_token_negative_log_likelihood": 0.40890735387802124,
              "predictive_entropy": 0.04431244350990937,
              "shannon_entropy": 0.186503395090154
            }
          },
          {
            "text": "The \"Lagrange, Euler",
            "logprob": -0.49704764934904233,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01249662134796381
              },
              {
                "text": "\"",
                "logprob": -0.40890735387802124
              },
              {
                "text": "L",
                "logprob": -0.07306163758039474
              },
              {
                "text": "ag",
                "logprob": -0.0001248043408850208
              },
              {
                "text": "range",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.002452225424349308
              },
              {
                "text": "E",
                "logprob": -5.006777428206988e-06
              },
              {
                "text": "uler",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.062130954945814665,
              "max_token_negative_log_likelihood": 0.40890735387802124,
              "predictive_entropy": 0.04431244350990937,
              "shannon_entropy": 0.186503395090154
            }
          },
          {
            "text": "The \"Lagrange, Euler",
            "logprob": -0.49704764934904233,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01249662134796381
              },
              {
                "text": "\"",
                "logprob": -0.40890735387802124
              },
              {
                "text": "L",
                "logprob": -0.07306163758039474
              },
              {
                "text": "ag",
                "logprob": -0.0001248043408850208
              },
              {
                "text": "range",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.002452225424349308
              },
              {
                "text": "E",
                "logprob": -5.006777428206988e-06
              },
              {
                "text": "uler",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.062130954945814665,
              "max_token_negative_log_likelihood": 0.40890735387802124,
              "predictive_entropy": 0.04431244350990937,
              "shannon_entropy": 0.186503395090154
            }
          },
          {
            "text": "The \"Lagrange, Euler",
            "logprob": -0.49704764934904233,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01249662134796381
              },
              {
                "text": "\"",
                "logprob": -0.40890735387802124
              },
              {
                "text": "L",
                "logprob": -0.07306163758039474
              },
              {
                "text": "ag",
                "logprob": -0.0001248043408850208
              },
              {
                "text": "range",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.002452225424349308
              },
              {
                "text": "E",
                "logprob": -5.006777428206988e-06
              },
              {
                "text": "uler",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.062130954945814665,
              "max_token_negative_log_likelihood": 0.40890735387802124,
              "predictive_entropy": 0.04431244350990937,
              "shannon_entropy": 0.186503395090154
            }
          },
          {
            "text": "The \"Lagrange, Euler",
            "logprob": -0.49704764934904233,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01249662134796381
              },
              {
                "text": "\"",
                "logprob": -0.40890735387802124
              },
              {
                "text": "L",
                "logprob": -0.07306163758039474
              },
              {
                "text": "ag",
                "logprob": -0.0001248043408850208
              },
              {
                "text": "range",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.002452225424349308
              },
              {
                "text": "E",
                "logprob": -5.006777428206988e-06
              },
              {
                "text": "uler",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.062130954945814665,
              "max_token_negative_log_likelihood": 0.40890735387802124,
              "predictive_entropy": 0.04431244350990937,
              "shannon_entropy": 0.186503395090154
            }
          }
        ],
        "cached": false,
        "request_time": 1.0190160274505615,
        "request_datetime": 1755801557
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Hilbert's thirteenth problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Vladimir Arnold"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Vladimir Igorevich Arnol'd"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "V. I. Arnol'd"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "V. I. Arnold"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "V.I. Arnol'd"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "V.I. Arnold"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Vladimir Igorevich Arnold"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "\u30f4\u30e9\u30b8\u30fc\u30df\u30eb\u30fb\u30a4\u30fc\u30b4\u30ec\u30f4\u30a3\u30c1\u30fb\u30a2\u30eb\u30ce\u30fc\u30ea\u30c8"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrey Kolmogorov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrey Nikolaevich Kolmogorov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrey Kolmogoroff"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrey N. Kolmogorov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "A. N. Kolmogorov"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id21"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nHilbert's thirteenth problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Hilbert's thirteenth problem",
            "logprob": -0.2564132603456457,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.24791599810123444
              },
              {
                "text": "bert",
                "logprob": -5.245195097813848e-06
              },
              {
                "text": "'",
                "logprob": -9.536697689327411e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "th",
                "logprob": -0.008470559492707253
              },
              {
                "text": "ir",
                "logprob": 0.0
              },
              {
                "text": "teenth",
                "logprob": -1.1801649634435307e-05
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.032051657808326084,
              "max_token_negative_log_likelihood": 0.24791601300239563,
              "predictive_entropy": 0.025238221495158086,
              "shannon_entropy": 0.08552304124929311
            }
          },
          {
            "text": "Hilbert's thirteenth problem",
            "logprob": -0.2564132603456457,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.24791599810123444
              },
              {
                "text": "bert",
                "logprob": -5.245195097813848e-06
              },
              {
                "text": "'",
                "logprob": -9.536697689327411e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "th",
                "logprob": -0.008470559492707253
              },
              {
                "text": "ir",
                "logprob": 0.0
              },
              {
                "text": "teenth",
                "logprob": -1.1801649634435307e-05
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.032051657808326084,
              "max_token_negative_log_likelihood": 0.24791601300239563,
              "predictive_entropy": 0.025238221495158086,
              "shannon_entropy": 0.08552304124929311
            }
          },
          {
            "text": "Hilbert's thirteenth problem",
            "logprob": -0.2564132603456457,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.24791599810123444
              },
              {
                "text": "bert",
                "logprob": -5.245195097813848e-06
              },
              {
                "text": "'",
                "logprob": -9.536697689327411e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "th",
                "logprob": -0.008470559492707253
              },
              {
                "text": "ir",
                "logprob": 0.0
              },
              {
                "text": "teenth",
                "logprob": -1.1801649634435307e-05
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.032051657808326084,
              "max_token_negative_log_likelihood": 0.24791601300239563,
              "predictive_entropy": 0.025238221495158086,
              "shannon_entropy": 0.08552304124929311
            }
          },
          {
            "text": "Hilbert's thirteenth problem",
            "logprob": -0.2564132603456457,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.24791599810123444
              },
              {
                "text": "bert",
                "logprob": -5.245195097813848e-06
              },
              {
                "text": "'",
                "logprob": -9.536697689327411e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "th",
                "logprob": -0.008470559492707253
              },
              {
                "text": "ir",
                "logprob": 0.0
              },
              {
                "text": "teenth",
                "logprob": -1.1801649634435307e-05
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.032051657808326084,
              "max_token_negative_log_likelihood": 0.24791601300239563,
              "predictive_entropy": 0.025238221495158086,
              "shannon_entropy": 0.08552304124929311
            }
          },
          {
            "text": "Hilbert's thirteenth problem",
            "logprob": -0.2564132603456457,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.24791599810123444
              },
              {
                "text": "bert",
                "logprob": -5.245195097813848e-06
              },
              {
                "text": "'",
                "logprob": -9.536697689327411e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "th",
                "logprob": -0.008470559492707253
              },
              {
                "text": "ir",
                "logprob": 0.0
              },
              {
                "text": "teenth",
                "logprob": -1.1801649634435307e-05
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.032051657808326084,
              "max_token_negative_log_likelihood": 0.24791601300239563,
              "predictive_entropy": 0.025238221495158086,
              "shannon_entropy": 0.08552304124929311
            }
          }
        ],
        "cached": false,
        "request_time": 1.3072004318237305,
        "request_datetime": 1755801557
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Euler's theorem in geometry was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Leonhard Euler"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Euler, Leonhard"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "L. Euler"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id22"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nEuler's theorem in geometry was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Euler's theorem in geometry,",
            "logprob": -0.2769446372153652,
            "tokens": [
              {
                "text": "E",
                "logprob": -0.049885790795087814
              },
              {
                "text": "uler",
                "logprob": -5.960446742392378e-06
              },
              {
                "text": "'",
                "logprob": -0.0002115741081070155
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.019161945208907127
              },
              {
                "text": "in",
                "logprob": -0.00019739109848160297
              },
              {
                "text": "geometry",
                "logprob": -9.762764238985255e-05
              },
              {
                "text": ",",
                "logprob": -0.20738434791564941
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.034618080369398285,
              "max_token_negative_log_likelihood": 0.20738433301448822,
              "predictive_entropy": 0.029413966686263393,
              "shannon_entropy": 0.13389085033031378
            }
          },
          {
            "text": "Euler's theorem in geometry,",
            "logprob": -0.2769446372153652,
            "tokens": [
              {
                "text": "E",
                "logprob": -0.049885790795087814
              },
              {
                "text": "uler",
                "logprob": -5.960446742392378e-06
              },
              {
                "text": "'",
                "logprob": -0.0002115741081070155
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.019161945208907127
              },
              {
                "text": "in",
                "logprob": -0.00019739109848160297
              },
              {
                "text": "geometry",
                "logprob": -9.762764238985255e-05
              },
              {
                "text": ",",
                "logprob": -0.20738434791564941
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.034618080369398285,
              "max_token_negative_log_likelihood": 0.20738433301448822,
              "predictive_entropy": 0.029413966686263393,
              "shannon_entropy": 0.13389085033031378
            }
          },
          {
            "text": "Euler's theorem in geometry,",
            "logprob": -0.2769446372153652,
            "tokens": [
              {
                "text": "E",
                "logprob": -0.049885790795087814
              },
              {
                "text": "uler",
                "logprob": -5.960446742392378e-06
              },
              {
                "text": "'",
                "logprob": -0.0002115741081070155
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.019161945208907127
              },
              {
                "text": "in",
                "logprob": -0.00019739109848160297
              },
              {
                "text": "geometry",
                "logprob": -9.762764238985255e-05
              },
              {
                "text": ",",
                "logprob": -0.20738434791564941
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.034618080369398285,
              "max_token_negative_log_likelihood": 0.20738433301448822,
              "predictive_entropy": 0.029413966686263393,
              "shannon_entropy": 0.13389085033031378
            }
          },
          {
            "text": "Euler's theorem in geometry,",
            "logprob": -0.2769446372153652,
            "tokens": [
              {
                "text": "E",
                "logprob": -0.049885790795087814
              },
              {
                "text": "uler",
                "logprob": -5.960446742392378e-06
              },
              {
                "text": "'",
                "logprob": -0.0002115741081070155
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.019161945208907127
              },
              {
                "text": "in",
                "logprob": -0.00019739109848160297
              },
              {
                "text": "geometry",
                "logprob": -9.762764238985255e-05
              },
              {
                "text": ",",
                "logprob": -0.20738434791564941
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.034618080369398285,
              "max_token_negative_log_likelihood": 0.20738433301448822,
              "predictive_entropy": 0.029413966686263393,
              "shannon_entropy": 0.13389085033031378
            }
          },
          {
            "text": "Euler's theorem in geometry,",
            "logprob": -0.2769446372153652,
            "tokens": [
              {
                "text": "E",
                "logprob": -0.049885790795087814
              },
              {
                "text": "uler",
                "logprob": -5.960446742392378e-06
              },
              {
                "text": "'",
                "logprob": -0.0002115741081070155
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.019161945208907127
              },
              {
                "text": "in",
                "logprob": -0.00019739109848160297
              },
              {
                "text": "geometry",
                "logprob": -9.762764238985255e-05
              },
              {
                "text": ",",
                "logprob": -0.20738434791564941
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.034618080369398285,
              "max_token_negative_log_likelihood": 0.20738433301448822,
              "predictive_entropy": 0.029413966686263393,
              "shannon_entropy": 0.13389085033031378
            }
          }
        ],
        "cached": false,
        "request_time": 1.0211451053619385,
        "request_datetime": 1755801558
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Toponogov's theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Viktor Toponogov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Viktor Andreyevich Toponogov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Victor Andreevich Toponogov"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id23"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nToponogov's theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Toponogov's theorem,",
            "logprob": -0.19056775222111355,
            "tokens": [
              {
                "text": "Top",
                "logprob": -0.011588283814489841
              },
              {
                "text": "on",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "og",
                "logprob": -2.7418097943154862e-06
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -7.629103492945433e-05
              },
              {
                "text": ",",
                "logprob": -0.17889602482318878
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02382096801122202,
              "max_token_negative_log_likelihood": 0.1788960099220276,
              "predictive_entropy": 0.02014122249858019,
              "shannon_entropy": 0.0845185660343093
            }
          },
          {
            "text": "Toponogov's theorem,",
            "logprob": -0.19056775222111355,
            "tokens": [
              {
                "text": "Top",
                "logprob": -0.011588283814489841
              },
              {
                "text": "on",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "og",
                "logprob": -2.7418097943154862e-06
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -7.629103492945433e-05
              },
              {
                "text": ",",
                "logprob": -0.17889602482318878
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02382096801122202,
              "max_token_negative_log_likelihood": 0.1788960099220276,
              "predictive_entropy": 0.02014122249858019,
              "shannon_entropy": 0.0845185660343093
            }
          },
          {
            "text": "Vladimir Petrovich Toponogov",
            "logprob": -8.41007240506562,
            "tokens": [
              {
                "text": "Vladimir",
                "logprob": -6.449088096618652
              },
              {
                "text": "Pet",
                "logprob": -1.9316562414169312
              },
              {
                "text": "rov",
                "logprob": -0.01665380410850048
              },
              {
                "text": "ich",
                "logprob": -0.003931532148271799
              },
              {
                "text": "Top",
                "logprob": -0.008578473702073097
              },
              {
                "text": "on",
                "logprob": -0.00016330339713022113
              },
              {
                "text": "og",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ov",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0512582510510065,
              "max_token_negative_log_likelihood": 6.449081897735596,
              "predictive_entropy": 0.0398848726981349,
              "shannon_entropy": 0.2724628327556786
            }
          },
          {
            "text": "Toponogov's theorem,",
            "logprob": -0.19056775222111355,
            "tokens": [
              {
                "text": "Top",
                "logprob": -0.011588283814489841
              },
              {
                "text": "on",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "og",
                "logprob": -2.7418097943154862e-06
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -7.629103492945433e-05
              },
              {
                "text": ",",
                "logprob": -0.17889602482318878
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02382096801122202,
              "max_token_negative_log_likelihood": 0.1788960099220276,
              "predictive_entropy": 0.02014122249858019,
              "shannon_entropy": 0.0845185660343093
            }
          },
          {
            "text": "Toponogov's theorem was",
            "logprob": -2.1280676777153076,
            "tokens": [
              {
                "text": "Top",
                "logprob": -0.011588283814489841
              },
              {
                "text": "on",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "og",
                "logprob": -2.7418097943154862e-06
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -7.629103492945433e-05
              },
              {
                "text": "was",
                "logprob": -2.116395950317383
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2660084605606414,
              "max_token_negative_log_likelihood": 2.116395950317383,
              "predictive_entropy": 0.033311233840152,
              "shannon_entropy": 0.0845185660343093
            }
          }
        ],
        "cached": false,
        "request_time": 1.0158202648162842,
        "request_datetime": 1755801558
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Reshetnyak gluing theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Yurii Reshetnyak"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Yury Grigoryevich Reshetnyak"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Yurii Grigorievich Reshetnyak"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id24"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nReshetnyak gluing theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Reshetnyak gluing theorem",
            "logprob": -0.24012997222233423,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.1648881435394287
              },
              {
                "text": "Res",
                "logprob": -0.0020944580901414156
              },
              {
                "text": "het",
                "logprob": -4.100715523236431e-05
              },
              {
                "text": "ny",
                "logprob": -0.06833506375551224
              },
              {
                "text": "ak",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "gl",
                "logprob": -0.0047412593849003315
              },
              {
                "text": "uing",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": -2.9801878554280847e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030016243036246948,
              "max_token_negative_log_likelihood": 0.1648881435394287,
              "predictive_entropy": 0.02631556805818036,
              "shannon_entropy": 0.10061112328871502
            }
          },
          {
            "text": "The Reshetnyak gluing theorem",
            "logprob": -0.24012997222233423,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.1648881435394287
              },
              {
                "text": "Res",
                "logprob": -0.0020944580901414156
              },
              {
                "text": "het",
                "logprob": -4.100715523236431e-05
              },
              {
                "text": "ny",
                "logprob": -0.06833506375551224
              },
              {
                "text": "ak",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "gl",
                "logprob": -0.0047412593849003315
              },
              {
                "text": "uing",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": -2.9801878554280847e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030016243036246948,
              "max_token_negative_log_likelihood": 0.1648881435394287,
              "predictive_entropy": 0.02631556805818036,
              "shannon_entropy": 0.10061112328871502
            }
          },
          {
            "text": "Reshetnyak gluing theorem was",
            "logprob": -2.200598050966498,
            "tokens": [
              {
                "text": "Res",
                "logprob": -1.9773881435394287
              },
              {
                "text": "het",
                "logprob": -9.059865078597795e-06
              },
              {
                "text": "ny",
                "logprob": -0.0069369906559586525
              },
              {
                "text": "ak",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "gl",
                "logprob": -0.005441140849143267
              },
              {
                "text": "uing",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": -2.4437606043647975e-05
              },
              {
                "text": "was",
                "logprob": -0.21079768240451813
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.27507474568723644,
              "max_token_negative_log_likelihood": 1.9773880243301392,
              "predictive_entropy": 0.05709978171340424,
              "shannon_entropy": 0.15482733376782676
            }
          },
          {
            "text": "The Reshetnyak gluing theorem",
            "logprob": -0.24012997222233423,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.1648881435394287
              },
              {
                "text": "Res",
                "logprob": -0.0020944580901414156
              },
              {
                "text": "het",
                "logprob": -4.100715523236431e-05
              },
              {
                "text": "ny",
                "logprob": -0.06833506375551224
              },
              {
                "text": "ak",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "gl",
                "logprob": -0.0047412593849003315
              },
              {
                "text": "uing",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": -2.9801878554280847e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030016243036246948,
              "max_token_negative_log_likelihood": 0.1648881435394287,
              "predictive_entropy": 0.02631556805818036,
              "shannon_entropy": 0.10061112328871502
            }
          },
          {
            "text": "The Reshetnyak gluing theorem",
            "logprob": -0.24012997222233423,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.1648881435394287
              },
              {
                "text": "Res",
                "logprob": -0.0020944580901414156
              },
              {
                "text": "het",
                "logprob": -4.100715523236431e-05
              },
              {
                "text": "ny",
                "logprob": -0.06833506375551224
              },
              {
                "text": "ak",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "gl",
                "logprob": -0.0047412593849003315
              },
              {
                "text": "uing",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": -2.9801878554280847e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030016243036246948,
              "max_token_negative_log_likelihood": 0.1648881435394287,
              "predictive_entropy": 0.02631556805818036,
              "shannon_entropy": 0.10061112328871502
            }
          }
        ],
        "cached": false,
        "request_time": 1.0160012245178223,
        "request_datetime": 1755801558
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Egorov's theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Dmitri Egorov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Dmitri Fedorovich Egorov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Dimitri Fedorovich Egorov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Egorov, D.F."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Egorov, Dimitri Fedorovitch"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Egorov, Dimitrij Fedorovich"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Dmitri Fyodorovich Egorov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Carlo Severini"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id25"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nEgorov's theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Egorov's theorem, a",
            "logprob": -2.624791756735249,
            "tokens": [
              {
                "text": "Eg",
                "logprob": -0.010363337583839893
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "'",
                "logprob": -0.00013982271775603294
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0020573418587446213
              },
              {
                "text": ",",
                "logprob": -0.6592628955841064
              },
              {
                "text": "a",
                "logprob": -1.9529659748077393
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3280989637427467,
              "max_token_negative_log_likelihood": 1.9529659748077393,
              "predictive_entropy": 0.0788096834727412,
              "shannon_entropy": 0.35069417111841616
            }
          },
          {
            "text": "Egorov's theorem was solved",
            "logprob": -0.9614047114710047,
            "tokens": [
              {
                "text": "Eg",
                "logprob": -0.010363337583839893
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "'",
                "logprob": -0.00013982271775603294
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0020573418587446213
              },
              {
                "text": "was",
                "logprob": -0.9092628955841064
              },
              {
                "text": "solved",
                "logprob": -0.03957892954349518
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.12017558122207106,
              "max_token_negative_log_likelihood": 0.9092628359794617,
              "predictive_entropy": 0.052095630002099824,
              "shannon_entropy": 0.16609507330027995
            }
          },
          {
            "text": "Egorov's theorem was solved",
            "logprob": -0.9614047114710047,
            "tokens": [
              {
                "text": "Eg",
                "logprob": -0.010363337583839893
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "'",
                "logprob": -0.00013982271775603294
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0020573418587446213
              },
              {
                "text": "was",
                "logprob": -0.9092628955841064
              },
              {
                "text": "solved",
                "logprob": -0.03957892954349518
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.12017558122207106,
              "max_token_negative_log_likelihood": 0.9092628359794617,
              "predictive_entropy": 0.052095630002099824,
              "shannon_entropy": 0.16609507330027995
            }
          },
          {
            "text": "Egorov's theorem, which",
            "logprob": -2.124791756735249,
            "tokens": [
              {
                "text": "Eg",
                "logprob": -0.010363337583839893
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "'",
                "logprob": -0.00013982271775603294
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0020573418587446213
              },
              {
                "text": ",",
                "logprob": -0.6592628955841064
              },
              {
                "text": "which",
                "logprob": -1.4529659748077393
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2655989637427467,
              "max_token_negative_log_likelihood": 1.4529659748077393,
              "predictive_entropy": 0.08665715277277286,
              "shannon_entropy": 0.35069417111841616
            }
          },
          {
            "text": "Egorov's theorem was solved",
            "logprob": -0.9614047114710047,
            "tokens": [
              {
                "text": "Eg",
                "logprob": -0.010363337583839893
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "'",
                "logprob": -0.00013982271775603294
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0020573418587446213
              },
              {
                "text": "was",
                "logprob": -0.9092628955841064
              },
              {
                "text": "solved",
                "logprob": -0.03957892954349518
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.12017558122207106,
              "max_token_negative_log_likelihood": 0.9092628359794617,
              "predictive_entropy": 0.052095630002099824,
              "shannon_entropy": 0.16609507330027995
            }
          }
        ],
        "cached": false,
        "request_time": 1.0312950611114502,
        "request_datetime": 1755801558
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Hilbert's seventeenth problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Emil Artin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id26"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nHilbert's seventeenth problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Hilbert's seventeenth problem",
            "logprob": -0.12166349276753863,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.12039977312088013
              },
              {
                "text": "bert",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "'",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "sevent",
                "logprob": -0.001209957292303443
              },
              {
                "text": "e",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "enth",
                "logprob": -4.51792984677013e-05
              },
              {
                "text": "problem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.015207935443214637,
              "max_token_negative_log_likelihood": 0.12039978802204132,
              "predictive_entropy": 0.013500572839063807,
              "shannon_entropy": 0.0569286496105601
            }
          },
          {
            "text": "Hilbert's seventeenth problem",
            "logprob": -0.12166349276753863,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.12039977312088013
              },
              {
                "text": "bert",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "'",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "sevent",
                "logprob": -0.001209957292303443
              },
              {
                "text": "e",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "enth",
                "logprob": -4.51792984677013e-05
              },
              {
                "text": "problem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.015207935443214637,
              "max_token_negative_log_likelihood": 0.12039978802204132,
              "predictive_entropy": 0.013500572839063807,
              "shannon_entropy": 0.0569286496105601
            }
          },
          {
            "text": "Hilbert's seventeenth problem",
            "logprob": -0.12166349276753863,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.12039977312088013
              },
              {
                "text": "bert",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "'",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "sevent",
                "logprob": -0.001209957292303443
              },
              {
                "text": "e",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "enth",
                "logprob": -4.51792984677013e-05
              },
              {
                "text": "problem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.015207935443214637,
              "max_token_negative_log_likelihood": 0.12039978802204132,
              "predictive_entropy": 0.013500572839063807,
              "shannon_entropy": 0.0569286496105601
            }
          },
          {
            "text": "The partial statement you have given about Hil",
            "logprob": -19.29034113883972,
            "tokens": [
              {
                "text": "The",
                "logprob": -2.4641497135162354
              },
              {
                "text": "partial",
                "logprob": -7.947390556335449
              },
              {
                "text": "statement",
                "logprob": -0.3896162211894989
              },
              {
                "text": "you",
                "logprob": -2.146470785140991
              },
              {
                "text": "have",
                "logprob": -2.4476664066314697
              },
              {
                "text": "given",
                "logprob": -1.8640724420547485
              },
              {
                "text": "about",
                "logprob": -1.781334638595581
              },
              {
                "text": "Hil",
                "logprob": -0.24964037537574768
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 2.4112891033291817,
              "max_token_negative_log_likelihood": 7.947362422943115,
              "predictive_entropy": 0.21530969016021118,
              "shannon_entropy": 1.2844634875655174
            }
          },
          {
            "text": "Hilbert's seventeenth problem",
            "logprob": -0.12166349276753863,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.12039977312088013
              },
              {
                "text": "bert",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "'",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "sevent",
                "logprob": -0.001209957292303443
              },
              {
                "text": "e",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "enth",
                "logprob": -4.51792984677013e-05
              },
              {
                "text": "problem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.015207935443214637,
              "max_token_negative_log_likelihood": 0.12039978802204132,
              "predictive_entropy": 0.013500572839063807,
              "shannon_entropy": 0.0569286496105601
            }
          }
        ],
        "cached": false,
        "request_time": 1.036391019821167,
        "request_datetime": 1755801559
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Godunov's theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Sergei Godunov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sergei Konstantinovich Godunov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sergey Kon stantinovich Godunov"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id27"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nGodunov's theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Godunov's theorem, which",
            "logprob": -1.594188075439888,
            "tokens": [
              {
                "text": "God",
                "logprob": -0.07295259088277817
              },
              {
                "text": "un",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -4.792098479811102e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0002824861148837954
              },
              {
                "text": ",",
                "logprob": -0.48294419050216675
              },
              {
                "text": "which",
                "logprob": -1.0379608869552612
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.19927353738785314,
              "max_token_negative_log_likelihood": 1.0379610061645508,
              "predictive_entropy": 0.09171633747473606,
              "shannon_entropy": 0.41547170925884913
            }
          },
          {
            "text": "Godunov's theorem, which",
            "logprob": -1.594188075439888,
            "tokens": [
              {
                "text": "God",
                "logprob": -0.07295259088277817
              },
              {
                "text": "un",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -4.792098479811102e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0002824861148837954
              },
              {
                "text": ",",
                "logprob": -0.48294419050216675
              },
              {
                "text": "which",
                "logprob": -1.0379608869552612
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.19927353738785314,
              "max_token_negative_log_likelihood": 1.0379610061645508,
              "predictive_entropy": 0.09171633747473606,
              "shannon_entropy": 0.41547170925884913
            }
          },
          {
            "text": "Godunov's theorem, named",
            "logprob": -4.750438194649178,
            "tokens": [
              {
                "text": "God",
                "logprob": -0.07295259088277817
              },
              {
                "text": "un",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -4.792098479811102e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0002824861148837954
              },
              {
                "text": ",",
                "logprob": -0.48294419050216675
              },
              {
                "text": "named",
                "logprob": -4.194211006164551
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5938046681785636,
              "max_token_negative_log_likelihood": 4.194210052490234,
              "predictive_entropy": 0.0536711816589559,
              "shannon_entropy": 0.41547170925884913
            }
          },
          {
            "text": "Godunov's theorem, also",
            "logprob": -2.062938075439888,
            "tokens": [
              {
                "text": "God",
                "logprob": -0.07295259088277817
              },
              {
                "text": "un",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -4.792098479811102e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0002824861148837954
              },
              {
                "text": ",",
                "logprob": -0.48294419050216675
              },
              {
                "text": "also",
                "logprob": -1.5067108869552612
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.25786725758553075,
              "max_token_negative_log_likelihood": 1.5067107677459717,
              "predictive_entropy": 0.08750671473399052,
              "shannon_entropy": 0.41547170925884913
            }
          },
          {
            "text": "Godunov's theorem was solved",
            "logprob": -1.281508926229435,
            "tokens": [
              {
                "text": "God",
                "logprob": -0.07295259088277817
              },
              {
                "text": "un",
                "logprob": 0.0
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -4.792098479811102e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0002824861148837954
              },
              {
                "text": "was",
                "logprob": -1.1704442501068115
              },
              {
                "text": "solved",
                "logprob": -0.03778167814016342
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1601886181251757,
              "max_token_negative_log_likelihood": 1.1704442501068115,
              "predictive_entropy": 0.05845463228479275,
              "shannon_entropy": 0.19403338145464133
            }
          }
        ],
        "cached": false,
        "request_time": 1.0192396640777588,
        "request_datetime": 1755801559
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Hilbert's fourteenth problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Masayoshi Nagata"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "\u306a\u304c\u305f \u307e\u3055\u3088\u3057"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id28"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nHilbert's fourteenth problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Hilbert's fourteenth problem",
            "logprob": -1.6212990934863498,
            "tokens": [
              {
                "text": "The",
                "logprob": -1.2491493225097656
              },
              {
                "text": "Hil",
                "logprob": -0.3718404471874237
              },
              {
                "text": "bert",
                "logprob": -1.311301275563892e-06
              },
              {
                "text": "'",
                "logprob": -0.00017975145601667464
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "four",
                "logprob": -0.00012778419477399439
              },
              {
                "text": "teenth",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.20266238903981026,
              "max_token_negative_log_likelihood": 1.2491493225097656,
              "predictive_entropy": 0.07685897568069677,
              "shannon_entropy": 0.24798949480633325
            }
          },
          {
            "text": "Hilbert's fourteenth problem,",
            "logprob": -1.2319776449738242,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.37414929270744324
              },
              {
                "text": "bert",
                "logprob": -7.271740287251305e-06
              },
              {
                "text": "'",
                "logprob": -2.3603161025675945e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "four",
                "logprob": -0.00022849810193292797
              },
              {
                "text": "teenth",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "problem",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": ",",
                "logprob": -0.8575681447982788
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15399720104860393,
              "max_token_negative_log_likelihood": 0.857568085193634,
              "predictive_entropy": 0.07767521260038635,
              "shannon_entropy": 0.22388894340674348
            }
          },
          {
            "text": "Hilbert's fourteenth problem was",
            "logprob": -1.0444776449738242,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.37414929270744324
              },
              {
                "text": "bert",
                "logprob": -7.271740287251305e-06
              },
              {
                "text": "'",
                "logprob": -2.3603161025675945e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "four",
                "logprob": -0.00022849810193292797
              },
              {
                "text": "teenth",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "problem",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "was",
                "logprob": -0.6700681447982788
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.13055971594976512,
              "max_token_negative_log_likelihood": 0.6700682044029236,
              "predictive_entropy": 0.0750605095709922,
              "shannon_entropy": 0.22388894340674348
            }
          },
          {
            "text": "David Mumford and Jonathan Karp",
            "logprob": -14.411707101295178,
            "tokens": [
              {
                "text": "David",
                "logprob": -4.061649322509766
              },
              {
                "text": "M",
                "logprob": -3.082672595977783
              },
              {
                "text": "um",
                "logprob": -0.0061022634617984295
              },
              {
                "text": "ford",
                "logprob": -0.00011896379146492109
              },
              {
                "text": "and",
                "logprob": -1.6294313669204712
              },
              {
                "text": "Jonathan",
                "logprob": -2.5228044986724854
              },
              {
                "text": "Kar",
                "logprob": -3.0832200050354004
              },
              {
                "text": "p",
                "logprob": -0.025708084926009178
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.8014632815729783,
              "max_token_negative_log_likelihood": 4.061648845672607,
              "predictive_entropy": 0.11319756367083755,
              "shannon_entropy": 1.0323758305603405
            }
          },
          {
            "text": "Hilbert's fourteenth problem,",
            "logprob": -1.2319776449738242,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.37414929270744324
              },
              {
                "text": "bert",
                "logprob": -7.271740287251305e-06
              },
              {
                "text": "'",
                "logprob": -2.3603161025675945e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "four",
                "logprob": -0.00022849810193292797
              },
              {
                "text": "teenth",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "problem",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": ",",
                "logprob": -0.8575681447982788
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15399720104860393,
              "max_token_negative_log_likelihood": 0.857568085193634,
              "predictive_entropy": 0.07767521260038635,
              "shannon_entropy": 0.22388894340674348
            }
          }
        ],
        "cached": false,
        "request_time": 1.026937484741211,
        "request_datetime": 1755801559
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Bernstein's problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Sergei Natanovich Bernstein"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bernshtein Sergei Natanovich"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id29"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nBernstein's problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Bernstein's problem, specifically the",
            "logprob": -2.528705498221825,
            "tokens": [
              {
                "text": "Bern",
                "logprob": -0.009363781660795212
              },
              {
                "text": "stein",
                "logprob": -5.364403477869928e-06
              },
              {
                "text": "'",
                "logprob": -3.6477376852417365e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0010258655529469252
              },
              {
                "text": ",",
                "logprob": -0.3144031763076782
              },
              {
                "text": "specifically",
                "logprob": -1.5431931018829346
              },
              {
                "text": "the",
                "logprob": -0.6606777310371399
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3160881813942069,
              "max_token_negative_log_likelihood": 1.5431931018829346,
              "predictive_entropy": 0.1138682008773344,
              "shannon_entropy": 0.5170458622026537
            }
          },
          {
            "text": "Bernstein's problem, concerning the",
            "logprob": -2.0026216954174743,
            "tokens": [
              {
                "text": "Bern",
                "logprob": -0.009363781660795212
              },
              {
                "text": "stein",
                "logprob": -5.364403477869928e-06
              },
              {
                "text": "'",
                "logprob": -3.6477376852417365e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0010258655529469252
              },
              {
                "text": ",",
                "logprob": -0.3144031763076782
              },
              {
                "text": "concerning",
                "logprob": -1.6681931018829346
              },
              {
                "text": "the",
                "logprob": -0.00959392823278904
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2503277153568888,
              "max_token_negative_log_likelihood": 1.6681931018829346,
              "predictive_entropy": 0.07050384961127065,
              "shannon_entropy": 0.3365269393409882
            }
          },
          {
            "text": "Bernstein's problem, concerning the",
            "logprob": -2.0026216954174743,
            "tokens": [
              {
                "text": "Bern",
                "logprob": -0.009363781660795212
              },
              {
                "text": "stein",
                "logprob": -5.364403477869928e-06
              },
              {
                "text": "'",
                "logprob": -3.6477376852417365e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0010258655529469252
              },
              {
                "text": ",",
                "logprob": -0.3144031763076782
              },
              {
                "text": "concerning",
                "logprob": -1.6681931018829346
              },
              {
                "text": "the",
                "logprob": -0.00959392823278904
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2503277153568888,
              "max_token_negative_log_likelihood": 1.6681931018829346,
              "predictive_entropy": 0.07050384961127065,
              "shannon_entropy": 0.3365269393409882
            }
          },
          {
            "text": "Bernstein's problem, specifically the",
            "logprob": -2.528705498221825,
            "tokens": [
              {
                "text": "Bern",
                "logprob": -0.009363781660795212
              },
              {
                "text": "stein",
                "logprob": -5.364403477869928e-06
              },
              {
                "text": "'",
                "logprob": -3.6477376852417365e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0010258655529469252
              },
              {
                "text": ",",
                "logprob": -0.3144031763076782
              },
              {
                "text": "specifically",
                "logprob": -1.5431931018829346
              },
              {
                "text": "the",
                "logprob": -0.6606777310371399
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3160881813942069,
              "max_token_negative_log_likelihood": 1.5431931018829346,
              "predictive_entropy": 0.1138682008773344,
              "shannon_entropy": 0.5170458622026537
            }
          },
          {
            "text": "Bernstein's problem, concerning the",
            "logprob": -2.0026216954174743,
            "tokens": [
              {
                "text": "Bern",
                "logprob": -0.009363781660795212
              },
              {
                "text": "stein",
                "logprob": -5.364403477869928e-06
              },
              {
                "text": "'",
                "logprob": -3.6477376852417365e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0010258655529469252
              },
              {
                "text": ",",
                "logprob": -0.3144031763076782
              },
              {
                "text": "concerning",
                "logprob": -1.6681931018829346
              },
              {
                "text": "the",
                "logprob": -0.00959392823278904
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2503277153568888,
              "max_token_negative_log_likelihood": 1.6681931018829346,
              "predictive_entropy": 0.07050384961127065,
              "shannon_entropy": 0.3365269393409882
            }
          }
        ],
        "cached": false,
        "request_time": 1.020604133605957,
        "request_datetime": 1755801559
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Burnside's problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Alexei Kostrikin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Alexei Ivanovich Kostrikin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id30"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nBurnside's problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Burnside's problem was a famous",
            "logprob": -3.0451425439677564,
            "tokens": [
              {
                "text": "Burn",
                "logprob": -0.007203558459877968
              },
              {
                "text": "side",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "'",
                "logprob": 0.0
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0005398723296821117
              },
              {
                "text": "was",
                "logprob": -0.7484851479530334
              },
              {
                "text": "a",
                "logprob": -1.2906601428985596
              },
              {
                "text": "famous",
                "logprob": -0.9982534646987915
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.380642799245841,
              "max_token_negative_log_likelihood": 1.29066002368927,
              "predictive_entropy": 0.13558906951947236,
              "shannon_entropy": 0.5825718421751018
            }
          },
          {
            "text": "Burnside's problem, specifically concerning",
            "logprob": -5.514343631919417,
            "tokens": [
              {
                "text": "Burn",
                "logprob": -0.007203558459877968
              },
              {
                "text": "side",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "'",
                "logprob": 0.0
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0005398723296821117
              },
              {
                "text": ",",
                "logprob": -0.6859851479530334
              },
              {
                "text": "specifically",
                "logprob": -3.7296271324157715
              },
              {
                "text": "concerning",
                "logprob": -1.0909875631332397
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6892929054374761,
              "max_token_negative_log_likelihood": 3.7296266555786133,
              "predictive_entropy": 0.10113916622502828,
              "shannon_entropy": 0.48261704335746725
            }
          },
          {
            "text": "Burnside's problem was not solved",
            "logprob": -3.9963222569785444,
            "tokens": [
              {
                "text": "Burn",
                "logprob": -0.007203558459877968
              },
              {
                "text": "side",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "'",
                "logprob": 0.0
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0005398723296821117
              },
              {
                "text": "was",
                "logprob": -0.7484851479530334
              },
              {
                "text": "not",
                "logprob": -3.1031601428985596
              },
              {
                "text": "solved",
                "logprob": -0.13693317770957947
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4995402521963186,
              "max_token_negative_log_likelihood": 3.1031599044799805,
              "predictive_entropy": 0.07756882144166255,
              "shannon_entropy": 0.4312984872871395
            }
          },
          {
            "text": "Burnside's problem was historically",
            "logprob": -3.8281391984782474,
            "tokens": [
              {
                "text": "Burn",
                "logprob": -0.007203558459877968
              },
              {
                "text": "side",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "'",
                "logprob": 0.0
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0005398723296821117
              },
              {
                "text": "was",
                "logprob": -0.7484851479530334
              },
              {
                "text": "histor",
                "logprob": -3.0719101428985596
              },
              {
                "text": "ically",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.47851736615849383,
              "max_token_negative_log_likelihood": 3.0719099044799805,
              "predictive_entropy": 0.06301458815140748,
              "shannon_entropy": 0.3474525181025596
            }
          },
          {
            "text": "Burnside's problem, a question",
            "logprob": -3.424633992370161,
            "tokens": [
              {
                "text": "Burn",
                "logprob": -0.007203558459877968
              },
              {
                "text": "side",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "'",
                "logprob": 0.0
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -0.0005398723296821117
              },
              {
                "text": ",",
                "logprob": -0.6859851479530334
              },
              {
                "text": "a",
                "logprob": -1.2608771324157715
              },
              {
                "text": "question",
                "logprob": -1.4700279235839844
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4280792302961416,
              "max_token_negative_log_likelihood": 1.4700278043746948,
              "predictive_entropy": 0.1310595486502173,
              "shannon_entropy": 0.5046005476528164
            }
          }
        ],
        "cached": false,
        "request_time": 0.946782112121582,
        "request_datetime": 1755801560
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Kutta\u2013Joukowski theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Nikolay Zhukovsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Zhukovski\u012d, Nikola\u012d Egorovich, 1847-1921"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Nikola\u012d Egorovich Zhukovski\u012d"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Nikolay Yegorovich Zhukovsky"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id31"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nKutta\u2013Joukowski theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Kutta\u2013Joukow",
            "logprob": -0.016631404338113498,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.0064794453792274
              },
              {
                "text": "K",
                "logprob": -2.6702524337451905e-05
              },
              {
                "text": "ut",
                "logprob": 0.0
              },
              {
                "text": "ta",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.00945719238370657
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "kow",
                "logprob": -0.0006680640508420765
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002078928629089205,
              "max_token_negative_log_likelihood": 0.009457165375351906,
              "predictive_entropy": 0.002062514721728803,
              "shannon_entropy": 0.014492019684331225
            }
          },
          {
            "text": "The Kutta\u2013Joukow",
            "logprob": -0.016631404338113498,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.0064794453792274
              },
              {
                "text": "K",
                "logprob": -2.6702524337451905e-05
              },
              {
                "text": "ut",
                "logprob": 0.0
              },
              {
                "text": "ta",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.00945719238370657
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "kow",
                "logprob": -0.0006680640508420765
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002078928629089205,
              "max_token_negative_log_likelihood": 0.009457165375351906,
              "predictive_entropy": 0.002062514721728803,
              "shannon_entropy": 0.014492019684331225
            }
          },
          {
            "text": "The Kutta\u2013Joukow",
            "logprob": -0.016631404338113498,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.0064794453792274
              },
              {
                "text": "K",
                "logprob": -2.6702524337451905e-05
              },
              {
                "text": "ut",
                "logprob": 0.0
              },
              {
                "text": "ta",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.00945719238370657
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "kow",
                "logprob": -0.0006680640508420765
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002078928629089205,
              "max_token_negative_log_likelihood": 0.009457165375351906,
              "predictive_entropy": 0.002062514721728803,
              "shannon_entropy": 0.014492019684331225
            }
          },
          {
            "text": "The Kutta\u2013Joukow",
            "logprob": -0.016631404338113498,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.0064794453792274
              },
              {
                "text": "K",
                "logprob": -2.6702524337451905e-05
              },
              {
                "text": "ut",
                "logprob": 0.0
              },
              {
                "text": "ta",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.00945719238370657
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "kow",
                "logprob": -0.0006680640508420765
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002078928629089205,
              "max_token_negative_log_likelihood": 0.009457165375351906,
              "predictive_entropy": 0.002062514721728803,
              "shannon_entropy": 0.014492019684331225
            }
          },
          {
            "text": "The Kutta\u2013Joukow",
            "logprob": -0.016631404338113498,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.0064794453792274
              },
              {
                "text": "K",
                "logprob": -2.6702524337451905e-05
              },
              {
                "text": "ut",
                "logprob": 0.0
              },
              {
                "text": "ta",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.00945719238370657
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "kow",
                "logprob": -0.0006680640508420765
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002078928629089205,
              "max_token_negative_log_likelihood": 0.009457165375351906,
              "predictive_entropy": 0.002062514721728803,
              "shannon_entropy": 0.014492019684331225
            }
          }
        ],
        "cached": false,
        "request_time": 1.083207130432129,
        "request_datetime": 1755801560
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "law of large numbers was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Pafnuty Chebyshev"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Pafnuty Lvovich Chebyshev"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id32"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nlaw of large numbers was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The law of large numbers is a fundamental",
            "logprob": -2.3811882333828294,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.006309707649052143
              },
              {
                "text": "law",
                "logprob": -0.16309839487075806
              },
              {
                "text": "of",
                "logprob": 0.0
              },
              {
                "text": "large",
                "logprob": 0.0
              },
              {
                "text": "numbers",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "is",
                "logprob": -1.5498378276824951
              },
              {
                "text": "a",
                "logprob": -0.5777947902679443
              },
              {
                "text": "fundamental",
                "logprob": -0.08414691686630249
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.297648522187977,
              "max_token_negative_log_likelihood": 1.5498378276824951,
              "predictive_entropy": 0.1094254585332024,
              "shannon_entropy": 0.4145418131537779
            }
          },
          {
            "text": "The law of large numbers, one of",
            "logprob": -4.2453837590274475,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.006309707649052143
              },
              {
                "text": "law",
                "logprob": -0.16309839487075806
              },
              {
                "text": "of",
                "logprob": 0.0
              },
              {
                "text": "large",
                "logprob": 0.0
              },
              {
                "text": "numbers",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": ",",
                "logprob": -2.424837827682495
              },
              {
                "text": "one",
                "logprob": -1.6511354446411133
              },
              {
                "text": "of",
                "logprob": -1.7881377516459906e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5306729433361781,
              "max_token_negative_log_likelihood": 2.424837827682495,
              "predictive_entropy": 0.0845182700429703,
              "shannon_entropy": 0.32063196211349787
            }
          },
          {
            "text": "The law of large numbers was solved by",
            "logprob": -1.2647203924132668,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.006309707649052143
              },
              {
                "text": "law",
                "logprob": -0.16309839487075806
              },
              {
                "text": "of",
                "logprob": 0.0
              },
              {
                "text": "large",
                "logprob": 0.0
              },
              {
                "text": "numbers",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "was",
                "logprob": -0.3623378574848175
              },
              {
                "text": "solved",
                "logprob": -0.6089500784873962
              },
              {
                "text": "by",
                "logprob": -0.12402375787496567
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15809005138000742,
              "max_token_negative_log_likelihood": 0.6089500784873962,
              "predictive_entropy": 0.10472585487875818,
              "shannon_entropy": 0.4672987634129866
            }
          },
          {
            "text": "The law of large numbers was solved by",
            "logprob": -1.2647203924132668,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.006309707649052143
              },
              {
                "text": "law",
                "logprob": -0.16309839487075806
              },
              {
                "text": "of",
                "logprob": 0.0
              },
              {
                "text": "large",
                "logprob": 0.0
              },
              {
                "text": "numbers",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "was",
                "logprob": -0.3623378574848175
              },
              {
                "text": "solved",
                "logprob": -0.6089500784873962
              },
              {
                "text": "by",
                "logprob": -0.12402375787496567
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15809005138000742,
              "max_token_negative_log_likelihood": 0.6089500784873962,
              "predictive_entropy": 0.10472585487875818,
              "shannon_entropy": 0.4672987634129866
            }
          },
          {
            "text": "The law of large numbers was not solved",
            "logprob": -2.833766196854242,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.006309707649052143
              },
              {
                "text": "law",
                "logprob": -0.16309839487075806
              },
              {
                "text": "of",
                "logprob": 0.0
              },
              {
                "text": "large",
                "logprob": 0.0
              },
              {
                "text": "numbers",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "was",
                "logprob": -0.3623378574848175
              },
              {
                "text": "not",
                "logprob": -2.077700138092041
              },
              {
                "text": "solved",
                "logprob": -0.22431950271129608
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.35422074247619406,
              "max_token_negative_log_likelihood": 2.077699899673462,
              "predictive_entropy": 0.10455475508931755,
              "shannon_entropy": 0.4931202778406485
            }
          }
        ],
        "cached": false,
        "request_time": 1.076967477798462,
        "request_datetime": 1755801560
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Cook\u2013Levin theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Leonid Levin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Leonid Anatolievich Levin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id33"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nCook\u2013Levin theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Cook\u2013Levin theorem, also",
            "logprob": -1.13322288476391,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.0014058002270758152
              },
              {
                "text": "Cook",
                "logprob": -6.425174069590867e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.16491271555423737
              },
              {
                "text": "Le",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "vin",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "theorem",
                "logprob": -4.303362584323622e-05
              },
              {
                "text": ",",
                "logprob": -0.1721610128879547
              },
              {
                "text": "also",
                "logprob": -0.7946352362632751
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1416528606455607,
              "max_token_negative_log_likelihood": 0.7946352362632751,
              "predictive_entropy": 0.08065731367057438,
              "shannon_entropy": 0.25142065983828843
            }
          },
          {
            "text": "The Cook\u2013Levin theorem, also",
            "logprob": -1.13322288476391,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.0014058002270758152
              },
              {
                "text": "Cook",
                "logprob": -6.425174069590867e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.16491271555423737
              },
              {
                "text": "Le",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "vin",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "theorem",
                "logprob": -4.303362584323622e-05
              },
              {
                "text": ",",
                "logprob": -0.1721610128879547
              },
              {
                "text": "also",
                "logprob": -0.7946352362632751
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1416528606455607,
              "max_token_negative_log_likelihood": 0.7946352362632751,
              "predictive_entropy": 0.08065731367057438,
              "shannon_entropy": 0.25142065983828843
            }
          },
          {
            "text": "The Cook\u2013Levin theorem, also",
            "logprob": -1.13322288476391,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.0014058002270758152
              },
              {
                "text": "Cook",
                "logprob": -6.425174069590867e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.16491271555423737
              },
              {
                "text": "Le",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "vin",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "theorem",
                "logprob": -4.303362584323622e-05
              },
              {
                "text": ",",
                "logprob": -0.1721610128879547
              },
              {
                "text": "also",
                "logprob": -0.7946352362632751
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1416528606455607,
              "max_token_negative_log_likelihood": 0.7946352362632751,
              "predictive_entropy": 0.08065731367057438,
              "shannon_entropy": 0.25142065983828843
            }
          },
          {
            "text": "The Cook\u2013Levin theorem, also",
            "logprob": -1.13322288476391,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.0014058002270758152
              },
              {
                "text": "Cook",
                "logprob": -6.425174069590867e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.16491271555423737
              },
              {
                "text": "Le",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "vin",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "theorem",
                "logprob": -4.303362584323622e-05
              },
              {
                "text": ",",
                "logprob": -0.1721610128879547
              },
              {
                "text": "also",
                "logprob": -0.7946352362632751
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1416528606455607,
              "max_token_negative_log_likelihood": 0.7946352362632751,
              "predictive_entropy": 0.08065731367057438,
              "shannon_entropy": 0.25142065983828843
            }
          },
          {
            "text": "The Cook\u2013Levin theorem, also",
            "logprob": -1.13322288476391,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.0014058002270758152
              },
              {
                "text": "Cook",
                "logprob": -6.425174069590867e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.16491271555423737
              },
              {
                "text": "Le",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "vin",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "theorem",
                "logprob": -4.303362584323622e-05
              },
              {
                "text": ",",
                "logprob": -0.1721610128879547
              },
              {
                "text": "also",
                "logprob": -0.7946352362632751
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1416528606455607,
              "max_token_negative_log_likelihood": 0.7946352362632751,
              "predictive_entropy": 0.08065731367057438,
              "shannon_entropy": 0.25142065983828843
            }
          }
        ],
        "cached": false,
        "request_time": 1.0138039588928223,
        "request_datetime": 1755801560
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Krein\u2013\u0160mulian theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Vitold Shmulyan"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Vitold Lvovich Shmulyan"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id34"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nKrein\u2013\u0160mulian theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Krein\u2013\u0160mulian theorem",
            "logprob": -0.10480716491883157,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.10439106822013855
              },
              {
                "text": "Kre",
                "logprob": -0.0003526780928950757
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -2.932505594799295e-05
              },
              {
                "text": "\u0160",
                "logprob": -6.556489552167477e-06
              },
              {
                "text": "mul",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ian",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "theorem",
                "logprob": -2.3603161025675945e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.013100893652508105,
              "max_token_negative_log_likelihood": 0.10439104586839676,
              "predictive_entropy": 0.011807380763002584,
              "shannon_entropy": 0.04996432359399705
            }
          },
          {
            "text": "The Krein\u2013\u0160mulian theorem",
            "logprob": -0.10480716491883157,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.10439106822013855
              },
              {
                "text": "Kre",
                "logprob": -0.0003526780928950757
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -2.932505594799295e-05
              },
              {
                "text": "\u0160",
                "logprob": -6.556489552167477e-06
              },
              {
                "text": "mul",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ian",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "theorem",
                "logprob": -2.3603161025675945e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.013100893652508105,
              "max_token_negative_log_likelihood": 0.10439104586839676,
              "predictive_entropy": 0.011807380763002584,
              "shannon_entropy": 0.04996432359399705
            }
          },
          {
            "text": "The Krein\u2013\u0160mulian theorem",
            "logprob": -0.10480716491883157,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.10439106822013855
              },
              {
                "text": "Kre",
                "logprob": -0.0003526780928950757
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -2.932505594799295e-05
              },
              {
                "text": "\u0160",
                "logprob": -6.556489552167477e-06
              },
              {
                "text": "mul",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ian",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "theorem",
                "logprob": -2.3603161025675945e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.013100893652508105,
              "max_token_negative_log_likelihood": 0.10439104586839676,
              "predictive_entropy": 0.011807380763002584,
              "shannon_entropy": 0.04996432359399705
            }
          },
          {
            "text": "The Krein\u2013\u0160mulian theorem",
            "logprob": -0.10480716491883157,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.10439106822013855
              },
              {
                "text": "Kre",
                "logprob": -0.0003526780928950757
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -2.932505594799295e-05
              },
              {
                "text": "\u0160",
                "logprob": -6.556489552167477e-06
              },
              {
                "text": "mul",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ian",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "theorem",
                "logprob": -2.3603161025675945e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.013100893652508105,
              "max_token_negative_log_likelihood": 0.10439104586839676,
              "predictive_entropy": 0.011807380763002584,
              "shannon_entropy": 0.04996432359399705
            }
          },
          {
            "text": "The Krein\u2013\u0160mulian theorem",
            "logprob": -0.10480716491883157,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.10439106822013855
              },
              {
                "text": "Kre",
                "logprob": -0.0003526780928950757
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -2.932505594799295e-05
              },
              {
                "text": "\u0160",
                "logprob": -6.556489552167477e-06
              },
              {
                "text": "mul",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ian",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "theorem",
                "logprob": -2.3603161025675945e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.013100893652508105,
              "max_token_negative_log_likelihood": 0.10439104586839676,
              "predictive_entropy": 0.011807380763002584,
              "shannon_entropy": 0.04996432359399705
            }
          }
        ],
        "cached": false,
        "request_time": 0.9959354400634766,
        "request_datetime": 1755801561
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "gap theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Boris Trakhtenbrot"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boris Avraamovich Trakhtenbrot"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boris A. Trakhtenbrot"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boaz Trakhtenbrot"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boris Avraamovi\u010d Trachtenbrot"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Allan Borodin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Allan Bertram Borodin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id35"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\ngap theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Gap Theorem, often associated within",
            "logprob": -10.016617289365968,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.004456469789147377
              },
              {
                "text": "G",
                "logprob": -0.5695962905883789
              },
              {
                "text": "ap",
                "logprob": -0.000169382052263245
              },
              {
                "text": "Theorem",
                "logprob": -0.036905910819768906
              },
              {
                "text": ",",
                "logprob": -0.32956990599632263
              },
              {
                "text": "often",
                "logprob": -1.940745234489441
              },
              {
                "text": "associated",
                "logprob": -0.7497156262397766
              },
              {
                "text": "within",
                "logprob": -6.385458469390869
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.2520763573593285,
              "max_token_negative_log_likelihood": 6.3854522705078125,
              "predictive_entropy": 0.1553943820290442,
              "shannon_entropy": 0.7344954177096952
            }
          },
          {
            "text": "The Gap Theorem in computational complexity theory",
            "logprob": -3.044680703053018,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.004456469789147377
              },
              {
                "text": "G",
                "logprob": -0.5695962905883789
              },
              {
                "text": "ap",
                "logprob": -0.000169382052263245
              },
              {
                "text": "Theorem",
                "logprob": -0.036905910819768906
              },
              {
                "text": "in",
                "logprob": -1.923319935798645
              },
              {
                "text": "computational",
                "logprob": -0.07681360095739365
              },
              {
                "text": "complexity",
                "logprob": -0.009386573918163776
              },
              {
                "text": "theory",
                "logprob": -0.4240325391292572
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.38058507732421276,
              "max_token_negative_log_likelihood": 1.9233198165893555,
              "predictive_entropy": 0.12517307111920672,
              "shannon_entropy": 0.4521996258117724
            }
          },
          {
            "text": "The Gap Theorem, formally known as",
            "logprob": -5.128903609322151,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.004456469789147377
              },
              {
                "text": "G",
                "logprob": -0.5695962905883789
              },
              {
                "text": "ap",
                "logprob": -0.000169382052263245
              },
              {
                "text": "Theorem",
                "logprob": -0.036905910819768906
              },
              {
                "text": ",",
                "logprob": -0.32956990599632263
              },
              {
                "text": "formally",
                "logprob": -4.0657453536987305
              },
              {
                "text": "known",
                "logprob": -0.11588788032531738
              },
              {
                "text": "as",
                "logprob": -0.006572416052222252
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6411128921790805,
              "max_token_negative_log_likelihood": 4.065744876861572,
              "predictive_entropy": 0.09736601310942206,
              "shannon_entropy": 0.6047158311412204
            }
          },
          {
            "text": "The gap theorem, also known as the",
            "logprob": -3.1448274933427456,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.004456469789147377
              },
              {
                "text": "gap",
                "logprob": -1.257096290588379
              },
              {
                "text": "theorem",
                "logprob": -9.77468371274881e-05
              },
              {
                "text": ",",
                "logprob": -0.5003888010978699
              },
              {
                "text": "also",
                "logprob": -1.2285553216934204
              },
              {
                "text": "known",
                "logprob": -0.05703213810920715
              },
              {
                "text": "as",
                "logprob": -0.028408844023942947
              },
              {
                "text": "the",
                "logprob": -0.06879188120365143
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3931034474671833,
              "max_token_negative_log_likelihood": 1.257096290588379,
              "predictive_entropy": 0.146356750963605,
              "shannon_entropy": 0.6465205800341209
            }
          },
          {
            "text": "The Gap Theorem is attributed to the",
            "logprob": -6.853581740608206,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.004456469789147377
              },
              {
                "text": "G",
                "logprob": -0.5695962905883789
              },
              {
                "text": "ap",
                "logprob": -0.000169382052263245
              },
              {
                "text": "Theorem",
                "logprob": -0.036905910819768906
              },
              {
                "text": "is",
                "logprob": -2.8608198165893555
              },
              {
                "text": "attributed",
                "logprob": -3.1107563972473145
              },
              {
                "text": "to",
                "logprob": -0.002001189161092043
              },
              {
                "text": "the",
                "logprob": -0.2688762843608856
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8566976527981751,
              "max_token_negative_log_likelihood": 3.1107561588287354,
              "predictive_entropy": 0.10903096136098611,
              "shannon_entropy": 0.5975806960195769
            }
          }
        ],
        "cached": false,
        "request_time": 0.9986135959625244,
        "request_datetime": 1755801561
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Rademacher\u2013Menchov theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Dmitrii Menshov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Dmitrii Evgenevich Menshov"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id36"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nRademacher\u2013Menchov theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Rademacher\u2013Menchov",
            "logprob": -0.03731281735234404,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.006720203906297684
              },
              {
                "text": "R",
                "logprob": -0.0008288762182928622
              },
              {
                "text": "adem",
                "logprob": 0.0
              },
              {
                "text": "acher",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0012850845232605934
              },
              {
                "text": "Men",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ch",
                "logprob": -0.02450544200837612
              },
              {
                "text": "ov",
                "logprob": -0.003972972277551889
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00466408900684101,
              "max_token_negative_log_likelihood": 0.024505412206053734,
              "predictive_entropy": 0.004582049405144062,
              "shannon_entropy": 0.03028245958108089
            }
          },
          {
            "text": "The Rademacher\u2013Menchov",
            "logprob": -0.03731281735234404,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.006720203906297684
              },
              {
                "text": "R",
                "logprob": -0.0008288762182928622
              },
              {
                "text": "adem",
                "logprob": 0.0
              },
              {
                "text": "acher",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0012850845232605934
              },
              {
                "text": "Men",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ch",
                "logprob": -0.02450544200837612
              },
              {
                "text": "ov",
                "logprob": -0.003972972277551889
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00466408900684101,
              "max_token_negative_log_likelihood": 0.024505412206053734,
              "predictive_entropy": 0.004582049405144062,
              "shannon_entropy": 0.03028245958108089
            }
          },
          {
            "text": "The Rademacher\u2013Menchov",
            "logprob": -0.03731281735234404,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.006720203906297684
              },
              {
                "text": "R",
                "logprob": -0.0008288762182928622
              },
              {
                "text": "adem",
                "logprob": 0.0
              },
              {
                "text": "acher",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0012850845232605934
              },
              {
                "text": "Men",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ch",
                "logprob": -0.02450544200837612
              },
              {
                "text": "ov",
                "logprob": -0.003972972277551889
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00466408900684101,
              "max_token_negative_log_likelihood": 0.024505412206053734,
              "predictive_entropy": 0.004582049405144062,
              "shannon_entropy": 0.03028245958108089
            }
          },
          {
            "text": "The Rademacher\u2013Menchov",
            "logprob": -0.03731281735234404,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.006720203906297684
              },
              {
                "text": "R",
                "logprob": -0.0008288762182928622
              },
              {
                "text": "adem",
                "logprob": 0.0
              },
              {
                "text": "acher",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0012850845232605934
              },
              {
                "text": "Men",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ch",
                "logprob": -0.02450544200837612
              },
              {
                "text": "ov",
                "logprob": -0.003972972277551889
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00466408900684101,
              "max_token_negative_log_likelihood": 0.024505412206053734,
              "predictive_entropy": 0.004582049405144062,
              "shannon_entropy": 0.03028245958108089
            }
          },
          {
            "text": "The Rademacher\u2013Menchov",
            "logprob": -0.03731281735234404,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.006720203906297684
              },
              {
                "text": "R",
                "logprob": -0.0008288762182928622
              },
              {
                "text": "adem",
                "logprob": 0.0
              },
              {
                "text": "acher",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0012850845232605934
              },
              {
                "text": "Men",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ch",
                "logprob": -0.02450544200837612
              },
              {
                "text": "ov",
                "logprob": -0.003972972277551889
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00466408900684101,
              "max_token_negative_log_likelihood": 0.024505412206053734,
              "predictive_entropy": 0.004582049405144062,
              "shannon_entropy": 0.03028245958108089
            }
          }
        ],
        "cached": false,
        "request_time": 1.0005755424499512,
        "request_datetime": 1755801561
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "geometrization conjecture was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Grigori Perelman"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Grigori Yakovlevich Perelman"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id37"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\ngeometrization conjecture was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The geometrization conjecture was solved",
            "logprob": -0.7245491128413732,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.47570931911468506
              },
              {
                "text": "geomet",
                "logprob": -0.022688215598464012
              },
              {
                "text": "riz",
                "logprob": 0.0
              },
              {
                "text": "ation",
                "logprob": 0.0
              },
              {
                "text": "conject",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "ure",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -0.19648608565330505
              },
              {
                "text": "solved",
                "logprob": -0.029665015637874603
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09056863537990978,
              "max_token_negative_log_likelihood": 0.47570931911468506,
              "predictive_entropy": 0.06350498436948726,
              "shannon_entropy": 0.19419125708985713
            }
          },
          {
            "text": "Grigori Perelman\n\n",
            "logprob": -1.5043852155540094,
            "tokens": [
              {
                "text": "Gr",
                "logprob": -1.038209319114685
              },
              {
                "text": "ig",
                "logprob": -2.4676019165781327e-05
              },
              {
                "text": "ori",
                "logprob": -0.0032968949526548386
              },
              {
                "text": "Per",
                "logprob": -7.629365427419543e-06
              },
              {
                "text": "el",
                "logprob": -1.0609570381348021e-05
              },
              {
                "text": "man",
                "logprob": -2.0861407392658293e-05
              },
              {
                "text": "\n",
                "logprob": -0.4628148674964905
              },
              {
                "text": "\n",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.18804817342925872,
              "max_token_negative_log_likelihood": 1.0382094383239746,
              "predictive_entropy": 0.08278926096362582,
              "shannon_entropy": 0.20349633950741008
            }
          },
          {
            "text": "Perelman's solution to the",
            "logprob": -5.447185418539448,
            "tokens": [
              {
                "text": "Per",
                "logprob": -4.069459438323975
              },
              {
                "text": "el",
                "logprob": -5.173549288883805e-05
              },
              {
                "text": "man",
                "logprob": -2.0146166207268834e-05
              },
              {
                "text": "'",
                "logprob": -0.12793637812137604
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "solution",
                "logprob": -1.1849292516708374
              },
              {
                "text": "to",
                "logprob": -0.0633656457066536
              },
              {
                "text": "the",
                "logprob": -0.0014228230575099587
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6808981178364775,
              "max_token_negative_log_likelihood": 4.069458961486816,
              "predictive_entropy": 0.07567332878193156,
              "shannon_entropy": 0.38810509165849294
            }
          },
          {
            "text": "Grigori Perelman\n\n",
            "logprob": -1.5043852155540094,
            "tokens": [
              {
                "text": "Gr",
                "logprob": -1.038209319114685
              },
              {
                "text": "ig",
                "logprob": -2.4676019165781327e-05
              },
              {
                "text": "ori",
                "logprob": -0.0032968949526548386
              },
              {
                "text": "Per",
                "logprob": -7.629365427419543e-06
              },
              {
                "text": "el",
                "logprob": -1.0609570381348021e-05
              },
              {
                "text": "man",
                "logprob": -2.0861407392658293e-05
              },
              {
                "text": "\n",
                "logprob": -0.4628148674964905
              },
              {
                "text": "\n",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.18804817342925872,
              "max_token_negative_log_likelihood": 1.0382094383239746,
              "predictive_entropy": 0.08278926096362582,
              "shannon_entropy": 0.20349633950741008
            }
          },
          {
            "text": "Perelman's work on the",
            "logprob": -6.018267685867613,
            "tokens": [
              {
                "text": "Per",
                "logprob": -4.069459438323975
              },
              {
                "text": "el",
                "logprob": -5.173549288883805e-05
              },
              {
                "text": "man",
                "logprob": -2.0146166207268834e-05
              },
              {
                "text": "'",
                "logprob": -0.12793637812137604
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -1.7786792516708374
              },
              {
                "text": "on",
                "logprob": -0.03135363385081291
              },
              {
                "text": "the",
                "logprob": -0.010767102241516113
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.7522834072187834,
              "max_token_negative_log_likelihood": 4.069458961486816,
              "predictive_entropy": 0.06544560931456544,
              "shannon_entropy": 0.3907665289203426
            }
          }
        ],
        "cached": false,
        "request_time": 1.0112473964691162,
        "request_datetime": 1755801561
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Ratner's theorems was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Marina Ratner"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Marina Evseevna Ratner"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id38"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nRatner's theorems was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Ratner's theorems were",
            "logprob": -0.4364645869809465,
            "tokens": [
              {
                "text": "Rat",
                "logprob": -0.02401350624859333
              },
              {
                "text": "ner",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -2.2172682292875834e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "the",
                "logprob": -0.032557420432567596
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ems",
                "logprob": 0.0
              },
              {
                "text": "were",
                "logprob": -0.3798714876174927
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.054558074830993064,
              "max_token_negative_log_likelihood": 0.3798714876174927,
              "predictive_entropy": 0.039349155702666394,
              "shannon_entropy": 0.17118007537221014
            }
          },
          {
            "text": "Ratner's theorems were",
            "logprob": -0.4364645869809465,
            "tokens": [
              {
                "text": "Rat",
                "logprob": -0.02401350624859333
              },
              {
                "text": "ner",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -2.2172682292875834e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "the",
                "logprob": -0.032557420432567596
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ems",
                "logprob": 0.0
              },
              {
                "text": "were",
                "logprob": -0.3798714876174927
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.054558074830993064,
              "max_token_negative_log_likelihood": 0.3798714876174927,
              "predictive_entropy": 0.039349155702666394,
              "shannon_entropy": 0.17118007537221014
            }
          },
          {
            "text": "Ratner's theorems were",
            "logprob": -0.4364645869809465,
            "tokens": [
              {
                "text": "Rat",
                "logprob": -0.02401350624859333
              },
              {
                "text": "ner",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -2.2172682292875834e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "the",
                "logprob": -0.032557420432567596
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ems",
                "logprob": 0.0
              },
              {
                "text": "were",
                "logprob": -0.3798714876174927
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.054558074830993064,
              "max_token_negative_log_likelihood": 0.3798714876174927,
              "predictive_entropy": 0.039349155702666394,
              "shannon_entropy": 0.17118007537221014
            }
          },
          {
            "text": "Ratner's theorems,",
            "logprob": -1.7489645869809465,
            "tokens": [
              {
                "text": "Rat",
                "logprob": -0.02401350624859333
              },
              {
                "text": "ner",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -2.2172682292875834e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "the",
                "logprob": -0.032557420432567596
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ems",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -1.6923714876174927
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.21862055992983187,
              "max_token_negative_log_likelihood": 1.6923713684082031,
              "predictive_entropy": 0.04581453857667839,
              "shannon_entropy": 0.17118007537221014
            }
          },
          {
            "text": "Ratner's theorems were",
            "logprob": -0.4364645869809465,
            "tokens": [
              {
                "text": "Rat",
                "logprob": -0.02401350624859333
              },
              {
                "text": "ner",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -2.2172682292875834e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "the",
                "logprob": -0.032557420432567596
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "ems",
                "logprob": 0.0
              },
              {
                "text": "were",
                "logprob": -0.3798714876174927
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.054558074830993064,
              "max_token_negative_log_likelihood": 0.3798714876174927,
              "predictive_entropy": 0.039349155702666394,
              "shannon_entropy": 0.17118007537221014
            }
          }
        ],
        "cached": false,
        "request_time": 1.022306203842163,
        "request_datetime": 1755801562
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Gromov's theorem on groups of polynomial growth was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Mikhail Gromov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Misha Gromov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mikhail Leonidovich Gromov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mikhael Gromov"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id39"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nGromov's theorem on groups of polynomial growth was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Mikhail Gromov is known",
            "logprob": -3.758024368434967,
            "tokens": [
              {
                "text": "Mik",
                "logprob": -0.7800143361091614
              },
              {
                "text": "h",
                "logprob": 0.0
              },
              {
                "text": "ail",
                "logprob": 0.0
              },
              {
                "text": "G",
                "logprob": -0.0005390383303165436
              },
              {
                "text": "rom",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "is",
                "logprob": -1.2258480787277222
              },
              {
                "text": "known",
                "logprob": -1.751622200012207
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4697530302146564,
              "max_token_negative_log_likelihood": 1.7516220808029175,
              "predictive_entropy": 0.12772344472612218,
              "shannon_entropy": 0.604233917054827
            }
          },
          {
            "text": "Mikhail Gromov is known",
            "logprob": -3.758024368434967,
            "tokens": [
              {
                "text": "Mik",
                "logprob": -0.7800143361091614
              },
              {
                "text": "h",
                "logprob": 0.0
              },
              {
                "text": "ail",
                "logprob": 0.0
              },
              {
                "text": "G",
                "logprob": -0.0005390383303165436
              },
              {
                "text": "rom",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "is",
                "logprob": -1.2258480787277222
              },
              {
                "text": "known",
                "logprob": -1.751622200012207
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4697530302146564,
              "max_token_negative_log_likelihood": 1.7516220808029175,
              "predictive_entropy": 0.12772344472612218,
              "shannon_entropy": 0.604233917054827
            }
          },
          {
            "text": "Gromov's theorem on groups",
            "logprob": -0.90836532923867,
            "tokens": [
              {
                "text": "G",
                "logprob": -0.9050143361091614
              },
              {
                "text": "rom",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "ov",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "'",
                "logprob": -0.0008320921915583313
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.002222807612270117
              },
              {
                "text": "on",
                "logprob": -0.00011729506513802335
              },
              {
                "text": "groups",
                "logprob": -0.0001770101225702092
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.11354566813878542,
              "max_token_negative_log_likelihood": 0.9050143957138062,
              "predictive_entropy": 0.046182028460677316,
              "shannon_entropy": 0.14523239973786684
            }
          },
          {
            "text": "Mikhail Gromov. Mik",
            "logprob": -5.116855297237457,
            "tokens": [
              {
                "text": "Mik",
                "logprob": -0.7800143361091614
              },
              {
                "text": "h",
                "logprob": 0.0
              },
              {
                "text": "ail",
                "logprob": 0.0
              },
              {
                "text": "G",
                "logprob": -0.0005390383303165436
              },
              {
                "text": "rom",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": ".",
                "logprob": -1.2883480787277222
              },
              {
                "text": "Mik",
                "logprob": -3.0479531288146973
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6396069112161289,
              "max_token_negative_log_likelihood": 3.0479531288146973,
              "predictive_entropy": 0.10724650184418039,
              "shannon_entropy": 0.5652862454029868
            }
          },
          {
            "text": "Gromov's theorem on groups",
            "logprob": -0.90836532923867,
            "tokens": [
              {
                "text": "G",
                "logprob": -0.9050143361091614
              },
              {
                "text": "rom",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "ov",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "'",
                "logprob": -0.0008320921915583313
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.002222807612270117
              },
              {
                "text": "on",
                "logprob": -0.00011729506513802335
              },
              {
                "text": "groups",
                "logprob": -0.0001770101225702092
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.11354566813878542,
              "max_token_negative_log_likelihood": 0.9050143957138062,
              "predictive_entropy": 0.046182028460677316,
              "shannon_entropy": 0.14523239973786684
            }
          }
        ],
        "cached": false,
        "request_time": 1.0205600261688232,
        "request_datetime": 1755801562
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Road coloring problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Avraham Trahtman"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Abram Naumovich Trakhtman"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Avraham Naumovich Trahtman"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id40"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nRoad coloring problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Road Colorings problem, often associated",
            "logprob": -7.789332256652415,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01166664157062769
              },
              {
                "text": "Road",
                "logprob": -0.1005207896232605
              },
              {
                "text": "Color",
                "logprob": -0.36737823486328125
              },
              {
                "text": "ings",
                "logprob": -1.7535114288330078
              },
              {
                "text": "problem",
                "logprob": -2.0101962089538574
              },
              {
                "text": ",",
                "logprob": -0.5619745254516602
              },
              {
                "text": "often",
                "logprob": -1.9991081953048706
              },
              {
                "text": "associated",
                "logprob": -0.9849762320518494
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.9736664572264999,
              "max_token_negative_log_likelihood": 2.0101959705352783,
              "predictive_entropy": 0.23610044037923217,
              "shannon_entropy": 1.1242860546335578
            }
          },
          {
            "text": "The Road Colorings problem, when fr",
            "logprob": -15.119228885509074,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01166664157062769
              },
              {
                "text": "Road",
                "logprob": -0.1005207896232605
              },
              {
                "text": "Color",
                "logprob": -0.36737823486328125
              },
              {
                "text": "ings",
                "logprob": -1.7535114288330078
              },
              {
                "text": "problem",
                "logprob": -2.0101962089538574
              },
              {
                "text": ",",
                "logprob": -0.5619745254516602
              },
              {
                "text": "when",
                "logprob": -5.46785831451416
              },
              {
                "text": "fr",
                "logprob": -4.846122741699219
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.8899030887987465,
              "max_token_negative_log_likelihood": 5.467855930328369,
              "predictive_entropy": 0.16391689679585397,
              "shannon_entropy": 1.1115980735048652
            }
          },
          {
            "text": "The Road Coloring Problem, a variant",
            "logprob": -6.7452773249242455,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01166664157062769
              },
              {
                "text": "Road",
                "logprob": -0.1005207896232605
              },
              {
                "text": "Color",
                "logprob": -0.36737823486328125
              },
              {
                "text": "ing",
                "logprob": -0.503511369228363
              },
              {
                "text": "Problem",
                "logprob": -0.0006083783227950335
              },
              {
                "text": ",",
                "logprob": -0.5226068496704102
              },
              {
                "text": "a",
                "logprob": -3.562346935272217
              },
              {
                "text": "variant",
                "logprob": -1.676638126373291
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8431596072259708,
              "max_token_negative_log_likelihood": 3.5623466968536377,
              "predictive_entropy": 0.17328694432217162,
              "shannon_entropy": 1.0325548759428784
            }
          },
          {
            "text": "The Road Coloring Problem, which concerns",
            "logprob": -4.8647045290563256,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01166664157062769
              },
              {
                "text": "Road",
                "logprob": -0.1005207896232605
              },
              {
                "text": "Color",
                "logprob": -0.36737823486328125
              },
              {
                "text": "ing",
                "logprob": -0.503511369228363
              },
              {
                "text": "Problem",
                "logprob": -0.0006083783227950335
              },
              {
                "text": ",",
                "logprob": -0.5226068496704102
              },
              {
                "text": "which",
                "logprob": -1.4998469352722168
              },
              {
                "text": "concerns",
                "logprob": -1.858565330505371
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6080880375448032,
              "max_token_negative_log_likelihood": 1.8585652112960815,
              "predictive_entropy": 0.19951819318521302,
              "shannon_entropy": 1.024244677159004
            }
          },
          {
            "text": "The Road Colorings problem is intric",
            "logprob": -12.523262546397746,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01166664157062769
              },
              {
                "text": "Road",
                "logprob": -0.1005207896232605
              },
              {
                "text": "Color",
                "logprob": -0.36737823486328125
              },
              {
                "text": "ings",
                "logprob": -1.7535114288330078
              },
              {
                "text": "problem",
                "logprob": -2.0101962089538574
              },
              {
                "text": "is",
                "logprob": -1.5307245254516602
              },
              {
                "text": "intr",
                "logprob": -6.414746284484863
              },
              {
                "text": "ic",
                "logprob": -0.3345184326171875
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.5654070617165416,
              "max_token_negative_log_likelihood": 6.414740562438965,
              "predictive_entropy": 0.1888663589488715,
              "shannon_entropy": 0.9509996986016631
            }
          }
        ],
        "cached": false,
        "request_time": 1.0229113101959229,
        "request_datetime": 1755801562
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Cauchy\u2013Kowalevski theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Sofia Kovalevskaya"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofya Kovalevskaya"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofya Kovalevskaia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofya Kovalevskaja"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofya Kovalevsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofia Kovalevskaya"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofia Kovalevskaia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofia Kovalevskaja"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofia Kovalevsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofja Kovalevskaya"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofja Kovalevskaja"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofja Kovalevskaia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofja Kovalevsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sofya Vasilyevna Kovalevskaya"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id41"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nCauchy\u2013Kowalevski theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Cauchy\u2013Kowale",
            "logprob": -0.01932221111200505,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.010336083360016346
              },
              {
                "text": "C",
                "logprob": -0.00019739109848160297
              },
              {
                "text": "auch",
                "logprob": 0.0
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0009403574513271451
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "ow",
                "logprob": -0.00784825999289751
              },
              {
                "text": "ale",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002415278748232552,
              "max_token_negative_log_likelihood": 0.01033610850572586,
              "predictive_entropy": 0.002394208409896237,
              "shannon_entropy": 0.015970643074797453
            }
          },
          {
            "text": "The Cauchy\u2013Kowale",
            "logprob": -0.01932221111200505,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.010336083360016346
              },
              {
                "text": "C",
                "logprob": -0.00019739109848160297
              },
              {
                "text": "auch",
                "logprob": 0.0
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0009403574513271451
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "ow",
                "logprob": -0.00784825999289751
              },
              {
                "text": "ale",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002415278748232552,
              "max_token_negative_log_likelihood": 0.01033610850572586,
              "predictive_entropy": 0.002394208409896237,
              "shannon_entropy": 0.015970643074797453
            }
          },
          {
            "text": "The Cauchy\u2013Kowale",
            "logprob": -0.01932221111200505,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.010336083360016346
              },
              {
                "text": "C",
                "logprob": -0.00019739109848160297
              },
              {
                "text": "auch",
                "logprob": 0.0
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0009403574513271451
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "ow",
                "logprob": -0.00784825999289751
              },
              {
                "text": "ale",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002415278748232552,
              "max_token_negative_log_likelihood": 0.01033610850572586,
              "predictive_entropy": 0.002394208409896237,
              "shannon_entropy": 0.015970643074797453
            }
          },
          {
            "text": "The Cauchy\u2013Kowale",
            "logprob": -0.01932221111200505,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.010336083360016346
              },
              {
                "text": "C",
                "logprob": -0.00019739109848160297
              },
              {
                "text": "auch",
                "logprob": 0.0
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0009403574513271451
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "ow",
                "logprob": -0.00784825999289751
              },
              {
                "text": "ale",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002415278748232552,
              "max_token_negative_log_likelihood": 0.01033610850572586,
              "predictive_entropy": 0.002394208409896237,
              "shannon_entropy": 0.015970643074797453
            }
          },
          {
            "text": "The Cauchy\u2013Kowale",
            "logprob": -0.01932221111200505,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.010336083360016346
              },
              {
                "text": "C",
                "logprob": -0.00019739109848160297
              },
              {
                "text": "auch",
                "logprob": 0.0
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0009403574513271451
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "ow",
                "logprob": -0.00784825999289751
              },
              {
                "text": "ale",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002415278748232552,
              "max_token_negative_log_likelihood": 0.01033610850572586,
              "predictive_entropy": 0.002394208409896237,
              "shannon_entropy": 0.015970643074797453
            }
          }
        ],
        "cached": false,
        "request_time": 1.0202643871307373,
        "request_datetime": 1755801562
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Hilbert's third problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Max Dehn"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Max Wilhelm Dehn"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id42"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nHilbert's third problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Hilbert's third problem, which",
            "logprob": -0.573249734863559,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.12844151258468628
              },
              {
                "text": "bert",
                "logprob": -5.006777428206988e-06
              },
              {
                "text": "'",
                "logprob": -1.1086402082582936e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "third",
                "logprob": -0.008352585136890411
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ",",
                "logprob": -0.1871929168701172
              },
              {
                "text": "which",
                "logprob": -0.2492465078830719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0716562260734026,
              "max_token_negative_log_likelihood": 0.2492465078830719,
              "predictive_entropy": 0.05884436610170951,
              "shannon_entropy": 0.22323875353813705
            }
          },
          {
            "text": "Hilbert's third problem was solved",
            "logprob": -1.9679478611051238,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.12844151258468628
              },
              {
                "text": "bert",
                "logprob": -5.006777428206988e-06
              },
              {
                "text": "'",
                "logprob": -1.1086402082582936e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "third",
                "logprob": -0.008352585136890411
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "was",
                "logprob": -1.8121929168701172
              },
              {
                "text": "solved",
                "logprob": -0.01894463412463665
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2459934844030176,
              "max_token_negative_log_likelihood": 1.8121929168701172,
              "predictive_entropy": 0.054471432920706775,
              "shannon_entropy": 0.14310325534225043
            }
          },
          {
            "text": "Hilbert's third problem, which",
            "logprob": -0.573249734863559,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.12844151258468628
              },
              {
                "text": "bert",
                "logprob": -5.006777428206988e-06
              },
              {
                "text": "'",
                "logprob": -1.1086402082582936e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "third",
                "logprob": -0.008352585136890411
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ",",
                "logprob": -0.1871929168701172
              },
              {
                "text": "which",
                "logprob": -0.2492465078830719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0716562260734026,
              "max_token_negative_log_likelihood": 0.2492465078830719,
              "predictive_entropy": 0.05884436610170951,
              "shannon_entropy": 0.22323875353813705
            }
          },
          {
            "text": "Hilbert's third problem, which",
            "logprob": -0.573249734863559,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.12844151258468628
              },
              {
                "text": "bert",
                "logprob": -5.006777428206988e-06
              },
              {
                "text": "'",
                "logprob": -1.1086402082582936e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "third",
                "logprob": -0.008352585136890411
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ",",
                "logprob": -0.1871929168701172
              },
              {
                "text": "which",
                "logprob": -0.2492465078830719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0716562260734026,
              "max_token_negative_log_likelihood": 0.2492465078830719,
              "predictive_entropy": 0.05884436610170951,
              "shannon_entropy": 0.22323875353813705
            }
          },
          {
            "text": "Hilbert's third problem, which",
            "logprob": -0.573249734863559,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.12844151258468628
              },
              {
                "text": "bert",
                "logprob": -5.006777428206988e-06
              },
              {
                "text": "'",
                "logprob": -1.1086402082582936e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "third",
                "logprob": -0.008352585136890411
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ",",
                "logprob": -0.1871929168701172
              },
              {
                "text": "which",
                "logprob": -0.2492465078830719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0716562260734026,
              "max_token_negative_log_likelihood": 0.2492465078830719,
              "predictive_entropy": 0.05884436610170951,
              "shannon_entropy": 0.22323875353813705
            }
          }
        ],
        "cached": false,
        "request_time": 1.0248908996582031,
        "request_datetime": 1755801563
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Sazonov's theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Vyacheslav Sazonov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Vyacheslav Vasilyevich Sazonov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Vyacheslav Vasilievich Sazonov"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id43"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nSazonov's theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Sazonov's theorem was solved",
            "logprob": -0.990059248455502,
            "tokens": [
              {
                "text": "S",
                "logprob": -0.010217975825071335
              },
              {
                "text": "azon",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.5735502529423684e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0005535738891921937
              },
              {
                "text": "was",
                "logprob": -0.9146347045898438
              },
              {
                "text": "solved",
                "logprob": -0.06463713943958282
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.12375740365041743,
              "max_token_negative_log_likelihood": 0.9146347045898438,
              "predictive_entropy": 0.05471684765416285,
              "shannon_entropy": 0.20361450540801268
            }
          },
          {
            "text": "Sazonov's theorem was solved",
            "logprob": -0.990059248455502,
            "tokens": [
              {
                "text": "S",
                "logprob": -0.010217975825071335
              },
              {
                "text": "azon",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.5735502529423684e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0005535738891921937
              },
              {
                "text": "was",
                "logprob": -0.9146347045898438
              },
              {
                "text": "solved",
                "logprob": -0.06463713943958282
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.12375740365041743,
              "max_token_negative_log_likelihood": 0.9146347045898438,
              "predictive_entropy": 0.05471684765416285,
              "shannon_entropy": 0.20361450540801268
            }
          },
          {
            "text": "Sazonov's theorem was solved",
            "logprob": -0.990059248455502,
            "tokens": [
              {
                "text": "S",
                "logprob": -0.010217975825071335
              },
              {
                "text": "azon",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.5735502529423684e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0005535738891921937
              },
              {
                "text": "was",
                "logprob": -0.9146347045898438
              },
              {
                "text": "solved",
                "logprob": -0.06463713943958282
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.12375740365041743,
              "max_token_negative_log_likelihood": 0.9146347045898438,
              "predictive_entropy": 0.05471684765416285,
              "shannon_entropy": 0.20361450540801268
            }
          },
          {
            "text": "Sazonov's theorem was solved",
            "logprob": -0.990059248455502,
            "tokens": [
              {
                "text": "S",
                "logprob": -0.010217975825071335
              },
              {
                "text": "azon",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.5735502529423684e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0005535738891921937
              },
              {
                "text": "was",
                "logprob": -0.9146347045898438
              },
              {
                "text": "solved",
                "logprob": -0.06463713943958282
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.12375740365041743,
              "max_token_negative_log_likelihood": 0.9146347045898438,
              "predictive_entropy": 0.05471684765416285,
              "shannon_entropy": 0.20361450540801268
            }
          },
          {
            "text": "Sazonov's theorem, which",
            "logprob": -1.7234025367579235,
            "tokens": [
              {
                "text": "S",
                "logprob": -0.010217975825071335
              },
              {
                "text": "azon",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.5735502529423684e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0005535738891921937
              },
              {
                "text": ",",
                "logprob": -0.8521347045898438
              },
              {
                "text": "which",
                "logprob": -0.8604804277420044
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2154253156195427,
              "max_token_negative_log_likelihood": 0.8604803681373596,
              "predictive_entropy": 0.09225867716941138,
              "shannon_entropy": 0.38273821997424345
            }
          }
        ],
        "cached": false,
        "request_time": 1.020561933517456,
        "request_datetime": 1755801563
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Serre's modularity conjecture was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Chandrashekhar Khare"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Chandrashekhar B. Khare"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Chandrashekhar Bhalchandra Khare"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Jean-Pierre Wintenberger"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mark Kisin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id44"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nSerre's modularity conjecture was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Andrew Wiles is known for proving",
            "logprob": -8.785428564529866,
            "tokens": [
              {
                "text": "Andrew",
                "logprob": -1.7564693689346313
              },
              {
                "text": "Wil",
                "logprob": -0.5551050305366516
              },
              {
                "text": "es",
                "logprob": 0.0
              },
              {
                "text": "is",
                "logprob": -1.2987316846847534
              },
              {
                "text": "known",
                "logprob": -3.587472915649414
              },
              {
                "text": "for",
                "logprob": -0.0031688022427260876
              },
              {
                "text": "prov",
                "logprob": -1.5844807624816895
              },
              {
                "text": "ing",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0981785144249443,
              "max_token_negative_log_likelihood": 3.587472677230835,
              "predictive_entropy": 0.17545176719431765,
              "shannon_entropy": 0.7440787752359412
            }
          },
          {
            "text": "Serre's modularity conject",
            "logprob": -0.6316786792110562,
            "tokens": [
              {
                "text": "Ser",
                "logprob": -0.6314693689346313
              },
              {
                "text": "re",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -3.099436753473128e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "mod",
                "logprob": -0.0002060916303889826
              },
              {
                "text": "ular",
                "logprob": 0.0
              },
              {
                "text": "ity",
                "logprob": 0.0
              },
              {
                "text": "conject",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07895983275980889,
              "max_token_negative_log_likelihood": 0.6314693689346313,
              "predictive_entropy": 0.042003856180002686,
              "shannon_entropy": 0.19307383053273303
            }
          },
          {
            "text": "Serre's modularity conject",
            "logprob": -0.6316786792110562,
            "tokens": [
              {
                "text": "Ser",
                "logprob": -0.6314693689346313
              },
              {
                "text": "re",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -3.099436753473128e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "mod",
                "logprob": -0.0002060916303889826
              },
              {
                "text": "ular",
                "logprob": 0.0
              },
              {
                "text": "ity",
                "logprob": 0.0
              },
              {
                "text": "conject",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07895983275980889,
              "max_token_negative_log_likelihood": 0.6314693689346313,
              "predictive_entropy": 0.042003856180002686,
              "shannon_entropy": 0.19307383053273303
            }
          },
          {
            "text": "Pierre Deligne\n\n\nThe Sau",
            "logprob": -8.67361630126095,
            "tokens": [
              {
                "text": "Pierre",
                "logprob": -3.850219249725342
              },
              {
                "text": "Del",
                "logprob": -0.05350760743021965
              },
              {
                "text": "igne",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "\n",
                "logprob": -1.943575143814087
              },
              {
                "text": "\n",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "\n",
                "logprob": -0.44565412402153015
              },
              {
                "text": "The",
                "logprob": -1.2299096584320068
              },
              {
                "text": "Sau",
                "logprob": -1.15074622631073
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0842019910933374,
              "max_token_negative_log_likelihood": 3.8502187728881836,
              "predictive_entropy": 0.17749529471528547,
              "shannon_entropy": 1.019624917172223
            }
          },
          {
            "text": "Serre's modularity conject",
            "logprob": -0.6316786792110562,
            "tokens": [
              {
                "text": "Ser",
                "logprob": -0.6314693689346313
              },
              {
                "text": "re",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -3.099436753473128e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "mod",
                "logprob": -0.0002060916303889826
              },
              {
                "text": "ular",
                "logprob": 0.0
              },
              {
                "text": "ity",
                "logprob": 0.0
              },
              {
                "text": "conject",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07895983275980889,
              "max_token_negative_log_likelihood": 0.6314693689346313,
              "predictive_entropy": 0.042003856180002686,
              "shannon_entropy": 0.19307383053273303
            }
          }
        ],
        "cached": false,
        "request_time": 1.0223362445831299,
        "request_datetime": 1755801563
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Hilbert's nineteenth problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Ennio De Giorgi"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "John Forbes Nash"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "John Forbes Nash Jr."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "John Nash"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Phantom of Fine Hall"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "John F. Nash"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "John F. Nash Jr."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "John Forbes Nash"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id45"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nHilbert's nineteenth problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Hilbert's nineteenth problem",
            "logprob": -0.5596329543074887,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.5595384240150452
              },
              {
                "text": "bert",
                "logprob": -8.583032467868179e-06
              },
              {
                "text": "'",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "nin",
                "logprob": -7.176141662057489e-05
              },
              {
                "text": "ete",
                "logprob": -1.0847986231965479e-05
              },
              {
                "text": "enth",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "problem",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06995411250654726,
              "max_token_negative_log_likelihood": 0.5595383644104004,
              "predictive_entropy": 0.039981938564405795,
              "shannon_entropy": 0.132879920373893
            }
          },
          {
            "text": "The non-squeezing theorem",
            "logprob": -5.090049184638701,
            "tokens": [
              {
                "text": "The",
                "logprob": -1.2470383644104004
              },
              {
                "text": "non",
                "logprob": -3.837928295135498
              },
              {
                "text": "-",
                "logprob": -0.0032109867315739393
              },
              {
                "text": "s",
                "logprob": -0.00032574593205936253
              },
              {
                "text": "que",
                "logprob": 0.0
              },
              {
                "text": "ez",
                "logprob": -5.722029527532868e-06
              },
              {
                "text": "ing",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0015400703996419907
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6362561298431046,
              "max_token_negative_log_likelihood": 3.837928056716919,
              "predictive_entropy": 0.05575923661467641,
              "shannon_entropy": 0.26754337122456995
            }
          },
          {
            "text": "Hilbert's nineteenth problem",
            "logprob": -0.5596329543074887,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.5595384240150452
              },
              {
                "text": "bert",
                "logprob": -8.583032467868179e-06
              },
              {
                "text": "'",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "nin",
                "logprob": -7.176141662057489e-05
              },
              {
                "text": "ete",
                "logprob": -1.0847986231965479e-05
              },
              {
                "text": "enth",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "problem",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06995411250654726,
              "max_token_negative_log_likelihood": 0.5595383644104004,
              "predictive_entropy": 0.039981938564405795,
              "shannon_entropy": 0.132879920373893
            }
          },
          {
            "text": "Hilbert's nineteenth problem",
            "logprob": -0.5596329543074887,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.5595384240150452
              },
              {
                "text": "bert",
                "logprob": -8.583032467868179e-06
              },
              {
                "text": "'",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "nin",
                "logprob": -7.176141662057489e-05
              },
              {
                "text": "ete",
                "logprob": -1.0847986231965479e-05
              },
              {
                "text": "enth",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "problem",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06995411250654726,
              "max_token_negative_log_likelihood": 0.5595383644104004,
              "predictive_entropy": 0.039981938564405795,
              "shannon_entropy": 0.132879920373893
            }
          },
          {
            "text": "Hilbert's nineteenth problem",
            "logprob": -0.5596329543074887,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.5595384240150452
              },
              {
                "text": "bert",
                "logprob": -8.583032467868179e-06
              },
              {
                "text": "'",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "nin",
                "logprob": -7.176141662057489e-05
              },
              {
                "text": "ete",
                "logprob": -1.0847986231965479e-05
              },
              {
                "text": "enth",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "problem",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06995411250654726,
              "max_token_negative_log_likelihood": 0.5595383644104004,
              "predictive_entropy": 0.039981938564405795,
              "shannon_entropy": 0.132879920373893
            }
          }
        ],
        "cached": false,
        "request_time": 1.0208187103271484,
        "request_datetime": 1755801563
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Ladyzhenskaya's inequality was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Olga Ladyzhenskaya"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Olga Aleksandrovna Ladyzhenskaya"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id46"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nLadyzhenskaya's inequality was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Ladyzhenskaya's inequality is",
            "logprob": -1.2222278781949782,
            "tokens": [
              {
                "text": "Lady",
                "logprob": -0.0354861281812191
              },
              {
                "text": "zh",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ensk",
                "logprob": -0.00038914260221645236
              },
              {
                "text": "aya",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "'",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "inequality",
                "logprob": -7.950943836476654e-05
              },
              {
                "text": "is",
                "logprob": -1.1862664222717285
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15277846864099054,
              "max_token_negative_log_likelihood": 1.186266303062439,
              "predictive_entropy": 0.049620187297918505,
              "shannon_entropy": 0.18049498845830314
            }
          },
          {
            "text": "Ladyzhenskaya's inequality is",
            "logprob": -1.2222278781949782,
            "tokens": [
              {
                "text": "Lady",
                "logprob": -0.0354861281812191
              },
              {
                "text": "zh",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ensk",
                "logprob": -0.00038914260221645236
              },
              {
                "text": "aya",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "'",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "inequality",
                "logprob": -7.950943836476654e-05
              },
              {
                "text": "is",
                "logprob": -1.1862664222717285
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15277846864099054,
              "max_token_negative_log_likelihood": 1.186266303062439,
              "predictive_entropy": 0.049620187297918505,
              "shannon_entropy": 0.18049498845830314
            }
          },
          {
            "text": "Ladyzhenskaya's inequality,",
            "logprob": -1.3472278781949782,
            "tokens": [
              {
                "text": "Lady",
                "logprob": -0.0354861281812191
              },
              {
                "text": "zh",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ensk",
                "logprob": -0.00038914260221645236
              },
              {
                "text": "aya",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "'",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "inequality",
                "logprob": -7.950943836476654e-05
              },
              {
                "text": ",",
                "logprob": -1.3112664222717285
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.16840346864099054,
              "max_token_negative_log_likelihood": 1.311266303062439,
              "predictive_entropy": 0.04851028548226566,
              "shannon_entropy": 0.18049498845830314
            }
          },
          {
            "text": "Ladyzhenskaya's inequality is",
            "logprob": -1.2222278781949782,
            "tokens": [
              {
                "text": "Lady",
                "logprob": -0.0354861281812191
              },
              {
                "text": "zh",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ensk",
                "logprob": -0.00038914260221645236
              },
              {
                "text": "aya",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "'",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "inequality",
                "logprob": -7.950943836476654e-05
              },
              {
                "text": "is",
                "logprob": -1.1862664222717285
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15277846864099054,
              "max_token_negative_log_likelihood": 1.186266303062439,
              "predictive_entropy": 0.049620187297918505,
              "shannon_entropy": 0.18049498845830314
            }
          },
          {
            "text": "Ladyzhenskaya's inequality is",
            "logprob": -1.2222278781949782,
            "tokens": [
              {
                "text": "Lady",
                "logprob": -0.0354861281812191
              },
              {
                "text": "zh",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ensk",
                "logprob": -0.00038914260221645236
              },
              {
                "text": "aya",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "'",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "inequality",
                "logprob": -7.950943836476654e-05
              },
              {
                "text": "is",
                "logprob": -1.1862664222717285
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15277846864099054,
              "max_token_negative_log_likelihood": 1.186266303062439,
              "predictive_entropy": 0.049620187297918505,
              "shannon_entropy": 0.18049498845830314
            }
          }
        ],
        "cached": false,
        "request_time": 1.0189387798309326,
        "request_datetime": 1755801564
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "continuum hypothesis was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Kurt G\u00f6del"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Kurt Friedrich G\u00f6del"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paul Cohen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paul Joseph Cohen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paul J"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paul J. Cohen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paul Joseph Cohen"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id47"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\ncontinuum hypothesis was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Continuum Hypothesis (",
            "logprob": -2.1938219599608075,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.008375519886612892
              },
              {
                "text": "Cont",
                "logprob": -0.5544742941856384
              },
              {
                "text": "inu",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "um",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Hyp",
                "logprob": -4.684815212385729e-05
              },
              {
                "text": "oth",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "esis",
                "logprob": 0.0
              },
              {
                "text": "(",
                "logprob": -1.6309235095977783
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2742277296702955,
              "max_token_negative_log_likelihood": 1.6309233903884888,
              "predictive_entropy": 0.08076014216331373,
              "shannon_entropy": 0.2927363103751215
            }
          },
          {
            "text": "The continuum hypothesis, which concerns the",
            "logprob": -3.1180023385504683,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.008375519886612892
              },
              {
                "text": "continu",
                "logprob": -0.8669742941856384
              },
              {
                "text": "um",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "hypothesis",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -1.171526551246643
              },
              {
                "text": "which",
                "logprob": -0.6687303781509399
              },
              {
                "text": "concerns",
                "logprob": -0.4022451639175415
              },
              {
                "text": "the",
                "logprob": -0.00014804698002990335
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3897503129868767,
              "max_token_negative_log_likelihood": 1.1715266704559326,
              "predictive_entropy": 0.16843544787445808,
              "shannon_entropy": 0.5424209959564621
            }
          },
          {
            "text": "The Continuum Hypothesis is",
            "logprob": -2.1625719599608075,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.008375519886612892
              },
              {
                "text": "Cont",
                "logprob": -0.5544742941856384
              },
              {
                "text": "inu",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "um",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Hyp",
                "logprob": -4.684815212385729e-05
              },
              {
                "text": "oth",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "esis",
                "logprob": 0.0
              },
              {
                "text": "is",
                "logprob": -1.5996735095977783
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2703214945714567,
              "max_token_negative_log_likelihood": 1.5996735095977783,
              "predictive_entropy": 0.08123799260047804,
              "shannon_entropy": 0.2927363103751215
            }
          },
          {
            "text": "The Continuum Hypothesis is",
            "logprob": -2.1625719599608075,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.008375519886612892
              },
              {
                "text": "Cont",
                "logprob": -0.5544742941856384
              },
              {
                "text": "inu",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "um",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Hyp",
                "logprob": -4.684815212385729e-05
              },
              {
                "text": "oth",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "esis",
                "logprob": 0.0
              },
              {
                "text": "is",
                "logprob": -1.5996735095977783
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2703214945714567,
              "max_token_negative_log_likelihood": 1.5996735095977783,
              "predictive_entropy": 0.08123799260047804,
              "shannon_entropy": 0.2927363103751215
            }
          },
          {
            "text": "The continuum hypothesis, a famous problem",
            "logprob": -4.583371045065178,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.008375519886612892
              },
              {
                "text": "continu",
                "logprob": -0.8669742941856384
              },
              {
                "text": "um",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "hypothesis",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -1.171526551246643
              },
              {
                "text": "a",
                "logprob": -2.0749802589416504
              },
              {
                "text": "famous",
                "logprob": -0.4150819778442383
              },
              {
                "text": "problem",
                "logprob": -0.046430058777332306
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.572921398096156,
              "max_token_negative_log_likelihood": 2.0749802589416504,
              "predictive_entropy": 0.1643257639367448,
              "shannon_entropy": 0.6437198894381879
            }
          }
        ],
        "cached": false,
        "request_time": 1.0231401920318604,
        "request_datetime": 1755801564
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Golod\u2013Shafarevich theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Evgeny Golod"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Yevgeny Solomonovich Golod"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Evgenii Solomonovich Golod"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id48"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nGolod\u2013Shafarevich theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Golod\u2013Shafarev",
            "logprob": -0.013749122443833528,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.013454710133373737
              },
              {
                "text": "Gol",
                "logprob": -3.0517112463712692e-05
              },
              {
                "text": "od",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0002613918040879071
              },
              {
                "text": "Sh",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "af",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "are",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "v",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0017186431433966476,
              "max_token_negative_log_likelihood": 0.013454723171889782,
              "predictive_entropy": 0.0016961573636145033,
              "shannon_entropy": 0.01159429582585858
            }
          },
          {
            "text": "The Golod\u2013Shafarev",
            "logprob": -0.013749122443833528,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.013454710133373737
              },
              {
                "text": "Gol",
                "logprob": -3.0517112463712692e-05
              },
              {
                "text": "od",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0002613918040879071
              },
              {
                "text": "Sh",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "af",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "are",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "v",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0017186431433966476,
              "max_token_negative_log_likelihood": 0.013454723171889782,
              "predictive_entropy": 0.0016961573636145033,
              "shannon_entropy": 0.01159429582585858
            }
          },
          {
            "text": "The Golod\u2013Shafarev",
            "logprob": -0.013749122443833528,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.013454710133373737
              },
              {
                "text": "Gol",
                "logprob": -3.0517112463712692e-05
              },
              {
                "text": "od",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0002613918040879071
              },
              {
                "text": "Sh",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "af",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "are",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "v",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0017186431433966476,
              "max_token_negative_log_likelihood": 0.013454723171889782,
              "predictive_entropy": 0.0016961573636145033,
              "shannon_entropy": 0.01159429582585858
            }
          },
          {
            "text": "The Golod\u2013Shafarev",
            "logprob": -0.013749122443833528,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.013454710133373737
              },
              {
                "text": "Gol",
                "logprob": -3.0517112463712692e-05
              },
              {
                "text": "od",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0002613918040879071
              },
              {
                "text": "Sh",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "af",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "are",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "v",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0017186431433966476,
              "max_token_negative_log_likelihood": 0.013454723171889782,
              "predictive_entropy": 0.0016961573636145033,
              "shannon_entropy": 0.01159429582585858
            }
          },
          {
            "text": "The Golod\u2013Shafarev",
            "logprob": -0.013749122443833528,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.013454710133373737
              },
              {
                "text": "Gol",
                "logprob": -3.0517112463712692e-05
              },
              {
                "text": "od",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.0002613918040879071
              },
              {
                "text": "Sh",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "af",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "are",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "v",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0017186431433966476,
              "max_token_negative_log_likelihood": 0.013454723171889782,
              "predictive_entropy": 0.0016961573636145033,
              "shannon_entropy": 0.01159429582585858
            }
          }
        ],
        "cached": false,
        "request_time": 1.0164806842803955,
        "request_datetime": 1755801564
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Trakhtenbrot's theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Boris Trakhtenbrot"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boris Avraamovich Trakhtenbrot"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boris A. Trakhtenbrot"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boaz Trakhtenbrot"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boris Avraamovi\u010d Trachtenbrot"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id49"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nTrakhtenbrot's theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Trakhtenbrot's",
            "logprob": -0.011658481442275104,
            "tokens": [
              {
                "text": "Tra",
                "logprob": -0.0013785392511636019
              },
              {
                "text": "k",
                "logprob": -0.009665240533649921
              },
              {
                "text": "ht",
                "logprob": 0.0
              },
              {
                "text": "en",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "b",
                "logprob": 0.0
              },
              {
                "text": "rot",
                "logprob": -0.0005995621904730797
              },
              {
                "text": "'",
                "logprob": -1.5020257706055418e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0014573117728122753,
              "max_token_negative_log_likelihood": 0.009665258228778839,
              "predictive_entropy": 0.0014454085107900028,
              "shannon_entropy": 0.010065053774751753
            }
          },
          {
            "text": "Trakhtenbrot's",
            "logprob": -0.011658481442275104,
            "tokens": [
              {
                "text": "Tra",
                "logprob": -0.0013785392511636019
              },
              {
                "text": "k",
                "logprob": -0.009665240533649921
              },
              {
                "text": "ht",
                "logprob": 0.0
              },
              {
                "text": "en",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "b",
                "logprob": 0.0
              },
              {
                "text": "rot",
                "logprob": -0.0005995621904730797
              },
              {
                "text": "'",
                "logprob": -1.5020257706055418e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0014573117728122753,
              "max_token_negative_log_likelihood": 0.009665258228778839,
              "predictive_entropy": 0.0014454085107900028,
              "shannon_entropy": 0.010065053774751753
            }
          },
          {
            "text": "Trakhtenbrot's",
            "logprob": -0.011658481442275104,
            "tokens": [
              {
                "text": "Tra",
                "logprob": -0.0013785392511636019
              },
              {
                "text": "k",
                "logprob": -0.009665240533649921
              },
              {
                "text": "ht",
                "logprob": 0.0
              },
              {
                "text": "en",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "b",
                "logprob": 0.0
              },
              {
                "text": "rot",
                "logprob": -0.0005995621904730797
              },
              {
                "text": "'",
                "logprob": -1.5020257706055418e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0014573117728122753,
              "max_token_negative_log_likelihood": 0.009665258228778839,
              "predictive_entropy": 0.0014454085107900028,
              "shannon_entropy": 0.010065053774751753
            }
          },
          {
            "text": "Trakhtenbrot's",
            "logprob": -0.011658481442275104,
            "tokens": [
              {
                "text": "Tra",
                "logprob": -0.0013785392511636019
              },
              {
                "text": "k",
                "logprob": -0.009665240533649921
              },
              {
                "text": "ht",
                "logprob": 0.0
              },
              {
                "text": "en",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "b",
                "logprob": 0.0
              },
              {
                "text": "rot",
                "logprob": -0.0005995621904730797
              },
              {
                "text": "'",
                "logprob": -1.5020257706055418e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0014573117728122753,
              "max_token_negative_log_likelihood": 0.009665258228778839,
              "predictive_entropy": 0.0014454085107900028,
              "shannon_entropy": 0.010065053774751753
            }
          },
          {
            "text": "Trakhtenbrot's",
            "logprob": -0.011658481442275104,
            "tokens": [
              {
                "text": "Tra",
                "logprob": -0.0013785392511636019
              },
              {
                "text": "k",
                "logprob": -0.009665240533649921
              },
              {
                "text": "ht",
                "logprob": 0.0
              },
              {
                "text": "en",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "b",
                "logprob": 0.0
              },
              {
                "text": "rot",
                "logprob": -0.0005995621904730797
              },
              {
                "text": "'",
                "logprob": -1.5020257706055418e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0014573117728122753,
              "max_token_negative_log_likelihood": 0.009665258228778839,
              "predictive_entropy": 0.0014454085107900028,
              "shannon_entropy": 0.010065053774751753
            }
          }
        ],
        "cached": false,
        "request_time": 1.022918462753296,
        "request_datetime": 1755801564
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Brouwer fixed-point theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Piers Bohl"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id50"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nBrouwer fixed-point theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Brouwer fixed-point theorem",
            "logprob": -1.123995730158633,
            "tokens": [
              {
                "text": "The",
                "logprob": -1.083064317703247
              },
              {
                "text": "Br",
                "logprob": -0.0004776767164003104
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "wer",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "fixed",
                "logprob": -0.04045361652970314
              },
              {
                "text": "-",
                "logprob": 0.0
              },
              {
                "text": "point",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.14049944682847304,
              "max_token_negative_log_likelihood": 1.0830641984939575,
              "predictive_entropy": 0.050750720027281204,
              "shannon_entropy": 0.16169642766697767
            }
          },
          {
            "text": "Brouwer's fixed-point",
            "logprob": -2.3273756355024204,
            "tokens": [
              {
                "text": "Br",
                "logprob": -1.395564317703247
              },
              {
                "text": "ou",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "wer",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -0.761425793170929
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "fixed",
                "logprob": -0.17038314044475555
              },
              {
                "text": "-",
                "logprob": -2.145764938177308e-06
              },
              {
                "text": "point",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.29092193767457175,
              "max_token_negative_log_likelihood": 1.3955641984939575,
              "predictive_entropy": 0.10561891645164323,
              "shannon_entropy": 0.2850797577210118
            }
          },
          {
            "text": "L.E.J. Brou",
            "logprob": -3.0364031437402446,
            "tokens": [
              {
                "text": "L",
                "logprob": -0.8955642580986023
              },
              {
                "text": ".",
                "logprob": -2.0493404865264893
              },
              {
                "text": "E",
                "logprob": -0.08894218504428864
              },
              {
                "text": ".",
                "logprob": -6.317892984952778e-05
              },
              {
                "text": "J",
                "logprob": -0.0022794236429035664
              },
              {
                "text": ".",
                "logprob": -5.1020273531321436e-05
              },
              {
                "text": "Br",
                "logprob": -0.00014161060971673578
              },
              {
                "text": "ou",
                "logprob": -2.098061486321967e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.37955039946723446,
              "max_token_negative_log_likelihood": 2.0493404865264893,
              "predictive_entropy": 0.08920596542316162,
              "shannon_entropy": 0.23199802233284572
            }
          },
          {
            "text": "Brouwer fixed-point theorem was",
            "logprob": -2.065025374293299,
            "tokens": [
              {
                "text": "Br",
                "logprob": -1.395564317703247
              },
              {
                "text": "ou",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "wer",
                "logprob": 0.0
              },
              {
                "text": "fixed",
                "logprob": -0.636425793170929
              },
              {
                "text": "-",
                "logprob": 0.0
              },
              {
                "text": "point",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -0.033035025000572205
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2581281485036051,
              "max_token_negative_log_likelihood": 1.3955641984939575,
              "predictive_entropy": 0.08930220874026062,
              "shannon_entropy": 0.2515936572922197
            }
          },
          {
            "text": "The Brouwer fixed-point theorem",
            "logprob": -1.123995730158633,
            "tokens": [
              {
                "text": "The",
                "logprob": -1.083064317703247
              },
              {
                "text": "Br",
                "logprob": -0.0004776767164003104
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "wer",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "fixed",
                "logprob": -0.04045361652970314
              },
              {
                "text": "-",
                "logprob": 0.0
              },
              {
                "text": "point",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.14049944682847304,
              "max_token_negative_log_likelihood": 1.0830641984939575,
              "predictive_entropy": 0.050750720027281204,
              "shannon_entropy": 0.16169642766697767
            }
          }
        ],
        "cached": false,
        "request_time": 1.007988691329956,
        "request_datetime": 1755801565
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Green\u2013Tao theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Ben Joseph Green"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ben Green"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ben J. Green"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Benjamin Joseph Green"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Terence Tao"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Terence \"Terry\" Chi-Shen Tao"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Terence Chi-Shen Tao"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Tao Zhexuan"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "T. Tao"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id51"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nGreen\u2013Tao theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Green\u2013Tao theorem was solved",
            "logprob": -0.33996809339771517,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005889443214982748
              },
              {
                "text": "Green",
                "logprob": -4.172238186583854e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.011756186373531818
              },
              {
                "text": "T",
                "logprob": 0.0
              },
              {
                "text": "ao",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "theorem",
                "logprob": -0.00019107422849629074
              },
              {
                "text": "was",
                "logprob": -0.31901034712791443
              },
              {
                "text": "solved",
                "logprob": -0.003078485606238246
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.042496006735333935,
              "max_token_negative_log_likelihood": 0.31901034712791443,
              "predictive_entropy": 0.03158183174305407,
              "shannon_entropy": 0.1046255061301089
            }
          },
          {
            "text": "The Green\u2013Tao theorem was solved",
            "logprob": -0.33996809339771517,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005889443214982748
              },
              {
                "text": "Green",
                "logprob": -4.172238186583854e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.011756186373531818
              },
              {
                "text": "T",
                "logprob": 0.0
              },
              {
                "text": "ao",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "theorem",
                "logprob": -0.00019107422849629074
              },
              {
                "text": "was",
                "logprob": -0.31901034712791443
              },
              {
                "text": "solved",
                "logprob": -0.003078485606238246
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.042496006735333935,
              "max_token_negative_log_likelihood": 0.31901034712791443,
              "predictive_entropy": 0.03158183174305407,
              "shannon_entropy": 0.1046255061301089
            }
          },
          {
            "text": "The Green\u2013Tao theorem is named",
            "logprob": -9.572475684766346,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005889443214982748
              },
              {
                "text": "Green",
                "logprob": -4.172238186583854e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.011756186373531818
              },
              {
                "text": "T",
                "logprob": 0.0
              },
              {
                "text": "ao",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "theorem",
                "logprob": -0.00019107422849629074
              },
              {
                "text": "is",
                "logprob": -4.662760257720947
              },
              {
                "text": "named",
                "logprob": -4.891836166381836
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1965591576331889,
              "max_token_negative_log_likelihood": 4.891834735870361,
              "predictive_entropy": 0.01230642880177868,
              "shannon_entropy": 0.1781178957680858
            }
          },
          {
            "text": "The Green\u2013Tao theorem was solved",
            "logprob": -0.33996809339771517,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005889443214982748
              },
              {
                "text": "Green",
                "logprob": -4.172238186583854e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.011756186373531818
              },
              {
                "text": "T",
                "logprob": 0.0
              },
              {
                "text": "ao",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "theorem",
                "logprob": -0.00019107422849629074
              },
              {
                "text": "was",
                "logprob": -0.31901034712791443
              },
              {
                "text": "solved",
                "logprob": -0.003078485606238246
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.042496006735333935,
              "max_token_negative_log_likelihood": 0.31901034712791443,
              "predictive_entropy": 0.03158183174305407,
              "shannon_entropy": 0.1046255061301089
            }
          },
          {
            "text": "The Green\u2013Tao theorem was solved",
            "logprob": -0.33996809339771517,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005889443214982748
              },
              {
                "text": "Green",
                "logprob": -4.172238186583854e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.011756186373531818
              },
              {
                "text": "T",
                "logprob": 0.0
              },
              {
                "text": "ao",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "theorem",
                "logprob": -0.00019107422849629074
              },
              {
                "text": "was",
                "logprob": -0.31901034712791443
              },
              {
                "text": "solved",
                "logprob": -0.003078485606238246
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.042496006735333935,
              "max_token_negative_log_likelihood": 0.31901034712791443,
              "predictive_entropy": 0.03158183174305407,
              "shannon_entropy": 0.1046255061301089
            }
          }
        ],
        "cached": false,
        "request_time": 1.009401798248291,
        "request_datetime": 1755801565
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "\u015aleszy\u0144ski\u2013Pringsheim theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Jan \u015aleszy\u0144ski"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ivan Sleszynski"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id52"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\n\u015aleszy\u0144ski\u2013Pringsheim theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The \u015aleszy\u0144ski\u2013Prings",
            "logprob": -0.006555205528115948,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.003578807692974806
              },
              {
                "text": "\u015a",
                "logprob": -0.0028936679009348154
              },
              {
                "text": "les",
                "logprob": 0.0
              },
              {
                "text": "zy",
                "logprob": -1.3708974620385561e-05
              },
              {
                "text": "\u0144ski",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "\u2013",
                "logprob": -2.6702524337451905e-05
              },
              {
                "text": "Pr",
                "logprob": 0.0
              },
              {
                "text": "ings",
                "logprob": -4.1483970562694594e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0008194037549600353,
              "max_token_negative_log_likelihood": 0.003578800708055496,
              "predictive_entropy": 0.000816760129922045,
              "shannon_entropy": 0.0074015647829712705
            }
          },
          {
            "text": "The \u015aleszy\u0144ski\u2013Prings",
            "logprob": -0.006555205528115948,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.003578807692974806
              },
              {
                "text": "\u015a",
                "logprob": -0.0028936679009348154
              },
              {
                "text": "les",
                "logprob": 0.0
              },
              {
                "text": "zy",
                "logprob": -1.3708974620385561e-05
              },
              {
                "text": "\u0144ski",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "\u2013",
                "logprob": -2.6702524337451905e-05
              },
              {
                "text": "Pr",
                "logprob": 0.0
              },
              {
                "text": "ings",
                "logprob": -4.1483970562694594e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0008194037549600353,
              "max_token_negative_log_likelihood": 0.003578800708055496,
              "predictive_entropy": 0.000816760129922045,
              "shannon_entropy": 0.0074015647829712705
            }
          },
          {
            "text": "The \u015aleszy\u0144ski\u2013Prings",
            "logprob": -0.006555205528115948,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.003578807692974806
              },
              {
                "text": "\u015a",
                "logprob": -0.0028936679009348154
              },
              {
                "text": "les",
                "logprob": 0.0
              },
              {
                "text": "zy",
                "logprob": -1.3708974620385561e-05
              },
              {
                "text": "\u0144ski",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "\u2013",
                "logprob": -2.6702524337451905e-05
              },
              {
                "text": "Pr",
                "logprob": 0.0
              },
              {
                "text": "ings",
                "logprob": -4.1483970562694594e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0008194037549600353,
              "max_token_negative_log_likelihood": 0.003578800708055496,
              "predictive_entropy": 0.000816760129922045,
              "shannon_entropy": 0.0074015647829712705
            }
          },
          {
            "text": "The \u015aleszy\u0144ski\u2013Prings",
            "logprob": -0.006555205528115948,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.003578807692974806
              },
              {
                "text": "\u015a",
                "logprob": -0.0028936679009348154
              },
              {
                "text": "les",
                "logprob": 0.0
              },
              {
                "text": "zy",
                "logprob": -1.3708974620385561e-05
              },
              {
                "text": "\u0144ski",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "\u2013",
                "logprob": -2.6702524337451905e-05
              },
              {
                "text": "Pr",
                "logprob": 0.0
              },
              {
                "text": "ings",
                "logprob": -4.1483970562694594e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0008194037549600353,
              "max_token_negative_log_likelihood": 0.003578800708055496,
              "predictive_entropy": 0.000816760129922045,
              "shannon_entropy": 0.0074015647829712705
            }
          },
          {
            "text": "The \u015aleszy\u0144ski\u2013Prings",
            "logprob": -0.006555205528115948,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.003578807692974806
              },
              {
                "text": "\u015a",
                "logprob": -0.0028936679009348154
              },
              {
                "text": "les",
                "logprob": 0.0
              },
              {
                "text": "zy",
                "logprob": -1.3708974620385561e-05
              },
              {
                "text": "\u0144ski",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "\u2013",
                "logprob": -2.6702524337451905e-05
              },
              {
                "text": "Pr",
                "logprob": 0.0
              },
              {
                "text": "ings",
                "logprob": -4.1483970562694594e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0008194037549600353,
              "max_token_negative_log_likelihood": 0.003578800708055496,
              "predictive_entropy": 0.000816760129922045,
              "shannon_entropy": 0.0074015647829712705
            }
          }
        ],
        "cached": false,
        "request_time": 1.0038721561431885,
        "request_datetime": 1755801565
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Hilbert's seventh problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Rodion Kuzmin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Rodion Osievich Kuzmin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Alexander Gelfond"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Aleksandr Osipovich Gelfond"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gel'fond Alexander Osipovich"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gelfond A."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gel'fond A."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Alexander Osipovich Gelfond"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id53"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nHilbert's seventh problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Hilbert's seventh problem was",
            "logprob": -2.0393484045551986,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.6268536448478699
              },
              {
                "text": "bert",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "'",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "sevent",
                "logprob": -0.00020382710499688983
              },
              {
                "text": "h",
                "logprob": -0.00784766860306263
              },
              {
                "text": "problem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -1.4044380187988281
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2549185500603386,
              "max_token_negative_log_likelihood": 1.4044380187988281,
              "predictive_entropy": 0.08596263240256974,
              "shannon_entropy": 0.2828377555259962
            }
          },
          {
            "text": "David Hilbert, a renowned math",
            "logprob": -5.157426433878754,
            "tokens": [
              {
                "text": "David",
                "logprob": -2.3456037044525146
              },
              {
                "text": "Hil",
                "logprob": -0.001073261140845716
              },
              {
                "text": "bert",
                "logprob": -1.1324817933200393e-05
              },
              {
                "text": ",",
                "logprob": -0.48168259859085083
              },
              {
                "text": "a",
                "logprob": -0.28208622336387634
              },
              {
                "text": "ren",
                "logprob": -1.5608820915222168
              },
              {
                "text": "owned",
                "logprob": -7.533743337262422e-05
              },
              {
                "text": "math",
                "logprob": -0.48601189255714417
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6446782701376605,
              "max_token_negative_log_likelihood": 2.3456034660339355,
              "predictive_entropy": 0.1703490636875813,
              "shannon_entropy": 0.6306366698881902
            }
          },
          {
            "text": "Hilbert's seventh problem was",
            "logprob": -2.0393484045551986,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.6268536448478699
              },
              {
                "text": "bert",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "'",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "sevent",
                "logprob": -0.00020382710499688983
              },
              {
                "text": "h",
                "logprob": -0.00784766860306263
              },
              {
                "text": "problem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -1.4044380187988281
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2549185500603386,
              "max_token_negative_log_likelihood": 1.4044380187988281,
              "predictive_entropy": 0.08596263240256974,
              "shannon_entropy": 0.2828377555259962
            }
          },
          {
            "text": "David Hilbert's seventh problem",
            "logprob": -3.9700886208383395,
            "tokens": [
              {
                "text": "David",
                "logprob": -2.3456037044525146
              },
              {
                "text": "Hil",
                "logprob": -0.001073261140845716
              },
              {
                "text": "bert",
                "logprob": -1.1324817933200393e-05
              },
              {
                "text": "'",
                "logprob": -1.606682538986206
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "sevent",
                "logprob": -0.015305919572710991
              },
              {
                "text": "h",
                "logprob": -0.0014115142403170466
              },
              {
                "text": "problem",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.49626105726282077,
              "max_token_negative_log_likelihood": 2.3456034660339355,
              "predictive_entropy": 0.0705592232036345,
              "shannon_entropy": 0.31624336144813014
            }
          },
          {
            "text": "Hilbert's seventh problem was",
            "logprob": -2.0393484045551986,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.6268536448478699
              },
              {
                "text": "bert",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "'",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "sevent",
                "logprob": -0.00020382710499688983
              },
              {
                "text": "h",
                "logprob": -0.00784766860306263
              },
              {
                "text": "problem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -1.4044380187988281
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2549185500603386,
              "max_token_negative_log_likelihood": 1.4044380187988281,
              "predictive_entropy": 0.08596263240256974,
              "shannon_entropy": 0.2828377555259962
            }
          }
        ],
        "cached": false,
        "request_time": 1.0073742866516113,
        "request_datetime": 1755801565
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Lusin's theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Nikolai Luzin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Nikolai Nikolayevich Luzin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Nikolai N. Luzin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Luzin, Nikolaj N."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lusin, Nicolas"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Luzin, N.N."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lusin, N.N."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Nikolai Nikolaevich Luzin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id54"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nLusin's theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Lusin's theorem, often",
            "logprob": -4.171142861032422,
            "tokens": [
              {
                "text": "L",
                "logprob": -0.6358163356781006
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -2.074220174108632e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.045934900641441345
              },
              {
                "text": ",",
                "logprob": -0.3218894600868225
              },
              {
                "text": "often",
                "logprob": -3.1674814224243164
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5213928311400196,
              "max_token_negative_log_likelihood": 3.1674811840057373,
              "predictive_entropy": 0.0934049593945474,
              "shannon_entropy": 0.4188937447634061
            }
          },
          {
            "text": "Lusin's theorem, also",
            "logprob": -1.5148927418231324,
            "tokens": [
              {
                "text": "L",
                "logprob": -0.6358163356781006
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -2.074220174108632e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.045934900641441345
              },
              {
                "text": ",",
                "logprob": -0.3218894600868225
              },
              {
                "text": "also",
                "logprob": -0.5112313032150269
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.18936159604118075,
              "max_token_negative_log_likelihood": 0.6358163356781006,
              "predictive_entropy": 0.1150591144998998,
              "shannon_entropy": 0.4188937447634061
            }
          },
          {
            "text": "Lusin's theorem, which",
            "logprob": -2.5773927418231324,
            "tokens": [
              {
                "text": "L",
                "logprob": -0.6358163356781006
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -2.074220174108632e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.045934900641441345
              },
              {
                "text": ",",
                "logprob": -0.3218894600868225
              },
              {
                "text": "which",
                "logprob": -1.5737313032150269
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.32217408114001955,
              "max_token_negative_log_likelihood": 1.5737311840057373,
              "predictive_entropy": 0.11750579948625273,
              "shannon_entropy": 0.4188937447634061
            }
          },
          {
            "text": "Lusin's theorem, also",
            "logprob": -1.5148927418231324,
            "tokens": [
              {
                "text": "L",
                "logprob": -0.6358163356781006
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -2.074220174108632e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.045934900641441345
              },
              {
                "text": ",",
                "logprob": -0.3218894600868225
              },
              {
                "text": "also",
                "logprob": -0.5112313032150269
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.18936159604118075,
              "max_token_negative_log_likelihood": 0.6358163356781006,
              "predictive_entropy": 0.1150591144998998,
              "shannon_entropy": 0.4188937447634061
            }
          },
          {
            "text": "Lusin's theorem, which",
            "logprob": -2.5773927418231324,
            "tokens": [
              {
                "text": "L",
                "logprob": -0.6358163356781006
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -2.074220174108632e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.045934900641441345
              },
              {
                "text": ",",
                "logprob": -0.3218894600868225
              },
              {
                "text": "which",
                "logprob": -1.5737313032150269
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.32217408114001955,
              "max_token_negative_log_likelihood": 1.5737311840057373,
              "predictive_entropy": 0.11750579948625273,
              "shannon_entropy": 0.4188937447634061
            }
          }
        ],
        "cached": false,
        "request_time": 1.013946294784546,
        "request_datetime": 1755801566
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Stolz\u2013Ces\u00e0ro theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Otto Stolz"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id55"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nStolz\u2013Ces\u00e0ro theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Stolz\u2013Ces\u00e0",
            "logprob": -0.15240883512205272,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.15197615325450897
              },
              {
                "text": "St",
                "logprob": -0.00026246439665555954
              },
              {
                "text": "ol",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.000163541772053577
              },
              {
                "text": "C",
                "logprob": 0.0
              },
              {
                "text": "es",
                "logprob": 0.0
              },
              {
                "text": "\u00e0",
                "logprob": -6.556489552167477e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01905110517413,
              "max_token_negative_log_likelihood": 0.15197612345218658,
              "predictive_entropy": 0.016372680270251294,
              "shannon_entropy": 0.06967750167990516
            }
          },
          {
            "text": "The Stolz\u2013Ces\u00e0",
            "logprob": -0.15240883512205272,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.15197615325450897
              },
              {
                "text": "St",
                "logprob": -0.00026246439665555954
              },
              {
                "text": "ol",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.000163541772053577
              },
              {
                "text": "C",
                "logprob": 0.0
              },
              {
                "text": "es",
                "logprob": 0.0
              },
              {
                "text": "\u00e0",
                "logprob": -6.556489552167477e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01905110517413,
              "max_token_negative_log_likelihood": 0.15197612345218658,
              "predictive_entropy": 0.016372680270251294,
              "shannon_entropy": 0.06967750167990516
            }
          },
          {
            "text": "The Stolz\u2013Ces\u00e0",
            "logprob": -0.15240883512205272,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.15197615325450897
              },
              {
                "text": "St",
                "logprob": -0.00026246439665555954
              },
              {
                "text": "ol",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.000163541772053577
              },
              {
                "text": "C",
                "logprob": 0.0
              },
              {
                "text": "es",
                "logprob": 0.0
              },
              {
                "text": "\u00e0",
                "logprob": -6.556489552167477e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01905110517413,
              "max_token_negative_log_likelihood": 0.15197612345218658,
              "predictive_entropy": 0.016372680270251294,
              "shannon_entropy": 0.06967750167990516
            }
          },
          {
            "text": "The Stolz\u2013Ces\u00e0",
            "logprob": -0.15240883512205272,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.15197615325450897
              },
              {
                "text": "St",
                "logprob": -0.00026246439665555954
              },
              {
                "text": "ol",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.000163541772053577
              },
              {
                "text": "C",
                "logprob": 0.0
              },
              {
                "text": "es",
                "logprob": 0.0
              },
              {
                "text": "\u00e0",
                "logprob": -6.556489552167477e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01905110517413,
              "max_token_negative_log_likelihood": 0.15197612345218658,
              "predictive_entropy": 0.016372680270251294,
              "shannon_entropy": 0.06967750167990516
            }
          },
          {
            "text": "Adolf Hurwitz\n\nThe Stol",
            "logprob": -11.874307445973955,
            "tokens": [
              {
                "text": "Adolf",
                "logprob": -9.183226585388184
              },
              {
                "text": "Hur",
                "logprob": -2.256575107574463
              },
              {
                "text": "witz",
                "logprob": -0.000302745756926015
              },
              {
                "text": "\n",
                "logprob": -0.2257138341665268
              },
              {
                "text": "\n",
                "logprob": -2.861018856492592e-06
              },
              {
                "text": "The",
                "logprob": -0.20071174204349518
              },
              {
                "text": "St",
                "logprob": -0.007774570025503635
              },
              {
                "text": "ol",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.4842762685953517,
              "max_token_negative_log_likelihood": 9.18312931060791,
              "predictive_entropy": 0.07369568198868137,
              "shannon_entropy": 0.3074881535372782
            }
          }
        ],
        "cached": false,
        "request_time": 1.0107340812683105,
        "request_datetime": 1755801566
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Hodge\u2013Arakelov theory was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Suren Arakelov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Suren Yuryevich Arakelov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Suren Yurievich Arakelov"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id56"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nHodge\u2013Arakelov theory was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Hodge\u2013Arakelov",
            "logprob": -0.528672114247172,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.5041198134422302
              },
              {
                "text": "H",
                "logprob": -0.002508352743461728
              },
              {
                "text": "odge",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.012909764423966408
              },
              {
                "text": "A",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "rak",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "el",
                "logprob": -0.009132872335612774
              },
              {
                "text": "ov",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06608402251735157,
              "max_token_negative_log_likelihood": 0.504119873046875,
              "predictive_entropy": 0.04110055611813834,
              "shannon_entropy": 0.10864794852526671
            }
          },
          {
            "text": "The Hodge\u2013Arakelov",
            "logprob": -0.528672114247172,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.5041198134422302
              },
              {
                "text": "H",
                "logprob": -0.002508352743461728
              },
              {
                "text": "odge",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.012909764423966408
              },
              {
                "text": "A",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "rak",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "el",
                "logprob": -0.009132872335612774
              },
              {
                "text": "ov",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06608402251735157,
              "max_token_negative_log_likelihood": 0.504119873046875,
              "predictive_entropy": 0.04110055611813834,
              "shannon_entropy": 0.10864794852526671
            }
          },
          {
            "text": "The Hodge\u2013Arakelov",
            "logprob": -0.528672114247172,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.5041198134422302
              },
              {
                "text": "H",
                "logprob": -0.002508352743461728
              },
              {
                "text": "odge",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.012909764423966408
              },
              {
                "text": "A",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "rak",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "el",
                "logprob": -0.009132872335612774
              },
              {
                "text": "ov",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06608402251735157,
              "max_token_negative_log_likelihood": 0.504119873046875,
              "predictive_entropy": 0.04110055611813834,
              "shannon_entropy": 0.10864794852526671
            }
          },
          {
            "text": "The Hodge\u2013Arakelov",
            "logprob": -0.528672114247172,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.5041198134422302
              },
              {
                "text": "H",
                "logprob": -0.002508352743461728
              },
              {
                "text": "odge",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.012909764423966408
              },
              {
                "text": "A",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "rak",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "el",
                "logprob": -0.009132872335612774
              },
              {
                "text": "ov",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06608402251735157,
              "max_token_negative_log_likelihood": 0.504119873046875,
              "predictive_entropy": 0.04110055611813834,
              "shannon_entropy": 0.10864794852526671
            }
          },
          {
            "text": "The Hodge\u2013Arakelov",
            "logprob": -0.528672114247172,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.5041198134422302
              },
              {
                "text": "H",
                "logprob": -0.002508352743461728
              },
              {
                "text": "odge",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.012909764423966408
              },
              {
                "text": "A",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "rak",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "el",
                "logprob": -0.009132872335612774
              },
              {
                "text": "ov",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06608402251735157,
              "max_token_negative_log_likelihood": 0.504119873046875,
              "predictive_entropy": 0.04110055611813834,
              "shannon_entropy": 0.10864794852526671
            }
          }
        ],
        "cached": false,
        "request_time": 1.0133554935455322,
        "request_datetime": 1755801566
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "divergence theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Mikhail Ostrogradsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mikhail Vasilievich Ostrogradsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mikhail Vasilyevich Ostrogradsky"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id57"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\ndivergence theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The divergence theorem, also known as",
            "logprob": -0.05840675817304941,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005425846204161644
              },
              {
                "text": "diver",
                "logprob": -0.02198677696287632
              },
              {
                "text": "gence",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -0.016663886606693268
              },
              {
                "text": "also",
                "logprob": -0.011792001314461231
              },
              {
                "text": "known",
                "logprob": -6.747018051100895e-05
              },
              {
                "text": "as",
                "logprob": -0.0024705384857952595
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00730084438055556,
              "max_token_negative_log_likelihood": 0.021986762061715126,
              "predictive_entropy": 0.007184941560804958,
              "shannon_entropy": 0.04229824535239857
            }
          },
          {
            "text": "The divergence theorem, also known as",
            "logprob": -0.05840675817304941,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005425846204161644
              },
              {
                "text": "diver",
                "logprob": -0.02198677696287632
              },
              {
                "text": "gence",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -0.016663886606693268
              },
              {
                "text": "also",
                "logprob": -0.011792001314461231
              },
              {
                "text": "known",
                "logprob": -6.747018051100895e-05
              },
              {
                "text": "as",
                "logprob": -0.0024705384857952595
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00730084438055556,
              "max_token_negative_log_likelihood": 0.021986762061715126,
              "predictive_entropy": 0.007184941560804958,
              "shannon_entropy": 0.04229824535239857
            }
          },
          {
            "text": "The divergence theorem, also known as",
            "logprob": -0.05840675817304941,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005425846204161644
              },
              {
                "text": "diver",
                "logprob": -0.02198677696287632
              },
              {
                "text": "gence",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -0.016663886606693268
              },
              {
                "text": "also",
                "logprob": -0.011792001314461231
              },
              {
                "text": "known",
                "logprob": -6.747018051100895e-05
              },
              {
                "text": "as",
                "logprob": -0.0024705384857952595
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00730084438055556,
              "max_token_negative_log_likelihood": 0.021986762061715126,
              "predictive_entropy": 0.007184941560804958,
              "shannon_entropy": 0.04229824535239857
            }
          },
          {
            "text": "The divergence theorem, also known as",
            "logprob": -0.05840675817304941,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005425846204161644
              },
              {
                "text": "diver",
                "logprob": -0.02198677696287632
              },
              {
                "text": "gence",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -0.016663886606693268
              },
              {
                "text": "also",
                "logprob": -0.011792001314461231
              },
              {
                "text": "known",
                "logprob": -6.747018051100895e-05
              },
              {
                "text": "as",
                "logprob": -0.0024705384857952595
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00730084438055556,
              "max_token_negative_log_likelihood": 0.021986762061715126,
              "predictive_entropy": 0.007184941560804958,
              "shannon_entropy": 0.04229824535239857
            }
          },
          {
            "text": "The divergence theorem, also known as",
            "logprob": -0.05840675817304941,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.005425846204161644
              },
              {
                "text": "diver",
                "logprob": -0.02198677696287632
              },
              {
                "text": "gence",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -0.016663886606693268
              },
              {
                "text": "also",
                "logprob": -0.011792001314461231
              },
              {
                "text": "known",
                "logprob": -6.747018051100895e-05
              },
              {
                "text": "as",
                "logprob": -0.0024705384857952595
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00730084438055556,
              "max_token_negative_log_likelihood": 0.021986762061715126,
              "predictive_entropy": 0.007184941560804958,
              "shannon_entropy": 0.04229824535239857
            }
          }
        ],
        "cached": false,
        "request_time": 1.013685941696167,
        "request_datetime": 1755801566
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Orr\u2013Sommerfeld equation was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Chia-Chiao Lin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "C.-C. Lin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id58"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nOrr\u2013Sommerfeld equation was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Orr-Sommerfeld",
            "logprob": -2.1195238432609926,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01771438494324684
              },
              {
                "text": "Or",
                "logprob": -0.0023078492376953363
              },
              {
                "text": "r",
                "logprob": -3.6954195820726454e-05
              },
              {
                "text": "-",
                "logprob": -2.0994555950164795
              },
              {
                "text": "S",
                "logprob": 0.0
              },
              {
                "text": "om",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "mer",
                "logprob": 0.0
              },
              {
                "text": "feld",
                "logprob": -8.702239938429557e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.26494045206641914,
              "max_token_negative_log_likelihood": 2.0994553565979004,
              "predictive_entropy": 0.03462296677513521,
              "shannon_entropy": 0.06647276014918901
            }
          },
          {
            "text": "The Orr-Sommerfeld",
            "logprob": -2.1195238432609926,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01771438494324684
              },
              {
                "text": "Or",
                "logprob": -0.0023078492376953363
              },
              {
                "text": "r",
                "logprob": -3.6954195820726454e-05
              },
              {
                "text": "-",
                "logprob": -2.0994555950164795
              },
              {
                "text": "S",
                "logprob": 0.0
              },
              {
                "text": "om",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "mer",
                "logprob": 0.0
              },
              {
                "text": "feld",
                "logprob": -8.702239938429557e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.26494045206641914,
              "max_token_negative_log_likelihood": 2.0994553565979004,
              "predictive_entropy": 0.03462296677513521,
              "shannon_entropy": 0.06647276014918901
            }
          },
          {
            "text": "The Orr\u2013Sommerfeld",
            "logprob": -0.15077087795816624,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01771438494324684
              },
              {
                "text": "Or",
                "logprob": -0.0023078492376953363
              },
              {
                "text": "r",
                "logprob": -3.6954195820726454e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.13070549070835114
              },
              {
                "text": "S",
                "logprob": 0.0
              },
              {
                "text": "om",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "mer",
                "logprob": 0.0
              },
              {
                "text": "feld",
                "logprob": -3.814689989667386e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.018846361198853856,
              "max_token_negative_log_likelihood": 0.13070549070835114,
              "predictive_entropy": 0.016804999207238325,
              "shannon_entropy": 0.06646838485905793
            }
          },
          {
            "text": "The Orr\u2013Sommerfeld",
            "logprob": -0.15077087795816624,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01771438494324684
              },
              {
                "text": "Or",
                "logprob": -0.0023078492376953363
              },
              {
                "text": "r",
                "logprob": -3.6954195820726454e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.13070549070835114
              },
              {
                "text": "S",
                "logprob": 0.0
              },
              {
                "text": "om",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "mer",
                "logprob": 0.0
              },
              {
                "text": "feld",
                "logprob": -3.814689989667386e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.018846361198853856,
              "max_token_negative_log_likelihood": 0.13070549070835114,
              "predictive_entropy": 0.016804999207238325,
              "shannon_entropy": 0.06646838485905793
            }
          },
          {
            "text": "The Orr\u2013Sommerfeld",
            "logprob": -0.15077087795816624,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.01771438494324684
              },
              {
                "text": "Or",
                "logprob": -0.0023078492376953363
              },
              {
                "text": "r",
                "logprob": -3.6954195820726454e-05
              },
              {
                "text": "\u2013",
                "logprob": -0.13070549070835114
              },
              {
                "text": "S",
                "logprob": 0.0
              },
              {
                "text": "om",
                "logprob": -2.3841830625315197e-06
              },
              {
                "text": "mer",
                "logprob": 0.0
              },
              {
                "text": "feld",
                "logprob": -3.814689989667386e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.018846361198853856,
              "max_token_negative_log_likelihood": 0.13070549070835114,
              "predictive_entropy": 0.016804999207238325,
              "shannon_entropy": 0.06646838485905793
            }
          }
        ],
        "cached": false,
        "request_time": 1.010103464126587,
        "request_datetime": 1755801567
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Hilbert's twenty-first problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Andrei Bolibrukh"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrey Andreyevich Bolibrukh"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrei Andreevich Bolibrukh"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id59"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nHilbert's twenty-first problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The statement pertaining to Hilbert",
            "logprob": -8.943326512523527,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.8151078820228577
              },
              {
                "text": "statement",
                "logprob": -3.8213486671447754
              },
              {
                "text": "per",
                "logprob": -3.943211078643799
              },
              {
                "text": "tain",
                "logprob": 0.0
              },
              {
                "text": "ing",
                "logprob": -0.1747453361749649
              },
              {
                "text": "to",
                "logprob": -0.0003997480380348861
              },
              {
                "text": "Hil",
                "logprob": -0.1885114163160324
              },
              {
                "text": "bert",
                "logprob": -2.3841830625315197e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1179156924812617,
              "max_token_negative_log_likelihood": 3.9432106018066406,
              "predictive_entropy": 0.10301715441130455,
              "shannon_entropy": 0.7352185115794558
            }
          },
          {
            "text": "David Hilbert's twenty-first",
            "logprob": -2.53283364287563,
            "tokens": [
              {
                "text": "David",
                "logprob": -2.127607822418213
              },
              {
                "text": "Hil",
                "logprob": -0.00018892886873800308
              },
              {
                "text": "bert",
                "logprob": -4.8040190449682996e-05
              },
              {
                "text": "'",
                "logprob": -0.3670511841773987
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "twenty",
                "logprob": -0.03793766722083092
              },
              {
                "text": "-",
                "logprob": 0.0
              },
              {
                "text": "first",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.31660420452180915,
              "max_token_negative_log_likelihood": 2.127607822418213,
              "predictive_entropy": 0.06806132053088731,
              "shannon_entropy": 0.294486546253516
            }
          },
          {
            "text": "David Hilbert's twenty-first",
            "logprob": -2.53283364287563,
            "tokens": [
              {
                "text": "David",
                "logprob": -2.127607822418213
              },
              {
                "text": "Hil",
                "logprob": -0.00018892886873800308
              },
              {
                "text": "bert",
                "logprob": -4.8040190449682996e-05
              },
              {
                "text": "'",
                "logprob": -0.3670511841773987
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "twenty",
                "logprob": -0.03793766722083092
              },
              {
                "text": "-",
                "logprob": 0.0
              },
              {
                "text": "first",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.31660420452180915,
              "max_token_negative_log_likelihood": 2.127607822418213,
              "predictive_entropy": 0.06806132053088731,
              "shannon_entropy": 0.294486546253516
            }
          },
          {
            "text": "Hilbert's twenty-first problem",
            "logprob": -0.849648983893978,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.8463578820228577
              },
              {
                "text": "bert",
                "logprob": -6.198863957251888e-06
              },
              {
                "text": "'",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "twenty",
                "logprob": -0.003282280405983329
              },
              {
                "text": "-",
                "logprob": 0.0
              },
              {
                "text": "first",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.10620612855115219,
              "max_token_negative_log_likelihood": 0.8463579416275024,
              "predictive_entropy": 0.045793282418230774,
              "shannon_entropy": 0.13387796122882986
            }
          },
          {
            "text": "The solution to Hilbert's twenty",
            "logprob": -1.4518241439227495,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.8151078820228577
              },
              {
                "text": "solution",
                "logprob": -0.6025987267494202
              },
              {
                "text": "to",
                "logprob": -0.02633284218609333
              },
              {
                "text": "Hil",
                "logprob": -0.0017171651124954224
              },
              {
                "text": "bert",
                "logprob": -1.0251946150674485e-05
              },
              {
                "text": "'",
                "logprob": -6.198863957251888e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "twenty",
                "logprob": -0.006051077041774988
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.18147803363706316,
              "max_token_negative_log_likelihood": 0.8151078820228577,
              "predictive_entropy": 0.09050106748151165,
              "shannon_entropy": 0.3736239874938305
            }
          }
        ],
        "cached": false,
        "request_time": 1.0095009803771973,
        "request_datetime": 1755801567
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Vinogradov's theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Ivan Matveevich Vinogradov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Vinogradov Ivan Matveevich"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ivan Matveyevich Vinogradov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ivan Vinogradov"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id60"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nVinogradov's theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Vinogradov's theorem is",
            "logprob": -3.79834251827468,
            "tokens": [
              {
                "text": "Vin",
                "logprob": -0.7389937043190002
              },
              {
                "text": "og",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "rad",
                "logprob": -1.311301275563892e-06
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -0.01411714032292366
              },
              {
                "text": "s",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": -0.002248499309644103
              },
              {
                "text": "is",
                "logprob": -3.0429816246032715
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4747927884164973,
              "max_token_negative_log_likelihood": 3.0429813861846924,
              "predictive_entropy": 0.06427883924324362,
              "shannon_entropy": 0.3617894223351379
            }
          },
          {
            "text": "Vinogradov's theorem,",
            "logprob": -1.61084251827468,
            "tokens": [
              {
                "text": "Vin",
                "logprob": -0.7389937043190002
              },
              {
                "text": "og",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "rad",
                "logprob": -1.311301275563892e-06
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -0.01411714032292366
              },
              {
                "text": "s",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": -0.002248499309644103
              },
              {
                "text": ",",
                "logprob": -0.8554816246032715
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2013553182188197,
              "max_token_negative_log_likelihood": 0.8554816246032715,
              "predictive_entropy": 0.09159377226013987,
              "shannon_entropy": 0.3617894223351379
            }
          },
          {
            "text": "The Vinogradov's theorem",
            "logprob": -2.089391738874653,
            "tokens": [
              {
                "text": "The",
                "logprob": -1.2389936447143555
              },
              {
                "text": "Vin",
                "logprob": -0.6346114873886108
              },
              {
                "text": "og",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "rad",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -0.21460308134555817
              },
              {
                "text": "s",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "theorem",
                "logprob": -0.0011826909612864256
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.26117398575300044,
              "max_token_negative_log_likelihood": 1.238993763923645,
              "predictive_entropy": 0.10870964844068709,
              "shannon_entropy": 0.45232407745702663
            }
          },
          {
            "text": "Askold Vinogradov\n\n",
            "logprob": -3.780698099336391,
            "tokens": [
              {
                "text": "Ask",
                "logprob": -1.7077436447143555
              },
              {
                "text": "old",
                "logprob": -2.9802276912960224e-06
              },
              {
                "text": "Vin",
                "logprob": -0.0024245171807706356
              },
              {
                "text": "og",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "rad",
                "logprob": -2.4437606043647975e-05
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": "\n",
                "logprob": -2.070502281188965
              },
              {
                "text": "\n",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.47258725966969806,
              "max_token_negative_log_likelihood": 2.070502281188965,
              "predictive_entropy": 0.0716441405151329,
              "shannon_entropy": 0.355041599616726
            }
          },
          {
            "text": "Askold Vinogradov. The",
            "logprob": -3.5587823178384426,
            "tokens": [
              {
                "text": "Ask",
                "logprob": -1.7077436447143555
              },
              {
                "text": "old",
                "logprob": -2.9802276912960224e-06
              },
              {
                "text": "Vin",
                "logprob": -0.0024245171807706356
              },
              {
                "text": "og",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "rad",
                "logprob": -2.4437606043647975e-05
              },
              {
                "text": "ov",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": -1.2892522811889648
              },
              {
                "text": "The",
                "logprob": -0.5593343377113342
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.44484779443303246,
              "max_token_negative_log_likelihood": 1.7077436447143555,
              "predictive_entropy": 0.12336060601811027,
              "shannon_entropy": 0.5510042073681518
            }
          }
        ],
        "cached": false,
        "request_time": 1.0117416381835938,
        "request_datetime": 1755801567
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Liouville's formula was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Mikhail Ostrogradsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mikhail Vasilievich Ostrogradsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mikhail Vasilyevich Ostrogradsky"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id61"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nLiouville's formula was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Liouville's formula is a",
            "logprob": -2.341531355382358,
            "tokens": [
              {
                "text": "Li",
                "logprob": -0.004104167688637972
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "ville",
                "logprob": -2.9802276912960224e-06
              },
              {
                "text": "'",
                "logprob": -2.2172682292875834e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "formula",
                "logprob": -0.002764810109511018
              },
              {
                "text": "is",
                "logprob": -1.777274250984192
              },
              {
                "text": "a",
                "logprob": -0.557362973690033
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2926914108705887,
              "max_token_negative_log_likelihood": 1.7772741317749023,
              "predictive_entropy": 0.07832692621528281,
              "shannon_entropy": 0.328969241504268
            }
          },
          {
            "text": "Liouville's formula, which",
            "logprob": -1.1058901739133944,
            "tokens": [
              {
                "text": "Li",
                "logprob": -0.004104167688637972
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "ville",
                "logprob": -2.9802276912960224e-06
              },
              {
                "text": "'",
                "logprob": -2.2172682292875834e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "formula",
                "logprob": -0.002764810109511018
              },
              {
                "text": ",",
                "logprob": -0.6210242509841919
              },
              {
                "text": "which",
                "logprob": -0.47797179222106934
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.13823626318696824,
              "max_token_negative_log_likelihood": 0.6210241913795471,
              "predictive_entropy": 0.07962070836006774,
              "shannon_entropy": 0.30623522532422953
            }
          },
          {
            "text": "Liouville's formula, which",
            "logprob": -1.1058901739133944,
            "tokens": [
              {
                "text": "Li",
                "logprob": -0.004104167688637972
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "ville",
                "logprob": -2.9802276912960224e-06
              },
              {
                "text": "'",
                "logprob": -2.2172682292875834e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "formula",
                "logprob": -0.002764810109511018
              },
              {
                "text": ",",
                "logprob": -0.6210242509841919
              },
              {
                "text": "which",
                "logprob": -0.47797179222106934
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.13823626318696824,
              "max_token_negative_log_likelihood": 0.6210241913795471,
              "predictive_entropy": 0.07962070836006774,
              "shannon_entropy": 0.30623522532422953
            }
          },
          {
            "text": "Liouville's formula is a",
            "logprob": -2.341531355382358,
            "tokens": [
              {
                "text": "Li",
                "logprob": -0.004104167688637972
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "ville",
                "logprob": -2.9802276912960224e-06
              },
              {
                "text": "'",
                "logprob": -2.2172682292875834e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "formula",
                "logprob": -0.002764810109511018
              },
              {
                "text": "is",
                "logprob": -1.777274250984192
              },
              {
                "text": "a",
                "logprob": -0.557362973690033
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2926914108705887,
              "max_token_negative_log_likelihood": 1.7772741317749023,
              "predictive_entropy": 0.07832692621528281,
              "shannon_entropy": 0.328969241504268
            }
          },
          {
            "text": "Liouville's formula, which",
            "logprob": -1.1058901739133944,
            "tokens": [
              {
                "text": "Li",
                "logprob": -0.004104167688637972
              },
              {
                "text": "ou",
                "logprob": 0.0
              },
              {
                "text": "ville",
                "logprob": -2.9802276912960224e-06
              },
              {
                "text": "'",
                "logprob": -2.2172682292875834e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "formula",
                "logprob": -0.002764810109511018
              },
              {
                "text": ",",
                "logprob": -0.6210242509841919
              },
              {
                "text": "which",
                "logprob": -0.47797179222106934
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.13823626318696824,
              "max_token_negative_log_likelihood": 0.6210241913795471,
              "predictive_entropy": 0.07962070836006774,
              "shannon_entropy": 0.30623522532422953
            }
          }
        ],
        "cached": false,
        "request_time": 1.0001945495605469,
        "request_datetime": 1755801567
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Girsanov theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Igor Girsanov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Igor Vladimirovich Girsanov"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id62"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nGirsanov theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Girsanov theorem was solved",
            "logprob": -0.8358776871737064,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.3162825405597687
              },
              {
                "text": "G",
                "logprob": -0.005696017760783434
              },
              {
                "text": "irs",
                "logprob": 0.0
              },
              {
                "text": "an",
                "logprob": -5.364403477869928e-06
              },
              {
                "text": "ov",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "theorem",
                "logprob": -4.6491513785440475e-06
              },
              {
                "text": "was",
                "logprob": -0.45367491245269775
              },
              {
                "text": "solved",
                "logprob": -0.06021086499094963
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.10448470682993616,
              "max_token_negative_log_likelihood": 0.453674852848053,
              "predictive_entropy": 0.07263848825442665,
              "shannon_entropy": 0.24235157062094448
            }
          },
          {
            "text": "The Girsanov theorem was solved",
            "logprob": -0.8358776871737064,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.3162825405597687
              },
              {
                "text": "G",
                "logprob": -0.005696017760783434
              },
              {
                "text": "irs",
                "logprob": 0.0
              },
              {
                "text": "an",
                "logprob": -5.364403477869928e-06
              },
              {
                "text": "ov",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "theorem",
                "logprob": -4.6491513785440475e-06
              },
              {
                "text": "was",
                "logprob": -0.45367491245269775
              },
              {
                "text": "solved",
                "logprob": -0.06021086499094963
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.10448470682993616,
              "max_token_negative_log_likelihood": 0.453674852848053,
              "predictive_entropy": 0.07263848825442665,
              "shannon_entropy": 0.24235157062094448
            }
          },
          {
            "text": "The Girsanov theorem was solved",
            "logprob": -0.8358776871737064,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.3162825405597687
              },
              {
                "text": "G",
                "logprob": -0.005696017760783434
              },
              {
                "text": "irs",
                "logprob": 0.0
              },
              {
                "text": "an",
                "logprob": -5.364403477869928e-06
              },
              {
                "text": "ov",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "theorem",
                "logprob": -4.6491513785440475e-06
              },
              {
                "text": "was",
                "logprob": -0.45367491245269775
              },
              {
                "text": "solved",
                "logprob": -0.06021086499094963
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.10448470682993616,
              "max_token_negative_log_likelihood": 0.453674852848053,
              "predictive_entropy": 0.07263848825442665,
              "shannon_entropy": 0.24235157062094448
            }
          },
          {
            "text": "The Girsanov theorem, which",
            "logprob": -2.401260603654009,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.3162825405597687
              },
              {
                "text": "G",
                "logprob": -0.005696017760783434
              },
              {
                "text": "irs",
                "logprob": 0.0
              },
              {
                "text": "an",
                "logprob": -5.364403477869928e-06
              },
              {
                "text": "ov",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "theorem",
                "logprob": -4.6491513785440475e-06
              },
              {
                "text": ",",
                "logprob": -1.3911749124526978
              },
              {
                "text": "which",
                "logprob": -0.6880937814712524
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3001575890851029,
              "max_token_negative_log_likelihood": 1.3911749124526978,
              "predictive_entropy": 0.11601137637245529,
              "shannon_entropy": 0.3809683895556235
            }
          },
          {
            "text": "The Girsanov theorem was largely",
            "logprob": -7.2108775269862235,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.3162825405597687
              },
              {
                "text": "G",
                "logprob": -0.005696017760783434
              },
              {
                "text": "irs",
                "logprob": 0.0
              },
              {
                "text": "an",
                "logprob": -5.364403477869928e-06
              },
              {
                "text": "ov",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "theorem",
                "logprob": -4.6491513785440475e-06
              },
              {
                "text": "was",
                "logprob": -0.45367491245269775
              },
              {
                "text": "largely",
                "logprob": -6.435210704803467
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.9013589147400864,
              "max_token_negative_log_likelihood": 6.43520450592041,
              "predictive_entropy": 0.06684224342080824,
              "shannon_entropy": 0.24235157062094448
            }
          }
        ],
        "cached": false,
        "request_time": 1.0018177032470703,
        "request_datetime": 1755801568
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Hilbert's fifth problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "John von Neumann"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "John Von Neumann"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Neumann, John von"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Janos Lajos Neumann"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "J\u00e1nos Lajos Neumann"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "von Neumann"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lev Pontryagin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lev Semenovich Pontryagin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lev Pontrjagin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lev Semyonovich Pontryagin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrew Gleason"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrew M. Gleason"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrew Mattei Gleason"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrew Mattei Gleason"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Deane Montgomery"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Leo Zippin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id63"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nHilbert's fifth problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Hilbert's fifth problem was fam",
            "logprob": -4.197917026603129,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.15096698701381683
              },
              {
                "text": "bert",
                "logprob": -2.4199192921514623e-05
              },
              {
                "text": "'",
                "logprob": -1.3828182090946939e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "fifth",
                "logprob": -6.735097849741578e-05
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "was",
                "logprob": -0.8338153958320618
              },
              {
                "text": "fam",
                "logprob": -3.213029146194458
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5247395973250395,
              "max_token_negative_log_likelihood": 3.213028907775879,
              "predictive_entropy": 0.07767414827196717,
              "shannon_entropy": 0.365945186899614
            }
          },
          {
            "text": "Hilbert's fifth problem was solved",
            "logprob": -1.2916670862077737,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.15096698701381683
              },
              {
                "text": "bert",
                "logprob": -2.4199192921514623e-05
              },
              {
                "text": "'",
                "logprob": -1.3828182090946939e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "fifth",
                "logprob": -6.735097849741578e-05
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "was",
                "logprob": -0.8338153958320618
              },
              {
                "text": "solved",
                "logprob": -0.3067792057991028
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.16145838085265218,
              "max_token_negative_log_likelihood": 0.8338153958320618,
              "predictive_entropy": 0.08973131854384064,
              "shannon_entropy": 0.365945186899614
            }
          },
          {
            "text": "Hilbert's fifth problem was solved",
            "logprob": -1.2916670862077737,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.15096698701381683
              },
              {
                "text": "bert",
                "logprob": -2.4199192921514623e-05
              },
              {
                "text": "'",
                "logprob": -1.3828182090946939e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "fifth",
                "logprob": -6.735097849741578e-05
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "was",
                "logprob": -0.8338153958320618
              },
              {
                "text": "solved",
                "logprob": -0.3067792057991028
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.16145838085265218,
              "max_token_negative_log_likelihood": 0.8338153958320618,
              "predictive_entropy": 0.08973131854384064,
              "shannon_entropy": 0.365945186899614
            }
          },
          {
            "text": "Hilbert's fifth problem, concerning",
            "logprob": -3.259783548438456,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.15096698701381683
              },
              {
                "text": "bert",
                "logprob": -2.4199192921514623e-05
              },
              {
                "text": "'",
                "logprob": -1.3828182090946939e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "fifth",
                "logprob": -6.735097849741578e-05
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ",",
                "logprob": -0.8338153958320618
              },
              {
                "text": "concerning",
                "logprob": -2.274895668029785
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4074729423567778,
              "max_token_negative_log_likelihood": 2.274895668029785,
              "predictive_entropy": 0.09074937705247521,
              "shannon_entropy": 0.33886521725506746
            }
          },
          {
            "text": "Hilbert's fifth problem was solved",
            "logprob": -1.2916670862077737,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.15096698701381683
              },
              {
                "text": "bert",
                "logprob": -2.4199192921514623e-05
              },
              {
                "text": "'",
                "logprob": -1.3828182090946939e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "fifth",
                "logprob": -6.735097849741578e-05
              },
              {
                "text": "problem",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "was",
                "logprob": -0.8338153958320618
              },
              {
                "text": "solved",
                "logprob": -0.3067792057991028
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.16145838085265218,
              "max_token_negative_log_likelihood": 0.8338153958320618,
              "predictive_entropy": 0.08973131854384064,
              "shannon_entropy": 0.365945186899614
            }
          }
        ],
        "cached": false,
        "request_time": 1.010645866394043,
        "request_datetime": 1755801568
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Conway knot was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Lisa Piccirillo"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lisa Marie Piccirillo"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lisa M. Piccirillo"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id64"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nConway knot was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Conway knot is attributed to",
            "logprob": -4.491725582751656,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.05899812653660774
              },
              {
                "text": "Con",
                "logprob": -0.0005585778853856027
              },
              {
                "text": "way",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "kn",
                "logprob": -5.769562994828448e-05
              },
              {
                "text": "ot",
                "logprob": -5.602820692729438e-06
              },
              {
                "text": "is",
                "logprob": -1.2304201126098633
              },
              {
                "text": "attributed",
                "logprob": -3.1955020427703857
              },
              {
                "text": "to",
                "logprob": -0.006182947661727667
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5614656707395653,
              "max_token_negative_log_likelihood": 3.1955018043518066,
              "predictive_entropy": 0.06908993274679176,
              "shannon_entropy": 0.4091082157613073
            }
          },
          {
            "text": "The Conway knot was solved by",
            "logprob": -1.637965114443773,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.05899812653660774
              },
              {
                "text": "Con",
                "logprob": -0.0005585778853856027
              },
              {
                "text": "way",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "kn",
                "logprob": -5.769562994828448e-05
              },
              {
                "text": "ot",
                "logprob": -5.602820692729438e-06
              },
              {
                "text": "was",
                "logprob": -1.1991701126098633
              },
              {
                "text": "solved",
                "logprob": -0.374939888715744
              },
              {
                "text": "by",
                "logprob": -0.004234633408486843
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.20474563804528145,
              "max_token_negative_log_likelihood": 1.1991701126098633,
              "predictive_entropy": 0.08495592637460447,
              "shannon_entropy": 0.37747320421499353
            }
          },
          {
            "text": "The Conway knot is a mathematical",
            "logprob": -2.980311850673729,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.05899812653660774
              },
              {
                "text": "Con",
                "logprob": -0.0005585778853856027
              },
              {
                "text": "way",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "kn",
                "logprob": -5.769562994828448e-05
              },
              {
                "text": "ot",
                "logprob": -5.602820692729438e-06
              },
              {
                "text": "is",
                "logprob": -1.2304201126098633
              },
              {
                "text": "a",
                "logprob": -0.883001983165741
              },
              {
                "text": "mathematical",
                "logprob": -0.807269275188446
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.37253897372939093,
              "max_token_negative_log_likelihood": 1.2304201126098633,
              "predictive_entropy": 0.14262377782266356,
              "shannon_entropy": 0.6644221505196128
            }
          },
          {
            "text": "The Conway knot, which is",
            "logprob": -3.0121573532290995,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.05899812653660774
              },
              {
                "text": "Con",
                "logprob": -0.0005585778853856027
              },
              {
                "text": "way",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "kn",
                "logprob": -5.769562994828448e-05
              },
              {
                "text": "ot",
                "logprob": -5.602820692729438e-06
              },
              {
                "text": ",",
                "logprob": -1.2929201126098633
              },
              {
                "text": "which",
                "logprob": -1.624276876449585
              },
              {
                "text": "is",
                "logprob": -0.03533988445997238
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.37651965689219935,
              "max_token_negative_log_likelihood": 1.6242767572402954,
              "predictive_entropy": 0.09566108402337647,
              "shannon_entropy": 0.4909598937304054
            }
          },
          {
            "text": "The Conway knot is named after",
            "logprob": -2.24497284426468,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.05899812653660774
              },
              {
                "text": "Con",
                "logprob": -0.0005585778853856027
              },
              {
                "text": "way",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "kn",
                "logprob": -5.769562994828448e-05
              },
              {
                "text": "ot",
                "logprob": -5.602820692729438e-06
              },
              {
                "text": "is",
                "logprob": -1.2304201126098633
              },
              {
                "text": "named",
                "logprob": -0.945501983165741
              },
              {
                "text": "after",
                "logprob": -0.00943026877939701
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2806216053788404,
              "max_token_negative_log_likelihood": 1.2304201126098633,
              "predictive_entropy": 0.0990482910723216,
              "shannon_entropy": 0.41078441618469697
            }
          }
        ],
        "cached": false,
        "request_time": 1.0116753578186035,
        "request_datetime": 1755801568
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Gershgorin circle theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Semyon Aranovich Gershgorin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Semyon Aronovich Gershgorin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id65"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nGershgorin circle theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Gershgorin circle theorem",
            "logprob": -0.688369504030554,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.2584932744503021
              },
              {
                "text": "G",
                "logprob": -0.0011520899133756757
              },
              {
                "text": "ers",
                "logprob": -2.288792165927589e-05
              },
              {
                "text": "h",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "gor",
                "logprob": 0.0
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "circle",
                "logprob": -0.42870113253593445
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08604619380276013,
              "max_token_negative_log_likelihood": 0.42870116233825684,
              "predictive_entropy": 0.060002804701071,
              "shannon_entropy": 0.1955097164591452
            }
          },
          {
            "text": "The Gershgorin circle theorem",
            "logprob": -0.688369504030554,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.2584932744503021
              },
              {
                "text": "G",
                "logprob": -0.0011520899133756757
              },
              {
                "text": "ers",
                "logprob": -2.288792165927589e-05
              },
              {
                "text": "h",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "gor",
                "logprob": 0.0
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "circle",
                "logprob": -0.42870113253593445
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08604619380276013,
              "max_token_negative_log_likelihood": 0.42870116233825684,
              "predictive_entropy": 0.060002804701071,
              "shannon_entropy": 0.1955097164591452
            }
          },
          {
            "text": "The Gershgorin circle theorem",
            "logprob": -0.688369504030554,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.2584932744503021
              },
              {
                "text": "G",
                "logprob": -0.0011520899133756757
              },
              {
                "text": "ers",
                "logprob": -2.288792165927589e-05
              },
              {
                "text": "h",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "gor",
                "logprob": 0.0
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "circle",
                "logprob": -0.42870113253593445
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08604619380276013,
              "max_token_negative_log_likelihood": 0.42870116233825684,
              "predictive_entropy": 0.060002804701071,
              "shannon_entropy": 0.1955097164591452
            }
          },
          {
            "text": "The Gershgorin circle theorem",
            "logprob": -0.688369504030554,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.2584932744503021
              },
              {
                "text": "G",
                "logprob": -0.0011520899133756757
              },
              {
                "text": "ers",
                "logprob": -2.288792165927589e-05
              },
              {
                "text": "h",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "gor",
                "logprob": 0.0
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "circle",
                "logprob": -0.42870113253593445
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08604619380276013,
              "max_token_negative_log_likelihood": 0.42870116233825684,
              "predictive_entropy": 0.060002804701071,
              "shannon_entropy": 0.1955097164591452
            }
          },
          {
            "text": "The Gershgorin circle theorem",
            "logprob": -0.688369504030554,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.2584932744503021
              },
              {
                "text": "G",
                "logprob": -0.0011520899133756757
              },
              {
                "text": "ers",
                "logprob": -2.288792165927589e-05
              },
              {
                "text": "h",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "gor",
                "logprob": 0.0
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "circle",
                "logprob": -0.42870113253593445
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08604619380276013,
              "max_token_negative_log_likelihood": 0.42870116233825684,
              "predictive_entropy": 0.060002804701071,
              "shannon_entropy": 0.1955097164591452
            }
          }
        ],
        "cached": false,
        "request_time": 1.0095131397247314,
        "request_datetime": 1755801568
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Selberg's zeta function conjecture was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Anatolii Alexeevitch Karatsuba"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Anatoly A. Karatsuba"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Anatoly Alexeyevich Karatsuba"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id66"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nSelberg's zeta function conjecture was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "At present, there is no record nor",
            "logprob": -16.316960786934942,
            "tokens": [
              {
                "text": "At",
                "logprob": -2.906266927719116
              },
              {
                "text": "present",
                "logprob": -1.9990947246551514
              },
              {
                "text": ",",
                "logprob": -0.006951315328478813
              },
              {
                "text": "there",
                "logprob": -1.3388521671295166
              },
              {
                "text": "is",
                "logprob": -0.10976565629243851
              },
              {
                "text": "no",
                "logprob": -0.003623231779783964
              },
              {
                "text": "record",
                "logprob": -1.3545292615890503
              },
              {
                "text": "nor",
                "logprob": -8.597877502441406
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 2.039613261062186,
              "max_token_negative_log_likelihood": 8.597823143005371,
              "predictive_entropy": 0.1550871974322945,
              "shannon_entropy": 0.7547573503106833
            }
          },
          {
            "text": "Selberg's zeta function conject",
            "logprob": -0.2526129581467842,
            "tokens": [
              {
                "text": "Sel",
                "logprob": -0.2500168979167938
              },
              {
                "text": "berg",
                "logprob": -4.768360213347478e-06
              },
              {
                "text": "'",
                "logprob": -2.3245540432981215e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": -0.002567211864516139
              },
              {
                "text": "eta",
                "logprob": 0.0
              },
              {
                "text": "function",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "conject",
                "logprob": -5.960462772236497e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03157662036286624,
              "max_token_negative_log_likelihood": 0.2500169277191162,
              "predictive_entropy": 0.02466244293592368,
              "shannon_entropy": 0.11208257279387324
            }
          },
          {
            "text": "Selberg's zeta function conject",
            "logprob": -0.2526129581467842,
            "tokens": [
              {
                "text": "Sel",
                "logprob": -0.2500168979167938
              },
              {
                "text": "berg",
                "logprob": -4.768360213347478e-06
              },
              {
                "text": "'",
                "logprob": -2.3245540432981215e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": -0.002567211864516139
              },
              {
                "text": "eta",
                "logprob": 0.0
              },
              {
                "text": "function",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "conject",
                "logprob": -5.960462772236497e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03157662036286624,
              "max_token_negative_log_likelihood": 0.2500169277191162,
              "predictive_entropy": 0.02466244293592368,
              "shannon_entropy": 0.11208257279387324
            }
          },
          {
            "text": "Selberg's zeta function conject",
            "logprob": -0.2526129581467842,
            "tokens": [
              {
                "text": "Sel",
                "logprob": -0.2500168979167938
              },
              {
                "text": "berg",
                "logprob": -4.768360213347478e-06
              },
              {
                "text": "'",
                "logprob": -2.3245540432981215e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": -0.002567211864516139
              },
              {
                "text": "eta",
                "logprob": 0.0
              },
              {
                "text": "function",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "conject",
                "logprob": -5.960462772236497e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03157662036286624,
              "max_token_negative_log_likelihood": 0.2500169277191162,
              "predictive_entropy": 0.02466244293592368,
              "shannon_entropy": 0.11208257279387324
            }
          },
          {
            "text": "The Saukrieg (a term likely",
            "logprob": -11.181457795202164,
            "tokens": [
              {
                "text": "The",
                "logprob": -2.218766927719116
              },
              {
                "text": "Sau",
                "logprob": -0.4547414779663086
              },
              {
                "text": "krie",
                "logprob": -0.12250379472970963
              },
              {
                "text": "g",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "(",
                "logprob": -2.077359199523926
              },
              {
                "text": "a",
                "logprob": -1.9044519662857056
              },
              {
                "text": "term",
                "logprob": -0.9493753910064697
              },
              {
                "text": "likely",
                "logprob": -3.4542579650878906
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3976821145043488,
              "max_token_negative_log_likelihood": 3.4542574882507324,
              "predictive_entropy": 0.2073270129039173,
              "shannon_entropy": 1.3437556050730564
            }
          }
        ],
        "cached": false,
        "request_time": 1.0189833641052246,
        "request_datetime": 1755801569
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Slutsky's theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Eugen Slutsky"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Evgeny Evgenievich Slutsky"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id67"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nSlutsky's theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Slutsky's theorem was solved",
            "logprob": -0.36381604094435716,
            "tokens": [
              {
                "text": "Sl",
                "logprob": -0.03861137852072716
              },
              {
                "text": "ut",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "sky",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "'",
                "logprob": -6.603976362384856e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0008590107318013906
              },
              {
                "text": "was",
                "logprob": -0.29622554779052734
              },
              {
                "text": "solved",
                "logprob": -0.02805120311677456
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.045477012685552154,
              "max_token_negative_log_likelihood": 0.29622554779052734,
              "predictive_entropy": 0.03570382386959636,
              "shannon_entropy": 0.15993724918292962
            }
          },
          {
            "text": "Slutsky's theorem, which",
            "logprob": -2.8920758491419747,
            "tokens": [
              {
                "text": "Sl",
                "logprob": -0.03861137852072716
              },
              {
                "text": "ut",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "sky",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "'",
                "logprob": -6.603976362384856e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0008590107318013906
              },
              {
                "text": ",",
                "logprob": -1.9212255477905273
              },
              {
                "text": "which",
                "logprob": -0.9313110113143921
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3615094859162866,
              "max_token_negative_log_likelihood": 1.9212255477905273,
              "predictive_entropy": 0.0857958753737762,
              "shannon_entropy": 0.29656216284560166
            }
          },
          {
            "text": "Slutsky's theorem was solved",
            "logprob": -0.36381604094435716,
            "tokens": [
              {
                "text": "Sl",
                "logprob": -0.03861137852072716
              },
              {
                "text": "ut",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "sky",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "'",
                "logprob": -6.603976362384856e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0008590107318013906
              },
              {
                "text": "was",
                "logprob": -0.29622554779052734
              },
              {
                "text": "solved",
                "logprob": -0.02805120311677456
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.045477012685552154,
              "max_token_negative_log_likelihood": 0.29622554779052734,
              "predictive_entropy": 0.03570382386959636,
              "shannon_entropy": 0.15993724918292962
            }
          },
          {
            "text": "Slutsky's theorem was solved",
            "logprob": -0.36381604094435716,
            "tokens": [
              {
                "text": "Sl",
                "logprob": -0.03861137852072716
              },
              {
                "text": "ut",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "sky",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "'",
                "logprob": -6.603976362384856e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0008590107318013906
              },
              {
                "text": "was",
                "logprob": -0.29622554779052734
              },
              {
                "text": "solved",
                "logprob": -0.02805120311677456
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.045477012685552154,
              "max_token_negative_log_likelihood": 0.29622554779052734,
              "predictive_entropy": 0.03570382386959636,
              "shannon_entropy": 0.15993724918292962
            }
          },
          {
            "text": "Slutsky's theorem in probability",
            "logprob": -3.293254417743583,
            "tokens": [
              {
                "text": "Sl",
                "logprob": -0.03861137852072716
              },
              {
                "text": "ut",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "sky",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "'",
                "logprob": -6.603976362384856e-05
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.0008590107318013906
              },
              {
                "text": "in",
                "logprob": -2.8899755477905273
              },
              {
                "text": "probability",
                "logprob": -0.36373957991600037
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.41165678091445557,
              "max_token_negative_log_likelihood": 2.8899753093719482,
              "predictive_entropy": 0.056439907956416846,
              "shannon_entropy": 0.2603975661687752
            }
          }
        ],
        "cached": false,
        "request_time": 1.0073285102844238,
        "request_datetime": 1755801569
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Novikov's compact leaf theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Sergei Novikov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sergei Petrovich Novikov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "S. P. Novikov"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id68"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nNovikov's compact leaf theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Novikov's compact leaf theorem",
            "logprob": -0.005750314317971572,
            "tokens": [
              {
                "text": "Nov",
                "logprob": -0.003619787283241749
              },
              {
                "text": "ik",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "'",
                "logprob": -0.00019727191829588264
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "compact",
                "logprob": -0.0019328974885866046
              },
              {
                "text": "leaf",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.000718783050620786,
              "max_token_negative_log_likelihood": 0.003619777038693428,
              "predictive_entropy": 0.000716676760930568,
              "shannon_entropy": 0.00573435058173466
            }
          },
          {
            "text": "Novikov's compact leaf theorem",
            "logprob": -0.005750314317971572,
            "tokens": [
              {
                "text": "Nov",
                "logprob": -0.003619787283241749
              },
              {
                "text": "ik",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "'",
                "logprob": -0.00019727191829588264
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "compact",
                "logprob": -0.0019328974885866046
              },
              {
                "text": "leaf",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.000718783050620786,
              "max_token_negative_log_likelihood": 0.003619777038693428,
              "predictive_entropy": 0.000716676760930568,
              "shannon_entropy": 0.00573435058173466
            }
          },
          {
            "text": "Novikov's compact leaf theorem",
            "logprob": -0.005750314317971572,
            "tokens": [
              {
                "text": "Nov",
                "logprob": -0.003619787283241749
              },
              {
                "text": "ik",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "'",
                "logprob": -0.00019727191829588264
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "compact",
                "logprob": -0.0019328974885866046
              },
              {
                "text": "leaf",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.000718783050620786,
              "max_token_negative_log_likelihood": 0.003619777038693428,
              "predictive_entropy": 0.000716676760930568,
              "shannon_entropy": 0.00573435058173466
            }
          },
          {
            "text": "Novikov's compact leaf theorem",
            "logprob": -0.005750314317971572,
            "tokens": [
              {
                "text": "Nov",
                "logprob": -0.003619787283241749
              },
              {
                "text": "ik",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "'",
                "logprob": -0.00019727191829588264
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "compact",
                "logprob": -0.0019328974885866046
              },
              {
                "text": "leaf",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.000718783050620786,
              "max_token_negative_log_likelihood": 0.003619777038693428,
              "predictive_entropy": 0.000716676760930568,
              "shannon_entropy": 0.00573435058173466
            }
          },
          {
            "text": "Novikov's compact leaf theorem",
            "logprob": -0.005750314317971572,
            "tokens": [
              {
                "text": "Nov",
                "logprob": -0.003619787283241749
              },
              {
                "text": "ik",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ov",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "'",
                "logprob": -0.00019727191829588264
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "compact",
                "logprob": -0.0019328974885866046
              },
              {
                "text": "leaf",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "theorem",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.000718783050620786,
              "max_token_negative_log_likelihood": 0.003619777038693428,
              "predictive_entropy": 0.000716676760930568,
              "shannon_entropy": 0.00573435058173466
            }
          }
        ],
        "cached": false,
        "request_time": 1.0099549293518066,
        "request_datetime": 1755801569
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Seven Bridges of K\u00f6nigsberg was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Leonhard Euler"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Euler, Leonhard"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "L. Euler"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id69"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nSeven Bridges of K\u00f6nigsberg was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Leonhard Euler.\n\nIn",
            "logprob": -5.24118092637422,
            "tokens": [
              {
                "text": "Leon",
                "logprob": -1.5133564472198486
              },
              {
                "text": "hard",
                "logprob": -1.883488948806189e-05
              },
              {
                "text": "E",
                "logprob": -2.0265558760002023e-06
              },
              {
                "text": "uler",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ".",
                "logprob": -0.23386552929878235
              },
              {
                "text": "\n",
                "logprob": -2.7909188270568848
              },
              {
                "text": "\n",
                "logprob": -3.6954811548639555e-06
              },
              {
                "text": "In",
                "logprob": -0.7030154466629028
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6551475674147884,
              "max_token_negative_log_likelihood": 2.7909185886383057,
              "predictive_entropy": 0.12970466164418326,
              "shannon_entropy": 0.49989680537308345
            }
          },
          {
            "text": "Leonhard Euler is the mathematic",
            "logprob": -4.061040345399071,
            "tokens": [
              {
                "text": "Leon",
                "logprob": -1.5133564472198486
              },
              {
                "text": "hard",
                "logprob": -1.883488948806189e-05
              },
              {
                "text": "E",
                "logprob": -2.0265558760002023e-06
              },
              {
                "text": "uler",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "is",
                "logprob": -2.10886549949646
              },
              {
                "text": "the",
                "logprob": -0.39584946632385254
              },
              {
                "text": "math",
                "logprob": -0.04294795170426369
              },
              {
                "text": "ematic",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5076300231965281,
              "max_token_negative_log_likelihood": 2.10886549949646,
              "predictive_entropy": 0.11209662256393926,
              "shannon_entropy": 0.31797382733068247
            }
          },
          {
            "text": "The Seven Bridges of K\u00f6nigs",
            "logprob": -0.3057559020802998,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.26335638761520386
              },
              {
                "text": "Seven",
                "logprob": -0.04239736869931221
              },
              {
                "text": "Br",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "id",
                "logprob": 0.0
              },
              {
                "text": "ges",
                "logprob": 0.0
              },
              {
                "text": "of",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "K\u00f6nig",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "s",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03821949288266957,
              "max_token_negative_log_likelihood": 0.26335641741752625,
              "predictive_entropy": 0.03037756634856592,
              "shannon_entropy": 0.10227478896104517
            }
          },
          {
            "text": "The Seven Bridges of K\u00f6nigs",
            "logprob": -0.3057559020802998,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.26335638761520386
              },
              {
                "text": "Seven",
                "logprob": -0.04239736869931221
              },
              {
                "text": "Br",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "id",
                "logprob": 0.0
              },
              {
                "text": "ges",
                "logprob": 0.0
              },
              {
                "text": "of",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "K\u00f6nig",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "s",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03821949288266957,
              "max_token_negative_log_likelihood": 0.26335641741752625,
              "predictive_entropy": 0.03037756634856592,
              "shannon_entropy": 0.10227478896104517
            }
          },
          {
            "text": "The Seven Bridges of K\u00f6nigs",
            "logprob": -0.3057559020802998,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.26335638761520386
              },
              {
                "text": "Seven",
                "logprob": -0.04239736869931221
              },
              {
                "text": "Br",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "id",
                "logprob": 0.0
              },
              {
                "text": "ges",
                "logprob": 0.0
              },
              {
                "text": "of",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "K\u00f6nig",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "s",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03821949288266957,
              "max_token_negative_log_likelihood": 0.26335641741752625,
              "predictive_entropy": 0.03037756634856592,
              "shannon_entropy": 0.10227478896104517
            }
          }
        ],
        "cached": false,
        "request_time": 1.012528896331787,
        "request_datetime": 1755801569
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Denjoy\u2013Luzin theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Nikolai Luzin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Nikolai Nikolayevich Luzin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Nikolai N. Luzin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Luzin, Nikolaj N."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lusin, Nicolas"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Luzin, N.N."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lusin, N.N."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Nikolai Nikolaevich Luzin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id70"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nDenjoy\u2013Luzin theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Denjoy\u2013Luzin",
            "logprob": -0.10061269561492736,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09998947381973267
              },
              {
                "text": "Den",
                "logprob": -0.00048303857329301536
              },
              {
                "text": "jo",
                "logprob": -3.2186455882765586e-06
              },
              {
                "text": "y",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "\u2013",
                "logprob": -0.00011598391574807465
              },
              {
                "text": "L",
                "logprob": 0.0
              },
              {
                "text": "uz",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "in",
                "logprob": -1.8596476365928538e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.012576584316491335,
              "max_token_negative_log_likelihood": 0.09998944401741028,
              "predictive_entropy": 0.011387265679630332,
              "shannon_entropy": 0.04261177556043094
            }
          },
          {
            "text": "The Denjoy\u2013Luzin",
            "logprob": -0.10061269561492736,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09998947381973267
              },
              {
                "text": "Den",
                "logprob": -0.00048303857329301536
              },
              {
                "text": "jo",
                "logprob": -3.2186455882765586e-06
              },
              {
                "text": "y",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "\u2013",
                "logprob": -0.00011598391574807465
              },
              {
                "text": "L",
                "logprob": 0.0
              },
              {
                "text": "uz",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "in",
                "logprob": -1.8596476365928538e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.012576584316491335,
              "max_token_negative_log_likelihood": 0.09998944401741028,
              "predictive_entropy": 0.011387265679630332,
              "shannon_entropy": 0.04261177556043094
            }
          },
          {
            "text": "The Denjoy\u2013Luzin",
            "logprob": -0.10061269561492736,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09998947381973267
              },
              {
                "text": "Den",
                "logprob": -0.00048303857329301536
              },
              {
                "text": "jo",
                "logprob": -3.2186455882765586e-06
              },
              {
                "text": "y",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "\u2013",
                "logprob": -0.00011598391574807465
              },
              {
                "text": "L",
                "logprob": 0.0
              },
              {
                "text": "uz",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "in",
                "logprob": -1.8596476365928538e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.012576584316491335,
              "max_token_negative_log_likelihood": 0.09998944401741028,
              "predictive_entropy": 0.011387265679630332,
              "shannon_entropy": 0.04261177556043094
            }
          },
          {
            "text": "The Denjoy\u2013Luzin",
            "logprob": -0.10061269561492736,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09998947381973267
              },
              {
                "text": "Den",
                "logprob": -0.00048303857329301536
              },
              {
                "text": "jo",
                "logprob": -3.2186455882765586e-06
              },
              {
                "text": "y",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "\u2013",
                "logprob": -0.00011598391574807465
              },
              {
                "text": "L",
                "logprob": 0.0
              },
              {
                "text": "uz",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "in",
                "logprob": -1.8596476365928538e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.012576584316491335,
              "max_token_negative_log_likelihood": 0.09998944401741028,
              "predictive_entropy": 0.011387265679630332,
              "shannon_entropy": 0.04261177556043094
            }
          },
          {
            "text": "The Denjoy\u2013Luzin",
            "logprob": -0.10061269561492736,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09998947381973267
              },
              {
                "text": "Den",
                "logprob": -0.00048303857329301536
              },
              {
                "text": "jo",
                "logprob": -3.2186455882765586e-06
              },
              {
                "text": "y",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "\u2013",
                "logprob": -0.00011598391574807465
              },
              {
                "text": "L",
                "logprob": 0.0
              },
              {
                "text": "uz",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "in",
                "logprob": -1.8596476365928538e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.012576584316491335,
              "max_token_negative_log_likelihood": 0.09998944401741028,
              "predictive_entropy": 0.011387265679630332,
              "shannon_entropy": 0.04261177556043094
            }
          }
        ],
        "cached": false,
        "request_time": 1.0055761337280273,
        "request_datetime": 1755801570
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Euler's theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Leonhard Euler"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Euler, Leonhard"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "L. Euler"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id71"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nEuler's theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Euler's theorem, referring to",
            "logprob": -5.220203562509596,
            "tokens": [
              {
                "text": "E",
                "logprob": -0.10199667513370514
              },
              {
                "text": "uler",
                "logprob": -5.245195097813848e-06
              },
              {
                "text": "'",
                "logprob": -0.00031454383861273527
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.05484337359666824
              },
              {
                "text": ",",
                "logprob": -0.16983537375926971
              },
              {
                "text": "referring",
                "logprob": -4.8637800216674805
              },
              {
                "text": "to",
                "logprob": -0.029428329318761826
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6525252653644884,
              "max_token_negative_log_likelihood": 4.863778591156006,
              "predictive_entropy": 0.044222452312226324,
              "shannon_entropy": 0.4610888181737334
            }
          },
          {
            "text": "Euler's theorem, in the",
            "logprob": -3.3899550986106988,
            "tokens": [
              {
                "text": "E",
                "logprob": -0.10199667513370514
              },
              {
                "text": "uler",
                "logprob": -5.245195097813848e-06
              },
              {
                "text": "'",
                "logprob": -0.00031454383861273527
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.05484337359666824
              },
              {
                "text": ",",
                "logprob": -0.16983537375926971
              },
              {
                "text": "in",
                "logprob": -2.9575300216674805
              },
              {
                "text": "the",
                "logprob": -0.10542986541986465
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.42374436151101236,
              "max_token_negative_log_likelihood": 2.9575297832489014,
              "predictive_entropy": 0.06702070344005051,
              "shannon_entropy": 0.5029978869965941
            }
          },
          {
            "text": "Euler's theorem, specifically the",
            "logprob": -3.097322779577553,
            "tokens": [
              {
                "text": "E",
                "logprob": -0.10199667513370514
              },
              {
                "text": "uler",
                "logprob": -5.245195097813848e-06
              },
              {
                "text": "'",
                "logprob": -0.00031454383861273527
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.05484337359666824
              },
              {
                "text": ",",
                "logprob": -0.16983537375926971
              },
              {
                "text": "specifically",
                "logprob": -1.707529902458191
              },
              {
                "text": "the",
                "logprob": -1.0627976655960083
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.38716533467038516,
              "max_token_negative_log_likelihood": 1.7075297832489014,
              "predictive_entropy": 0.12055394273016873,
              "shannon_entropy": 0.7061114056518942
            }
          },
          {
            "text": "Euler's theorem in the context",
            "logprob": -3.186681034844696,
            "tokens": [
              {
                "text": "E",
                "logprob": -0.10199667513370514
              },
              {
                "text": "uler",
                "logprob": -5.245195097813848e-06
              },
              {
                "text": "'",
                "logprob": -0.00031454383861273527
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.05484337359666824
              },
              {
                "text": "in",
                "logprob": -2.669835329055786
              },
              {
                "text": "the",
                "logprob": -0.3340795636177063
              },
              {
                "text": "context",
                "logprob": -0.02560630440711975
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.398335134273907,
              "max_token_negative_log_likelihood": 2.669835329055786,
              "predictive_entropy": 0.07417799169894579,
              "shannon_entropy": 0.3077527681848675
            }
          },
          {
            "text": "Euler's theorem, which is",
            "logprob": -2.326002674978554,
            "tokens": [
              {
                "text": "E",
                "logprob": -0.10199667513370514
              },
              {
                "text": "uler",
                "logprob": -5.245195097813848e-06
              },
              {
                "text": "'",
                "logprob": -0.00031454383861273527
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -0.05484337359666824
              },
              {
                "text": ",",
                "logprob": -0.16983537375926971
              },
              {
                "text": "which",
                "logprob": -1.395029902458191
              },
              {
                "text": "is",
                "logprob": -0.6039775609970093
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2907503439472521,
              "max_token_negative_log_likelihood": 1.395029902458191,
              "predictive_entropy": 0.12044107015941563,
              "shannon_entropy": 0.6761898441723257
            }
          }
        ],
        "cached": false,
        "request_time": 1.0031917095184326,
        "request_datetime": 1755801570
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Quillen\u2013Suslin theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Daniel Quillen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Daniel Gray \"Dan\" Quillen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrei Suslin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrey Aleksandrovich Suslin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id72"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nQuillen\u2013Suslin theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Quillen\u2013Suslin",
            "logprob": -0.10769488193906795,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09550243616104126
              },
              {
                "text": "Qu",
                "logprob": -6.139089964563027e-05
              },
              {
                "text": "ill",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "en",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.012127001769840717
              },
              {
                "text": "S",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "lin",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01346185978400527,
              "max_token_negative_log_likelihood": 0.09550240635871887,
              "predictive_entropy": 0.012356246701525464,
              "shannon_entropy": 0.04738524650607934
            }
          },
          {
            "text": "The Quillen\u2013Suslin",
            "logprob": -0.10769488193906795,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09550243616104126
              },
              {
                "text": "Qu",
                "logprob": -6.139089964563027e-05
              },
              {
                "text": "ill",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "en",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.012127001769840717
              },
              {
                "text": "S",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "lin",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01346185978400527,
              "max_token_negative_log_likelihood": 0.09550240635871887,
              "predictive_entropy": 0.012356246701525464,
              "shannon_entropy": 0.04738524650607934
            }
          },
          {
            "text": "The Quillen\u2013Suslin",
            "logprob": -0.10769488193906795,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09550243616104126
              },
              {
                "text": "Qu",
                "logprob": -6.139089964563027e-05
              },
              {
                "text": "ill",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "en",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.012127001769840717
              },
              {
                "text": "S",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "lin",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01346185978400527,
              "max_token_negative_log_likelihood": 0.09550240635871887,
              "predictive_entropy": 0.012356246701525464,
              "shannon_entropy": 0.04738524650607934
            }
          },
          {
            "text": "The Quillen\u2013Suslin",
            "logprob": -0.10769488193906795,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09550243616104126
              },
              {
                "text": "Qu",
                "logprob": -6.139089964563027e-05
              },
              {
                "text": "ill",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "en",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.012127001769840717
              },
              {
                "text": "S",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "lin",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01346185978400527,
              "max_token_negative_log_likelihood": 0.09550240635871887,
              "predictive_entropy": 0.012356246701525464,
              "shannon_entropy": 0.04738524650607934
            }
          },
          {
            "text": "The Quillen\u2013Suslin",
            "logprob": -0.10769488193906795,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.09550243616104126
              },
              {
                "text": "Qu",
                "logprob": -6.139089964563027e-05
              },
              {
                "text": "ill",
                "logprob": -3.814689989667386e-06
              },
              {
                "text": "en",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.012127001769840717
              },
              {
                "text": "S",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "lin",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01346185978400527,
              "max_token_negative_log_likelihood": 0.09550240635871887,
              "predictive_entropy": 0.012356246701525464,
              "shannon_entropy": 0.04738524650607934
            }
          }
        ],
        "cached": false,
        "request_time": 0.9970440864562988,
        "request_datetime": 1755801570
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Basel problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Leonhard Euler"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Euler, Leonhard"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "L. Euler"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id73"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nBasel problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Basel problem, which asks for",
            "logprob": -1.8609458587307017,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.07090938091278076
              },
              {
                "text": "Bas",
                "logprob": -0.001868646708317101
              },
              {
                "text": "el",
                "logprob": -0.00025674383505247533
              },
              {
                "text": "problem",
                "logprob": -0.0017021704697981477
              },
              {
                "text": ",",
                "logprob": -0.5563162565231323
              },
              {
                "text": "which",
                "logprob": -0.045287299901247025
              },
              {
                "text": "asks",
                "logprob": -1.1829146146774292
              },
              {
                "text": "for",
                "logprob": -0.001690745702944696
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.23261821518826764,
              "max_token_negative_log_likelihood": 1.1829146146774292,
              "predictive_entropy": 0.09952733220052323,
              "shannon_entropy": 0.36514663288835436
            }
          },
          {
            "text": "The Basel problem, which concerns the",
            "logprob": -1.3908060711983126,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.07090938091278076
              },
              {
                "text": "Bas",
                "logprob": -0.001868646708317101
              },
              {
                "text": "el",
                "logprob": -0.00025674383505247533
              },
              {
                "text": "problem",
                "logprob": -0.0017021704697981477
              },
              {
                "text": ",",
                "logprob": -0.5563162565231323
              },
              {
                "text": "which",
                "logprob": -0.045287299901247025
              },
              {
                "text": "concerns",
                "logprob": -0.7141646146774292
              },
              {
                "text": "the",
                "logprob": -0.000300958170555532
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.17385074590856675,
              "max_token_negative_log_likelihood": 0.714164674282074,
              "predictive_entropy": 0.09775758233445231,
              "shannon_entropy": 0.36390678718453273
            }
          },
          {
            "text": "The Basel problem, which concerns the",
            "logprob": -1.3908060711983126,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.07090938091278076
              },
              {
                "text": "Bas",
                "logprob": -0.001868646708317101
              },
              {
                "text": "el",
                "logprob": -0.00025674383505247533
              },
              {
                "text": "problem",
                "logprob": -0.0017021704697981477
              },
              {
                "text": ",",
                "logprob": -0.5563162565231323
              },
              {
                "text": "which",
                "logprob": -0.045287299901247025
              },
              {
                "text": "concerns",
                "logprob": -0.7141646146774292
              },
              {
                "text": "the",
                "logprob": -0.000300958170555532
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.17385074590856675,
              "max_token_negative_log_likelihood": 0.714164674282074,
              "predictive_entropy": 0.09775758233445231,
              "shannon_entropy": 0.36390678718453273
            }
          },
          {
            "text": "The Basel problem was solved by Carl",
            "logprob": -5.2053880764578935,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.07090938091278076
              },
              {
                "text": "Bas",
                "logprob": -0.001868646708317101
              },
              {
                "text": "el",
                "logprob": -0.00025674383505247533
              },
              {
                "text": "problem",
                "logprob": -0.0017021704697981477
              },
              {
                "text": "was",
                "logprob": -0.9313162565231323
              },
              {
                "text": "solved",
                "logprob": -0.0873274877667427
              },
              {
                "text": "by",
                "logprob": -0.0020072567276656628
              },
              {
                "text": "Carl",
                "logprob": -4.110000133514404
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6506734295981005,
              "max_token_negative_log_likelihood": 4.109999656677246,
              "predictive_entropy": 0.07328892341683968,
              "shannon_entropy": 0.2791704166447744
            }
          },
          {
            "text": "The Basel problem, which asks for",
            "logprob": -1.8609458587307017,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.07090938091278076
              },
              {
                "text": "Bas",
                "logprob": -0.001868646708317101
              },
              {
                "text": "el",
                "logprob": -0.00025674383505247533
              },
              {
                "text": "problem",
                "logprob": -0.0017021704697981477
              },
              {
                "text": ",",
                "logprob": -0.5563162565231323
              },
              {
                "text": "which",
                "logprob": -0.045287299901247025
              },
              {
                "text": "asks",
                "logprob": -1.1829146146774292
              },
              {
                "text": "for",
                "logprob": -0.001690745702944696
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.23261821518826764,
              "max_token_negative_log_likelihood": 1.1829146146774292,
              "predictive_entropy": 0.09952733220052323,
              "shannon_entropy": 0.36514663288835436
            }
          }
        ],
        "cached": false,
        "request_time": 1.0013039112091064,
        "request_datetime": 1755801570
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Hilbert's tenth problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Yuri Matiyasevich"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Yury Matiyasevich"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Yuri Vladimirovich Matiyasevich"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Yury Vladimirovich Matiyasevich"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id74"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nHilbert's tenth problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Hilbert's tenth problem was",
            "logprob": -0.3552573758595372,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.025742126628756523
              },
              {
                "text": "bert",
                "logprob": -2.861018856492592e-06
              },
              {
                "text": "'",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "t",
                "logprob": -0.0020561523269861937
              },
              {
                "text": "enth",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -0.3274550437927246
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04440717262392013,
              "max_token_negative_log_likelihood": 0.3274550437927246,
              "predictive_entropy": 0.032894874165620536,
              "shannon_entropy": 0.12213985488112222
            }
          },
          {
            "text": "Hilbert's tenth problem,",
            "logprob": -1.5740073758595372,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.025742126628756523
              },
              {
                "text": "bert",
                "logprob": -2.861018856492592e-06
              },
              {
                "text": "'",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "t",
                "logprob": -0.0020561523269861937
              },
              {
                "text": "enth",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -1.5462050437927246
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.19675092262392013,
              "max_token_negative_log_likelihood": 1.5462050437927246,
              "predictive_entropy": 0.0445713234942815,
              "shannon_entropy": 0.12213985488112222
            }
          },
          {
            "text": "Hilbert's tenth problem was",
            "logprob": -0.3552573758595372,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.025742126628756523
              },
              {
                "text": "bert",
                "logprob": -2.861018856492592e-06
              },
              {
                "text": "'",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "t",
                "logprob": -0.0020561523269861937
              },
              {
                "text": "enth",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -0.3274550437927246
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04440717262392013,
              "max_token_negative_log_likelihood": 0.3274550437927246,
              "predictive_entropy": 0.032894874165620536,
              "shannon_entropy": 0.12213985488112222
            }
          },
          {
            "text": "Hilbert's tenth problem was",
            "logprob": -0.3552573758595372,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.025742126628756523
              },
              {
                "text": "bert",
                "logprob": -2.861018856492592e-06
              },
              {
                "text": "'",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "t",
                "logprob": -0.0020561523269861937
              },
              {
                "text": "enth",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -0.3274550437927246
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04440717262392013,
              "max_token_negative_log_likelihood": 0.3274550437927246,
              "predictive_entropy": 0.032894874165620536,
              "shannon_entropy": 0.12213985488112222
            }
          },
          {
            "text": "Hilbert's tenth problem,",
            "logprob": -1.5740073758595372,
            "tokens": [
              {
                "text": "Hil",
                "logprob": -0.025742126628756523
              },
              {
                "text": "bert",
                "logprob": -2.861018856492592e-06
              },
              {
                "text": "'",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "t",
                "logprob": -0.0020561523269861937
              },
              {
                "text": "enth",
                "logprob": 0.0
              },
              {
                "text": "problem",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -1.5462050437927246
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.19675092262392013,
              "max_token_negative_log_likelihood": 1.5462050437927246,
              "predictive_entropy": 0.0445713234942815,
              "shannon_entropy": 0.12213985488112222
            }
          }
        ],
        "cached": false,
        "request_time": 1.0041487216949463,
        "request_datetime": 1755801571
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Krein\u2013Milman theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Mark Krein"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mark Grigorievich Krein"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "David Milman"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "David Pinhusovich Milman"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id75"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nKrein\u2013Milman theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Krein\u2013Milman theorem was",
            "logprob": -0.40620104388654,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.014511402696371078
              },
              {
                "text": "Kre",
                "logprob": -0.0002512616047170013
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0001740304142003879
              },
              {
                "text": "Mil",
                "logprob": 0.0
              },
              {
                "text": "man",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -1.0132738680113107e-05
              },
              {
                "text": "was",
                "logprob": -0.3912542164325714
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.050775123784660536,
              "max_token_negative_log_likelihood": 0.391254186630249,
              "predictive_entropy": 0.03491337024831864,
              "shannon_entropy": 0.12671236959133125
            }
          },
          {
            "text": "The Krein\u2013Milman theorem was",
            "logprob": -0.40620104388654,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.014511402696371078
              },
              {
                "text": "Kre",
                "logprob": -0.0002512616047170013
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0001740304142003879
              },
              {
                "text": "Mil",
                "logprob": 0.0
              },
              {
                "text": "man",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -1.0132738680113107e-05
              },
              {
                "text": "was",
                "logprob": -0.3912542164325714
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.050775123784660536,
              "max_token_negative_log_likelihood": 0.391254186630249,
              "predictive_entropy": 0.03491337024831864,
              "shannon_entropy": 0.12671236959133125
            }
          },
          {
            "text": "The Krein\u2013Milman theorem is",
            "logprob": -1.8437010140842176,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.014511402696371078
              },
              {
                "text": "Kre",
                "logprob": -0.0002512616047170013
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0001740304142003879
              },
              {
                "text": "Mil",
                "logprob": 0.0
              },
              {
                "text": "man",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -1.0132738680113107e-05
              },
              {
                "text": "is",
                "logprob": -1.828754186630249
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.23046260888349934,
              "max_token_negative_log_likelihood": 1.8287540674209595,
              "predictive_entropy": 0.03855753862524125,
              "shannon_entropy": 0.12671236959133125
            }
          },
          {
            "text": "The Krein\u2013Milman theorem was",
            "logprob": -0.40620104388654,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.014511402696371078
              },
              {
                "text": "Kre",
                "logprob": -0.0002512616047170013
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0001740304142003879
              },
              {
                "text": "Mil",
                "logprob": 0.0
              },
              {
                "text": "man",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -1.0132738680113107e-05
              },
              {
                "text": "was",
                "logprob": -0.3912542164325714
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.050775123784660536,
              "max_token_negative_log_likelihood": 0.391254186630249,
              "predictive_entropy": 0.03491337024831864,
              "shannon_entropy": 0.12671236959133125
            }
          },
          {
            "text": "The Krein\u2013Milman theorem was",
            "logprob": -0.40620104388654,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.014511402696371078
              },
              {
                "text": "Kre",
                "logprob": -0.0002512616047170013
              },
              {
                "text": "in",
                "logprob": 0.0
              },
              {
                "text": "\u2013",
                "logprob": -0.0001740304142003879
              },
              {
                "text": "Mil",
                "logprob": 0.0
              },
              {
                "text": "man",
                "logprob": 0.0
              },
              {
                "text": "theorem",
                "logprob": -1.0132738680113107e-05
              },
              {
                "text": "was",
                "logprob": -0.3912542164325714
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.050775123784660536,
              "max_token_negative_log_likelihood": 0.391254186630249,
              "predictive_entropy": 0.03491337024831864,
              "shannon_entropy": 0.12671236959133125
            }
          }
        ],
        "cached": false,
        "request_time": 0.9216213226318359,
        "request_datetime": 1755801571
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Fermat's Last Theorem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Andrew Wiles"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sir Andrew John Wiles"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrew John Wiles"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrew J. Wiles"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Dr. Andrew Wiles"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Prof. Sir Andrew Wiles FRS"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Andrew Wiles"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Richard Taylor"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Richard Lawrence Taylor"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "R.L Taylor"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Richard Lawrence Taylor"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id76"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nFermat's Last Theorem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Fermat's Last Theorem was",
            "logprob": -0.06331960949864879,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.059428561478853226
              },
              {
                "text": "erm",
                "logprob": 0.0
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "Last",
                "logprob": 0.0
              },
              {
                "text": "Theorem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -0.003889140672981739
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.007914952672081199,
              "max_token_negative_log_likelihood": 0.059428587555885315,
              "predictive_entropy": 0.007484457979217041,
              "shannon_entropy": 0.034250085705584105
            }
          },
          {
            "text": "Fermat's Last Theorem was",
            "logprob": -0.06331960949864879,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.059428561478853226
              },
              {
                "text": "erm",
                "logprob": 0.0
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "Last",
                "logprob": 0.0
              },
              {
                "text": "Theorem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -0.003889140672981739
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.007914952672081199,
              "max_token_negative_log_likelihood": 0.059428587555885315,
              "predictive_entropy": 0.007484457979217041,
              "shannon_entropy": 0.034250085705584105
            }
          },
          {
            "text": "Fermat's Last Theorem was",
            "logprob": -0.06331960949864879,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.059428561478853226
              },
              {
                "text": "erm",
                "logprob": 0.0
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "Last",
                "logprob": 0.0
              },
              {
                "text": "Theorem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -0.003889140672981739
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.007914952672081199,
              "max_token_negative_log_likelihood": 0.059428587555885315,
              "predictive_entropy": 0.007484457979217041,
              "shannon_entropy": 0.034250085705584105
            }
          },
          {
            "text": "Fermat's Last Theorem was",
            "logprob": -0.06331960949864879,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.059428561478853226
              },
              {
                "text": "erm",
                "logprob": 0.0
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "Last",
                "logprob": 0.0
              },
              {
                "text": "Theorem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -0.003889140672981739
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.007914952672081199,
              "max_token_negative_log_likelihood": 0.059428587555885315,
              "predictive_entropy": 0.007484457979217041,
              "shannon_entropy": 0.034250085705584105
            }
          },
          {
            "text": "Fermat's Last Theorem was",
            "logprob": -0.06331960949864879,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.059428561478853226
              },
              {
                "text": "erm",
                "logprob": 0.0
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "Last",
                "logprob": 0.0
              },
              {
                "text": "Theorem",
                "logprob": 0.0
              },
              {
                "text": "was",
                "logprob": -0.003889140672981739
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.007914952672081199,
              "max_token_negative_log_likelihood": 0.059428587555885315,
              "predictive_entropy": 0.007484457979217041,
              "shannon_entropy": 0.034250085705584105
            }
          }
        ],
        "cached": false,
        "request_time": 0.9176936149597168,
        "request_datetime": 1755801571
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Kadison\u2013Singer problem was solved by"
        },
        "references": [
          {
            "output": {
              "text": "Adam Marcus"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Adam Wade Marcus"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Daniel Spielman"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Daniel A. Spielman"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Daniel Alan Spielman"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Nikhil Srivastava"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id77"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Non-squeezing theorem was solved by Mikhail Gromov\n\nEuler's rotation theorem was solved by Leonhard Euler\n\nBombieri\u2013Vinogradov theorem was solved by Askold Vinogradov\n\nPappus's centroid theorem was solved by Paul Guldin\n\nSaukrieg was solved by Augustus, Elector of Saxony\n\nKadison\u2013Singer problem was solved by",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The Kadison\u2013Singer problem",
            "logprob": -0.00735326939928882,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.001505433232523501
              },
              {
                "text": "K",
                "logprob": -3.516612196108326e-05
              },
              {
                "text": "ad",
                "logprob": 0.0
              },
              {
                "text": "ison",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.005746748298406601
              },
              {
                "text": "S",
                "logprob": -2.8013790142722428e-05
              },
              {
                "text": "inger",
                "logprob": -3.099436753473128e-06
              },
              {
                "text": "problem",
                "logprob": -3.4450891689630225e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0009191597756981196,
              "max_token_negative_log_likelihood": 0.005746752489358187,
              "predictive_entropy": 0.0009147599658554384,
              "shannon_entropy": 0.00654280775195204
            }
          },
          {
            "text": "The Kadison\u2013Singer problem",
            "logprob": -0.00735326939928882,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.001505433232523501
              },
              {
                "text": "K",
                "logprob": -3.516612196108326e-05
              },
              {
                "text": "ad",
                "logprob": 0.0
              },
              {
                "text": "ison",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.005746748298406601
              },
              {
                "text": "S",
                "logprob": -2.8013790142722428e-05
              },
              {
                "text": "inger",
                "logprob": -3.099436753473128e-06
              },
              {
                "text": "problem",
                "logprob": -3.4450891689630225e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0009191597756981196,
              "max_token_negative_log_likelihood": 0.005746752489358187,
              "predictive_entropy": 0.0009147599658554384,
              "shannon_entropy": 0.00654280775195204
            }
          },
          {
            "text": "The Kadison\u2013Singer problem",
            "logprob": -0.00735326939928882,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.001505433232523501
              },
              {
                "text": "K",
                "logprob": -3.516612196108326e-05
              },
              {
                "text": "ad",
                "logprob": 0.0
              },
              {
                "text": "ison",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.005746748298406601
              },
              {
                "text": "S",
                "logprob": -2.8013790142722428e-05
              },
              {
                "text": "inger",
                "logprob": -3.099436753473128e-06
              },
              {
                "text": "problem",
                "logprob": -3.4450891689630225e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0009191597756981196,
              "max_token_negative_log_likelihood": 0.005746752489358187,
              "predictive_entropy": 0.0009147599658554384,
              "shannon_entropy": 0.00654280775195204
            }
          },
          {
            "text": "The Kadison\u2013Singer problem",
            "logprob": -0.00735326939928882,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.001505433232523501
              },
              {
                "text": "K",
                "logprob": -3.516612196108326e-05
              },
              {
                "text": "ad",
                "logprob": 0.0
              },
              {
                "text": "ison",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.005746748298406601
              },
              {
                "text": "S",
                "logprob": -2.8013790142722428e-05
              },
              {
                "text": "inger",
                "logprob": -3.099436753473128e-06
              },
              {
                "text": "problem",
                "logprob": -3.4450891689630225e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0009191597756981196,
              "max_token_negative_log_likelihood": 0.005746752489358187,
              "predictive_entropy": 0.0009147599658554384,
              "shannon_entropy": 0.00654280775195204
            }
          },
          {
            "text": "The Kadison\u2013Singer problem",
            "logprob": -0.00735326939928882,
            "tokens": [
              {
                "text": "The",
                "logprob": -0.001505433232523501
              },
              {
                "text": "K",
                "logprob": -3.516612196108326e-05
              },
              {
                "text": "ad",
                "logprob": 0.0
              },
              {
                "text": "ison",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "\u2013",
                "logprob": -0.005746748298406601
              },
              {
                "text": "S",
                "logprob": -2.8013790142722428e-05
              },
              {
                "text": "inger",
                "logprob": -3.099436753473128e-06
              },
              {
                "text": "problem",
                "logprob": -3.4450891689630225e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0009191597756981196,
              "max_token_negative_log_likelihood": 0.005746752489358187,
              "predictive_entropy": 0.0009147599658554384,
              "shannon_entropy": 0.00654280775195204
            }
          }
        ],
        "cached": false,
        "request_time": 0.7227985858917236,
        "request_datetime": 1755801571
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    }
  ]
}