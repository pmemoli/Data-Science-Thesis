{
  "adapter_spec": {
    "method": "generation",
    "global_prefix": "",
    "global_suffix": "",
    "instructions": "",
    "input_prefix": "",
    "input_suffix": "",
    "reference_prefix": "A. ",
    "reference_suffix": "\n",
    "chain_of_thought_prefix": "",
    "chain_of_thought_suffix": "\n",
    "output_prefix": " ",
    "output_suffix": "\n",
    "instance_prefix": "\n",
    "substitutions": [],
    "max_train_instances": 5,
    "max_eval_instances": 100,
    "num_outputs": 5,
    "num_train_trials": 1,
    "num_trials": 1,
    "sample_train": true,
    "model_deployment": "huggingface/phi-3.5-mini-instruct",
    "model": "microsoft/phi-3.5-mini-instruct",
    "temperature": 1.0,
    "max_tokens": 8,
    "stop_sequences": [
      "\n"
    ],
    "multi_label": false
  },
  "request_states": [
    {
      "instance": {
        "input": {
          "text": "Kaare Fostervoll used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Oslo"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Christiania"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Kristiania"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "NOOSL"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Oslo, Norway"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id592"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nKaare Fostervoll used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Kaare Fostervoll used to",
            "logprob": -0.3827526718322929,
            "tokens": [
              {
                "text": "Ka",
                "logprob": -0.22902469336986542
              },
              {
                "text": "are",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "F",
                "logprob": 0.0
              },
              {
                "text": "oster",
                "logprob": 0.0
              },
              {
                "text": "vol",
                "logprob": 0.0
              },
              {
                "text": "l",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.15372416377067566
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04784408211779834,
              "max_token_negative_log_likelihood": 0.2290247082710266,
              "predictive_entropy": 0.03924611955812196,
              "shannon_entropy": 0.18246160155112534
            }
          },
          {
            "text": "Kaare Fostervoll used to",
            "logprob": -0.3827526718322929,
            "tokens": [
              {
                "text": "Ka",
                "logprob": -0.22902469336986542
              },
              {
                "text": "are",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "F",
                "logprob": 0.0
              },
              {
                "text": "oster",
                "logprob": 0.0
              },
              {
                "text": "vol",
                "logprob": 0.0
              },
              {
                "text": "l",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.15372416377067566
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04784408211779834,
              "max_token_negative_log_likelihood": 0.2290247082710266,
              "predictive_entropy": 0.03924611955812196,
              "shannon_entropy": 0.18246160155112534
            }
          },
          {
            "text": "Kaare Fostervoll used to",
            "logprob": -0.3827526718322929,
            "tokens": [
              {
                "text": "Ka",
                "logprob": -0.22902469336986542
              },
              {
                "text": "are",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "F",
                "logprob": 0.0
              },
              {
                "text": "oster",
                "logprob": 0.0
              },
              {
                "text": "vol",
                "logprob": 0.0
              },
              {
                "text": "l",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.15372416377067566
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04784408211779834,
              "max_token_negative_log_likelihood": 0.2290247082710266,
              "predictive_entropy": 0.03924611955812196,
              "shannon_entropy": 0.18246160155112534
            }
          },
          {
            "text": "It seems that the final statement for Ka",
            "logprob": -12.981838048435748,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.510274648666382
              },
              {
                "text": "seems",
                "logprob": -0.6439090967178345
              },
              {
                "text": "that",
                "logprob": -0.9739723205566406
              },
              {
                "text": "the",
                "logprob": -0.1806950569152832
              },
              {
                "text": "final",
                "logprob": -4.021668434143066
              },
              {
                "text": "statement",
                "logprob": -1.1304899454116821
              },
              {
                "text": "for",
                "logprob": -3.5109519958496094
              },
              {
                "text": "Ka",
                "logprob": -0.009876550175249577
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.622729648486711,
              "max_token_negative_log_likelihood": 4.021667957305908,
              "predictive_entropy": 0.2015579908620566,
              "shannon_entropy": 1.0771785941906273
            }
          },
          {
            "text": "Kaare Fostervoll seems to",
            "logprob": -5.402727443719385,
            "tokens": [
              {
                "text": "Ka",
                "logprob": -0.22902469336986542
              },
              {
                "text": "are",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "F",
                "logprob": 0.0
              },
              {
                "text": "oster",
                "logprob": 0.0
              },
              {
                "text": "vol",
                "logprob": 0.0
              },
              {
                "text": "l",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "seems",
                "logprob": -5.153724193572998
              },
              {
                "text": "to",
                "logprob": -0.019974980503320694
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6753406962386954,
              "max_token_negative_log_likelihood": 5.153722286224365,
              "predictive_entropy": 0.028938292292192358,
              "shannon_entropy": 0.19506246899820212
            }
          }
        ],
        "cached": false,
        "request_time": 1.1498456001281738,
        "request_datetime": 1755803163
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "George Fullard used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Love"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paree"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lutetia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paris, France"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisians"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id241"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nGeorge Fullard used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "George Fullard used to work in London",
            "logprob": -0.6339145718209167,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.3762928247451782
              },
              {
                "text": "Full",
                "logprob": -2.0265558760002023e-06
              },
              {
                "text": "ard",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03248610720038414
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00010597144137136638
              },
              {
                "text": "in",
                "logprob": -0.00013207517622504383
              },
              {
                "text": "London",
                "logprob": -0.2248954474925995
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07923932599286054,
              "max_token_negative_log_likelihood": 0.3762928247451782,
              "predictive_entropy": 0.05869715481432536,
              "shannon_entropy": 0.24796322036586105
            }
          },
          {
            "text": "Henry St. John once played a significant",
            "logprob": -11.658400088548632,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -2.2512927055358887
              },
              {
                "text": "St",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "John",
                "logprob": 0.0
              },
              {
                "text": "once",
                "logprob": -5.497270107269287
              },
              {
                "text": "played",
                "logprob": -3.314937114715576
              },
              {
                "text": "a",
                "logprob": -0.11232256889343262
              },
              {
                "text": "significant",
                "logprob": -0.4825773537158966
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.457299746572975,
              "max_token_negative_log_likelihood": 5.497268199920654,
              "predictive_entropy": 0.09727368759922328,
              "shannon_entropy": 0.6859083001473678
            }
          },
          {
            "text": "Henry St. John, also known as",
            "logprob": -3.8501565195619776,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -2.2512927055358887
              },
              {
                "text": "St",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "John",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.21602033078670502
              },
              {
                "text": "also",
                "logprob": -1.36896812915802
              },
              {
                "text": "known",
                "logprob": -0.0027037039399147034
              },
              {
                "text": "as",
                "logprob": -0.011171411722898483
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.48126954981126246,
              "max_token_negative_log_likelihood": 2.2512927055358887,
              "predictive_entropy": 0.09662462523555959,
              "shannon_entropy": 0.5795341358026249
            }
          },
          {
            "text": "George Fullard used to work in London",
            "logprob": -0.6339145718209167,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.3762928247451782
              },
              {
                "text": "Full",
                "logprob": -2.0265558760002023e-06
              },
              {
                "text": "ard",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03248610720038414
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00010597144137136638
              },
              {
                "text": "in",
                "logprob": -0.00013207517622504383
              },
              {
                "text": "London",
                "logprob": -0.2248954474925995
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07923932599286054,
              "max_token_negative_log_likelihood": 0.3762928247451782,
              "predictive_entropy": 0.05869715481432536,
              "shannon_entropy": 0.24796322036586105
            }
          },
          {
            "text": "George Fullard used to work in London",
            "logprob": -0.6339145718209167,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.3762928247451782
              },
              {
                "text": "Full",
                "logprob": -2.0265558760002023e-06
              },
              {
                "text": "ard",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03248610720038414
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00010597144137136638
              },
              {
                "text": "in",
                "logprob": -0.00013207517622504383
              },
              {
                "text": "London",
                "logprob": -0.2248954474925995
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07923932599286054,
              "max_token_negative_log_likelihood": 0.3762928247451782,
              "predictive_entropy": 0.05869715481432536,
              "shannon_entropy": 0.24796322036586105
            }
          }
        ],
        "cached": false,
        "request_time": 1.1384272575378418,
        "request_datetime": 1755803163
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "John Sabatina used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Harrisburg"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Capital of Pennsylvania"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Harrisburg, Pennsylvania"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id509"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJohn Sabatina used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "John Sabatina used to work in",
            "logprob": -0.18610284664464416,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.15722763538360596
              },
              {
                "text": "Sab",
                "logprob": -1.4543427823809907e-05
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "ina",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.02873288094997406
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.658331868587993e-05
              },
              {
                "text": "in",
                "logprob": -0.0001012035645544529
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.023262854198947025,
              "max_token_negative_log_likelihood": 0.15722762048244476,
              "predictive_entropy": 0.02030173456353168,
              "shannon_entropy": 0.10561898887546128
            }
          },
          {
            "text": "John Sabatina used to work in",
            "logprob": -0.18610284664464416,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.15722763538360596
              },
              {
                "text": "Sab",
                "logprob": -1.4543427823809907e-05
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "ina",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.02873288094997406
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.658331868587993e-05
              },
              {
                "text": "in",
                "logprob": -0.0001012035645544529
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.023262854198947025,
              "max_token_negative_log_likelihood": 0.15722762048244476,
              "predictive_entropy": 0.02030173456353168,
              "shannon_entropy": 0.10561898887546128
            }
          },
          {
            "text": "John Sabatina used to work in",
            "logprob": -0.18610284664464416,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.15722763538360596
              },
              {
                "text": "Sab",
                "logprob": -1.4543427823809907e-05
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "ina",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.02873288094997406
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.658331868587993e-05
              },
              {
                "text": "in",
                "logprob": -0.0001012035645544529
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.023262854198947025,
              "max_token_negative_log_likelihood": 0.15722762048244476,
              "predictive_entropy": 0.02030173456353168,
              "shannon_entropy": 0.10561898887546128
            }
          },
          {
            "text": "John Sabatina used to work in",
            "logprob": -0.18610284664464416,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.15722763538360596
              },
              {
                "text": "Sab",
                "logprob": -1.4543427823809907e-05
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "ina",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.02873288094997406
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.658331868587993e-05
              },
              {
                "text": "in",
                "logprob": -0.0001012035645544529
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.023262854198947025,
              "max_token_negative_log_likelihood": 0.15722762048244476,
              "predictive_entropy": 0.02030173456353168,
              "shannon_entropy": 0.10561898887546128
            }
          },
          {
            "text": "John Sabatina used to work in",
            "logprob": -0.18610284664464416,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.15722763538360596
              },
              {
                "text": "Sab",
                "logprob": -1.4543427823809907e-05
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "ina",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.02873288094997406
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.658331868587993e-05
              },
              {
                "text": "in",
                "logprob": -0.0001012035645544529
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.023262854198947025,
              "max_token_negative_log_likelihood": 0.15722762048244476,
              "predictive_entropy": 0.02030173456353168,
              "shannon_entropy": 0.10561898887546128
            }
          }
        ],
        "cached": false,
        "request_time": 0.96608567237854,
        "request_datetime": 1755803163
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Obed Hall used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id131"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nObed Hall used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Obed Hall used to work in Lincoln",
            "logprob": -5.760470341069322,
            "tokens": [
              {
                "text": "O",
                "logprob": -0.17388863861560822
              },
              {
                "text": "bed",
                "logprob": -4.029192859889008e-05
              },
              {
                "text": "Hall",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "used",
                "logprob": -0.07727682590484619
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -5.23315102327615e-05
              },
              {
                "text": "in",
                "logprob": -6.878139538457617e-05
              },
              {
                "text": "Lincoln",
                "logprob": -5.509140968322754
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.720058495747196,
              "max_token_negative_log_likelihood": 5.509138584136963,
              "predictive_entropy": 0.030017251278479762,
              "shannon_entropy": 0.5499510229930493
            }
          },
          {
            "text": "Obed Hall used to work in London",
            "logprob": -2.229220579487901,
            "tokens": [
              {
                "text": "O",
                "logprob": -0.17388863861560822
              },
              {
                "text": "bed",
                "logprob": -4.029192859889008e-05
              },
              {
                "text": "Hall",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "used",
                "logprob": -0.07727682590484619
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -5.23315102327615e-05
              },
              {
                "text": "in",
                "logprob": -6.878139538457617e-05
              },
              {
                "text": "London",
                "logprob": -1.977891206741333
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2786525586715811,
              "max_token_negative_log_likelihood": 1.9778910875320435,
              "predictive_entropy": 0.06143633871266729,
              "shannon_entropy": 0.5499510229930493
            }
          },
          {
            "text": "Obed Hall used to work in York",
            "logprob": -4.604220341069322,
            "tokens": [
              {
                "text": "O",
                "logprob": -0.17388863861560822
              },
              {
                "text": "bed",
                "logprob": -4.029192859889008e-05
              },
              {
                "text": "Hall",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "used",
                "logprob": -0.07727682590484619
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -5.23315102327615e-05
              },
              {
                "text": "in",
                "logprob": -6.878139538457617e-05
              },
              {
                "text": "York",
                "logprob": -4.352890968322754
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5755274841657751,
              "max_token_negative_log_likelihood": 4.352890491485596,
              "predictive_entropy": 0.03423100466767437,
              "shannon_entropy": 0.5499510229930493
            }
          },
          {
            "text": "Obed Hall used to work in Char",
            "logprob": -3.447970579487901,
            "tokens": [
              {
                "text": "O",
                "logprob": -0.17388863861560822
              },
              {
                "text": "bed",
                "logprob": -4.029192859889008e-05
              },
              {
                "text": "Hall",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "used",
                "logprob": -0.07727682590484619
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -5.23315102327615e-05
              },
              {
                "text": "in",
                "logprob": -6.878139538457617e-05
              },
              {
                "text": "Char",
                "logprob": -3.196641206741333
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4309962937704199,
              "max_token_negative_log_likelihood": 3.196640968322754,
              "predictive_entropy": 0.043571101864074535,
              "shannon_entropy": 0.5499510229930493
            }
          },
          {
            "text": "Obed Hall used to work in various",
            "logprob": -2.791720579487901,
            "tokens": [
              {
                "text": "O",
                "logprob": -0.17388863861560822
              },
              {
                "text": "bed",
                "logprob": -4.029192859889008e-05
              },
              {
                "text": "Hall",
                "logprob": -2.50339189733495e-06
              },
              {
                "text": "used",
                "logprob": -0.07727682590484619
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -5.23315102327615e-05
              },
              {
                "text": "in",
                "logprob": -6.878139538457617e-05
              },
              {
                "text": "various",
                "logprob": -2.540391206741333
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3489650735727423,
              "max_token_negative_log_likelihood": 2.540391206741333,
              "predictive_entropy": 0.052262680967544384,
              "shannon_entropy": 0.5499510229930493
            }
          }
        ],
        "cached": false,
        "request_time": 0.9688217639923096,
        "request_datetime": 1755803163
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Bernard H. Breslauer used to work in"
        },
        "references": [
          {
            "output": {
              "text": "New York City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "NYC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "the five boroughs"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Big Apple"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "NY City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York, New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York City, New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York, NY"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York City (NYC)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New Yorker"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Fort Neu-Amsterdam"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Big Apple"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The City That Never Sleeps"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gotham City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "NYC"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id670"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nBernard H. Breslauer used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Bernard H. Breslauer used to",
            "logprob": -1.008045195280431,
            "tokens": [
              {
                "text": "Bernard",
                "logprob": -0.7843384742736816
              },
              {
                "text": "H",
                "logprob": -4.172316494077677e-06
              },
              {
                "text": ".",
                "logprob": -4.7444173105759546e-05
              },
              {
                "text": "Bres",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "la",
                "logprob": -1.5258672647178173e-05
              },
              {
                "text": "uer",
                "logprob": -2.622600959512056e-06
              },
              {
                "text": "used",
                "logprob": -0.22363638877868652
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.126005638547376,
              "max_token_negative_log_likelihood": 0.7843384146690369,
              "predictive_entropy": 0.06711002796084031,
              "shannon_entropy": 0.3337128115216501
            }
          },
          {
            "text": "It seems like the information about the last",
            "logprob": -8.934189349412918,
            "tokens": [
              {
                "text": "It",
                "logprob": -1.9718384742736816
              },
              {
                "text": "seems",
                "logprob": -0.6148203611373901
              },
              {
                "text": "like",
                "logprob": -0.9724328517913818
              },
              {
                "text": "the",
                "logprob": -0.3886648714542389
              },
              {
                "text": "information",
                "logprob": -0.5483867526054382
              },
              {
                "text": "about",
                "logprob": -0.6448525786399841
              },
              {
                "text": "the",
                "logprob": -2.5957257747650146
              },
              {
                "text": "last",
                "logprob": -1.1974676847457886
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1167736127972603,
              "max_token_negative_log_likelihood": 2.5957255363464355,
              "predictive_entropy": 0.3060827124863863,
              "shannon_entropy": 1.3470265045762062
            }
          },
          {
            "text": "Bernard H. Breslauer used to",
            "logprob": -1.008045195280431,
            "tokens": [
              {
                "text": "Bernard",
                "logprob": -0.7843384742736816
              },
              {
                "text": "H",
                "logprob": -4.172316494077677e-06
              },
              {
                "text": ".",
                "logprob": -4.7444173105759546e-05
              },
              {
                "text": "Bres",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "la",
                "logprob": -1.5258672647178173e-05
              },
              {
                "text": "uer",
                "logprob": -2.622600959512056e-06
              },
              {
                "text": "used",
                "logprob": -0.22363638877868652
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.126005638547376,
              "max_token_negative_log_likelihood": 0.7843384146690369,
              "predictive_entropy": 0.06711002796084031,
              "shannon_entropy": 0.3337128115216501
            }
          },
          {
            "text": "Bernard H. Breslauer, to",
            "logprob": -8.054666041075222,
            "tokens": [
              {
                "text": "Bernard",
                "logprob": -0.7843384742736816
              },
              {
                "text": "H",
                "logprob": -4.172316494077677e-06
              },
              {
                "text": ".",
                "logprob": -4.7444173105759546e-05
              },
              {
                "text": "Bres",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "la",
                "logprob": -1.5258672647178173e-05
              },
              {
                "text": "uer",
                "logprob": -2.622600959512056e-06
              },
              {
                "text": ",",
                "logprob": -2.4111363887786865
              },
              {
                "text": "to",
                "logprob": -4.859121322631836
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0068331287876973,
              "max_token_negative_log_likelihood": 4.8591203689575195,
              "predictive_entropy": 0.07650792536454176,
              "shannon_entropy": 0.6264905742608562
            }
          },
          {
            "text": "Victor Leemans used to work in",
            "logprob": -3.311054799763717,
            "tokens": [
              {
                "text": "Victor",
                "logprob": -2.9405884742736816
              },
              {
                "text": "Le",
                "logprob": -0.006002258043736219
              },
              {
                "text": "em",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ans",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "used",
                "logprob": -0.3628544211387634
              },
              {
                "text": "to",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "work",
                "logprob": -0.00033098942367359996
              },
              {
                "text": "in",
                "logprob": -0.0012775840004906058
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4138818250867491,
              "max_token_negative_log_likelihood": 2.9405882358551025,
              "predictive_entropy": 0.0519215661006136,
              "shannon_entropy": 0.38946144959123785
            }
          }
        ],
        "cached": false,
        "request_time": 0.979633092880249,
        "request_datetime": 1755803164
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Christian Adolph Klotz used to work in"
        },
        "references": [
          {
            "output": {
              "text": "G\u00f6rlitz"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Goerlitz"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gorlitz"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Leipzig"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Jena"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "G\u00f6ttingen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Halle (Saale)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Halle/Saale"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Halle an der Saale"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Halle a. d. Saale"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Halle"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Halle, Saxony-Anhalt"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id693"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nChristian Adolph Klotz used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Christian Adolph Klotz used to",
            "logprob": -0.11865011036411488,
            "tokens": [
              {
                "text": "Christian",
                "logprob": -0.016707029193639755
              },
              {
                "text": "Ad",
                "logprob": -6.222531374078244e-05
              },
              {
                "text": "olph",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "lot",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10187847167253494
              },
              {
                "text": "to",
                "logprob": -1.6689286894688848e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014831265443923769,
              "max_token_negative_log_likelihood": 0.10187847912311554,
              "predictive_entropy": 0.013563161939387669,
              "shannon_entropy": 0.06430295284366042
            }
          },
          {
            "text": "Christian Adolph Klotz used to",
            "logprob": -0.11865011036411488,
            "tokens": [
              {
                "text": "Christian",
                "logprob": -0.016707029193639755
              },
              {
                "text": "Ad",
                "logprob": -6.222531374078244e-05
              },
              {
                "text": "olph",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "lot",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10187847167253494
              },
              {
                "text": "to",
                "logprob": -1.6689286894688848e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014831265443923769,
              "max_token_negative_log_likelihood": 0.10187847912311554,
              "predictive_entropy": 0.013563161939387669,
              "shannon_entropy": 0.06430295284366042
            }
          },
          {
            "text": "Christian Adolph Klotz used to",
            "logprob": -0.11865011036411488,
            "tokens": [
              {
                "text": "Christian",
                "logprob": -0.016707029193639755
              },
              {
                "text": "Ad",
                "logprob": -6.222531374078244e-05
              },
              {
                "text": "olph",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "lot",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10187847167253494
              },
              {
                "text": "to",
                "logprob": -1.6689286894688848e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014831265443923769,
              "max_token_negative_log_likelihood": 0.10187847912311554,
              "predictive_entropy": 0.013563161939387669,
              "shannon_entropy": 0.06430295284366042
            }
          },
          {
            "text": "Christian Adolph Klotz used to",
            "logprob": -0.11865011036411488,
            "tokens": [
              {
                "text": "Christian",
                "logprob": -0.016707029193639755
              },
              {
                "text": "Ad",
                "logprob": -6.222531374078244e-05
              },
              {
                "text": "olph",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "lot",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10187847167253494
              },
              {
                "text": "to",
                "logprob": -1.6689286894688848e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014831265443923769,
              "max_token_negative_log_likelihood": 0.10187847912311554,
              "predictive_entropy": 0.013563161939387669,
              "shannon_entropy": 0.06430295284366042
            }
          },
          {
            "text": "Christian Adolph Klotz used to",
            "logprob": -0.11865011036411488,
            "tokens": [
              {
                "text": "Christian",
                "logprob": -0.016707029193639755
              },
              {
                "text": "Ad",
                "logprob": -6.222531374078244e-05
              },
              {
                "text": "olph",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "lot",
                "logprob": 0.0
              },
              {
                "text": "z",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10187847167253494
              },
              {
                "text": "to",
                "logprob": -1.6689286894688848e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014831265443923769,
              "max_token_negative_log_likelihood": 0.10187847912311554,
              "predictive_entropy": 0.013563161939387669,
              "shannon_entropy": 0.06430295284366042
            }
          }
        ],
        "cached": false,
        "request_time": 0.9824657440185547,
        "request_datetime": 1755803164
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Asahel Huntington used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Beantown"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Liberty"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Modern America"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Athens of America"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Walking City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub of the Universe"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bostonia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, Massachusetts"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, MA"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, Mass."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Puritan City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bostonian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Beantown"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Liberty"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id973"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nAsahel Huntington used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Asahel Huntington, based",
            "logprob": -3.1039334718807083,
            "tokens": [
              {
                "text": "As",
                "logprob": -0.3820813000202179
              },
              {
                "text": "ah",
                "logprob": -0.0001515035255579278
              },
              {
                "text": "el",
                "logprob": 0.0
              },
              {
                "text": "Hun",
                "logprob": 0.0
              },
              {
                "text": "ting",
                "logprob": 0.0
              },
              {
                "text": "ton",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -1.549920916557312
              },
              {
                "text": "based",
                "logprob": -1.1717795133590698
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.38799167195429973,
              "max_token_negative_log_likelihood": 1.5499207973480225,
              "predictive_entropy": 0.11911596959361859,
              "shannon_entropy": 0.5696764951728659
            }
          },
          {
            "text": "Asahel Huntington, like",
            "logprob": -3.2601834718807083,
            "tokens": [
              {
                "text": "As",
                "logprob": -0.3820813000202179
              },
              {
                "text": "ah",
                "logprob": -0.0001515035255579278
              },
              {
                "text": "el",
                "logprob": 0.0
              },
              {
                "text": "Hun",
                "logprob": 0.0
              },
              {
                "text": "ting",
                "logprob": 0.0
              },
              {
                "text": "ton",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -1.549920916557312
              },
              {
                "text": "like",
                "logprob": -1.3280295133590698
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.40752290705313854,
              "max_token_negative_log_likelihood": 1.5499207973480225,
              "predictive_entropy": 0.1177273899866087,
              "shannon_entropy": 0.5696764951728659
            }
          },
          {
            "text": "It seems the information about Asahel",
            "logprob": -5.129177607370366,
            "tokens": [
              {
                "text": "It",
                "logprob": -1.7570812702178955
              },
              {
                "text": "seems",
                "logprob": -0.7045726180076599
              },
              {
                "text": "the",
                "logprob": -1.628076195716858
              },
              {
                "text": "information",
                "logprob": -0.4250359833240509
              },
              {
                "text": "about",
                "logprob": -0.5722793340682983
              },
              {
                "text": "As",
                "logprob": -0.04211098700761795
              },
              {
                "text": "ah",
                "logprob": -2.1219027985353023e-05
              },
              {
                "text": "el",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6411471902674748,
              "max_token_negative_log_likelihood": 1.7570812702178955,
              "predictive_entropy": 0.20152877501186595,
              "shannon_entropy": 0.759044509713626
            }
          },
          {
            "text": "Asahel Huntington used to",
            "logprob": -0.8696545247655934,
            "tokens": [
              {
                "text": "As",
                "logprob": -0.3820813000202179
              },
              {
                "text": "ah",
                "logprob": -0.0001515035255579278
              },
              {
                "text": "el",
                "logprob": 0.0
              },
              {
                "text": "Hun",
                "logprob": 0.0
              },
              {
                "text": "ting",
                "logprob": 0.0
              },
              {
                "text": "ton",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.4874208867549896
              },
              {
                "text": "to",
                "logprob": -5.960462772236497e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.10870682219140448,
              "max_token_negative_log_likelihood": 0.487420916557312,
              "predictive_entropy": 0.07003472229368768,
              "shannon_entropy": 0.2975622073785138
            }
          },
          {
            "text": "Asahel Huntington used to",
            "logprob": -0.8696545247655934,
            "tokens": [
              {
                "text": "As",
                "logprob": -0.3820813000202179
              },
              {
                "text": "ah",
                "logprob": -0.0001515035255579278
              },
              {
                "text": "el",
                "logprob": 0.0
              },
              {
                "text": "Hun",
                "logprob": 0.0
              },
              {
                "text": "ting",
                "logprob": 0.0
              },
              {
                "text": "ton",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.4874208867549896
              },
              {
                "text": "to",
                "logprob": -5.960462772236497e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.10870682219140448,
              "max_token_negative_log_likelihood": 0.487420916557312,
              "predictive_entropy": 0.07003472229368768,
              "shannon_entropy": 0.2975622073785138
            }
          }
        ],
        "cached": false,
        "request_time": 1.032127857208252,
        "request_datetime": 1755803165
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "John Gorton used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Canberra"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Canberra, Australia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Canberra"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Canberra"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Canberran"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id499"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJohn Gorton used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "John Gorton used to work in Can",
            "logprob": -0.35757681066627356,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.07447247207164764
              },
              {
                "text": "G",
                "logprob": 0.0
              },
              {
                "text": "orton",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "used",
                "logprob": -0.13462920486927032
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00034433635300956666
              },
              {
                "text": "in",
                "logprob": -0.0006565084331668913
              },
              {
                "text": "Can",
                "logprob": -0.14747273921966553
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.044697102977963254,
              "max_token_negative_log_likelihood": 0.14747275412082672,
              "predictive_entropy": 0.03938163923143634,
              "shannon_entropy": 0.16483366474430028
            }
          },
          {
            "text": "John Gorton used to work in Can",
            "logprob": -0.35757681066627356,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.07447247207164764
              },
              {
                "text": "G",
                "logprob": 0.0
              },
              {
                "text": "orton",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "used",
                "logprob": -0.13462920486927032
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00034433635300956666
              },
              {
                "text": "in",
                "logprob": -0.0006565084331668913
              },
              {
                "text": "Can",
                "logprob": -0.14747273921966553
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.044697102977963254,
              "max_token_negative_log_likelihood": 0.14747275412082672,
              "predictive_entropy": 0.03938163923143634,
              "shannon_entropy": 0.16483366474430028
            }
          },
          {
            "text": "John Gorton used to work in Can",
            "logprob": -0.35757681066627356,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.07447247207164764
              },
              {
                "text": "G",
                "logprob": 0.0
              },
              {
                "text": "orton",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "used",
                "logprob": -0.13462920486927032
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00034433635300956666
              },
              {
                "text": "in",
                "logprob": -0.0006565084331668913
              },
              {
                "text": "Can",
                "logprob": -0.14747273921966553
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.044697102977963254,
              "max_token_negative_log_likelihood": 0.14747275412082672,
              "predictive_entropy": 0.03938163923143634,
              "shannon_entropy": 0.16483366474430028
            }
          },
          {
            "text": "John Gorton used to work in Can",
            "logprob": -0.35757681066627356,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.07447247207164764
              },
              {
                "text": "G",
                "logprob": 0.0
              },
              {
                "text": "orton",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "used",
                "logprob": -0.13462920486927032
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00034433635300956666
              },
              {
                "text": "in",
                "logprob": -0.0006565084331668913
              },
              {
                "text": "Can",
                "logprob": -0.14747273921966553
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.044697102977963254,
              "max_token_negative_log_likelihood": 0.14747275412082672,
              "predictive_entropy": 0.03938163923143634,
              "shannon_entropy": 0.16483366474430028
            }
          },
          {
            "text": "John Gorton used to work in Australia",
            "logprob": -3.826326929875563,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.07447247207164764
              },
              {
                "text": "G",
                "logprob": 0.0
              },
              {
                "text": "orton",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "used",
                "logprob": -0.13462920486927032
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00034433635300956666
              },
              {
                "text": "in",
                "logprob": -0.0006565084331668913
              },
              {
                "text": "Australia",
                "logprob": -3.616222858428955
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4782908064118345,
              "max_token_negative_log_likelihood": 3.616222381591797,
              "predictive_entropy": 0.035627449993484106,
              "shannon_entropy": 0.16483366474430028
            }
          }
        ],
        "cached": false,
        "request_time": 1.0183250904083252,
        "request_datetime": 1755803165
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Joe Hackney used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Raleigh"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Raleigh, North Carolina"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Raleigh, NC"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id506"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJoe Hackney used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Joe Hackney used to work in",
            "logprob": -0.22537686779460842,
            "tokens": [
              {
                "text": "Joe",
                "logprob": -0.19586943089962006
              },
              {
                "text": "H",
                "logprob": 0.0
              },
              {
                "text": "ack",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ney",
                "logprob": -1.680836794548668e-05
              },
              {
                "text": "used",
                "logprob": -0.029156044125556946
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -7.652943895664066e-05
              },
              {
                "text": "in",
                "logprob": -0.0002574589161667973
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02817210542208315,
              "max_token_negative_log_likelihood": 0.19586940109729767,
              "predictive_entropy": 0.02371220513553851,
              "shannon_entropy": 0.11859328397905866
            }
          },
          {
            "text": "Joe Hackney used to work in",
            "logprob": -0.22537686779460842,
            "tokens": [
              {
                "text": "Joe",
                "logprob": -0.19586943089962006
              },
              {
                "text": "H",
                "logprob": 0.0
              },
              {
                "text": "ack",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ney",
                "logprob": -1.680836794548668e-05
              },
              {
                "text": "used",
                "logprob": -0.029156044125556946
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -7.652943895664066e-05
              },
              {
                "text": "in",
                "logprob": -0.0002574589161667973
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02817210542208315,
              "max_token_negative_log_likelihood": 0.19586940109729767,
              "predictive_entropy": 0.02371220513553851,
              "shannon_entropy": 0.11859328397905866
            }
          },
          {
            "text": "Joe Hackney used to work in",
            "logprob": -0.22537686779460842,
            "tokens": [
              {
                "text": "Joe",
                "logprob": -0.19586943089962006
              },
              {
                "text": "H",
                "logprob": 0.0
              },
              {
                "text": "ack",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ney",
                "logprob": -1.680836794548668e-05
              },
              {
                "text": "used",
                "logprob": -0.029156044125556946
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -7.652943895664066e-05
              },
              {
                "text": "in",
                "logprob": -0.0002574589161667973
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02817210542208315,
              "max_token_negative_log_likelihood": 0.19586940109729767,
              "predictive_entropy": 0.02371220513553851,
              "shannon_entropy": 0.11859328397905866
            }
          },
          {
            "text": "Joe Hackney used to work in",
            "logprob": -0.22537686779460842,
            "tokens": [
              {
                "text": "Joe",
                "logprob": -0.19586943089962006
              },
              {
                "text": "H",
                "logprob": 0.0
              },
              {
                "text": "ack",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ney",
                "logprob": -1.680836794548668e-05
              },
              {
                "text": "used",
                "logprob": -0.029156044125556946
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -7.652943895664066e-05
              },
              {
                "text": "in",
                "logprob": -0.0002574589161667973
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02817210542208315,
              "max_token_negative_log_likelihood": 0.19586940109729767,
              "predictive_entropy": 0.02371220513553851,
              "shannon_entropy": 0.11859328397905866
            }
          },
          {
            "text": "Joe Hackney used to work in",
            "logprob": -0.22537686779460842,
            "tokens": [
              {
                "text": "Joe",
                "logprob": -0.19586943089962006
              },
              {
                "text": "H",
                "logprob": 0.0
              },
              {
                "text": "ack",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ney",
                "logprob": -1.680836794548668e-05
              },
              {
                "text": "used",
                "logprob": -0.029156044125556946
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -7.652943895664066e-05
              },
              {
                "text": "in",
                "logprob": -0.0002574589161667973
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02817210542208315,
              "max_token_negative_log_likelihood": 0.19586940109729767,
              "predictive_entropy": 0.02371220513553851,
              "shannon_entropy": 0.11859328397905866
            }
          }
        ],
        "cached": false,
        "request_time": 1.0099332332611084,
        "request_datetime": 1755803165
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Fabrizio Santafede used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Naples"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Napoli"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Neapolis"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Rome"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Eternal City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Roma"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Rome, Italy"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Roman"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bologna"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bologna, Italy"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bolognian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bolognese"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modena"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parma"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Venice"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Serenissima"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Venezia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Venexia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Venetia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Venice, Italy"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bride of the Sea"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id372"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nFabrizio Santafede used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Fabrizio Santafede used to",
            "logprob": -0.23561666157013406,
            "tokens": [
              {
                "text": "Fab",
                "logprob": -0.12252151221036911
              },
              {
                "text": "riz",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "io",
                "logprob": 0.0
              },
              {
                "text": "Sant",
                "logprob": -2.145764938177308e-06
              },
              {
                "text": "af",
                "logprob": -8.4638240878121e-06
              },
              {
                "text": "ede",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.11308310925960541
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02945208270578803,
              "max_token_negative_log_likelihood": 0.12252149730920792,
              "predictive_entropy": 0.026174634690175225,
              "shannon_entropy": 0.14102659987547117
            }
          },
          {
            "text": "Fabrizio Santafede used to",
            "logprob": -0.23561666157013406,
            "tokens": [
              {
                "text": "Fab",
                "logprob": -0.12252151221036911
              },
              {
                "text": "riz",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "io",
                "logprob": 0.0
              },
              {
                "text": "Sant",
                "logprob": -2.145764938177308e-06
              },
              {
                "text": "af",
                "logprob": -8.4638240878121e-06
              },
              {
                "text": "ede",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.11308310925960541
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02945208270578803,
              "max_token_negative_log_likelihood": 0.12252149730920792,
              "predictive_entropy": 0.026174634690175225,
              "shannon_entropy": 0.14102659987547117
            }
          },
          {
            "text": "Given the pattern, it seems that each",
            "logprob": -10.017200469970703,
            "tokens": [
              {
                "text": "Given",
                "logprob": -4.68502140045166
              },
              {
                "text": "the",
                "logprob": -0.15002164244651794
              },
              {
                "text": "pattern",
                "logprob": -0.4388609230518341
              },
              {
                "text": ",",
                "logprob": -2.5151748657226562
              },
              {
                "text": "it",
                "logprob": -0.1579512357711792
              },
              {
                "text": "seems",
                "logprob": -0.7471581697463989
              },
              {
                "text": "that",
                "logprob": -0.5896174311637878
              },
              {
                "text": "each",
                "logprob": -0.7333948016166687
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.2521499376744032,
              "max_token_negative_log_likelihood": 4.685020446777344,
              "predictive_entropy": 0.2283372483216226,
              "shannon_entropy": 1.0636070370674133
            }
          },
          {
            "text": "Considering the pattern presented, which is",
            "logprob": -16.524823974104947,
            "tokens": [
              {
                "text": "Consider",
                "logprob": -8.37252140045166
              },
              {
                "text": "ing",
                "logprob": -0.00021479207498487085
              },
              {
                "text": "the",
                "logprob": -0.038336072117090225
              },
              {
                "text": "pattern",
                "logprob": -0.4208722710609436
              },
              {
                "text": "presented",
                "logprob": -3.0307841300964355
              },
              {
                "text": ",",
                "logprob": -1.108550786972046
              },
              {
                "text": "which",
                "logprob": -1.8560423851013184
              },
              {
                "text": "is",
                "logprob": -1.6975021362304688
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 2.0655976325233496,
              "max_token_negative_log_likelihood": 8.372478485107422,
              "predictive_entropy": 0.1785599906270363,
              "shannon_entropy": 1.2850160749512725
            }
          },
          {
            "text": "Fabrizio Santafede used to",
            "logprob": -0.23561666157013406,
            "tokens": [
              {
                "text": "Fab",
                "logprob": -0.12252151221036911
              },
              {
                "text": "riz",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "io",
                "logprob": 0.0
              },
              {
                "text": "Sant",
                "logprob": -2.145764938177308e-06
              },
              {
                "text": "af",
                "logprob": -8.4638240878121e-06
              },
              {
                "text": "ede",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.11308310925960541
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02945208270578803,
              "max_token_negative_log_likelihood": 0.12252149730920792,
              "predictive_entropy": 0.026174634690175225,
              "shannon_entropy": 0.14102659987547117
            }
          }
        ],
        "cached": false,
        "request_time": 1.0123794078826904,
        "request_datetime": 1755803165
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Fabi\u00e1n R\u00edos used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Buenos Aires"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Autonomous City of Buenos Aires"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "CABA"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ciudad de Buenos Aire"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ciudad Autonoma de Buenos Aires"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id791"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nFabi\u00e1n R\u00edos used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Fabi\u00e1n R\u00edos used to work",
            "logprob": -0.22974950767564906,
            "tokens": [
              {
                "text": "Fab",
                "logprob": -0.19324810802936554
              },
              {
                "text": "i",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "\u00e1n",
                "logprob": 0.0
              },
              {
                "text": "R",
                "logprob": 0.0
              },
              {
                "text": "\u00edos",
                "logprob": -1.5258672647178173e-05
              },
              {
                "text": "used",
                "logprob": -0.036392565816640854
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02871868207271433,
              "max_token_negative_log_likelihood": 0.19324807822704315,
              "predictive_entropy": 0.024311349195716758,
              "shannon_entropy": 0.13056006204857518
            }
          },
          {
            "text": "Fabi\u00e1n R\u00edos used to work",
            "logprob": -0.22974950767564906,
            "tokens": [
              {
                "text": "Fab",
                "logprob": -0.19324810802936554
              },
              {
                "text": "i",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "\u00e1n",
                "logprob": 0.0
              },
              {
                "text": "R",
                "logprob": 0.0
              },
              {
                "text": "\u00edos",
                "logprob": -1.5258672647178173e-05
              },
              {
                "text": "used",
                "logprob": -0.036392565816640854
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02871868207271433,
              "max_token_negative_log_likelihood": 0.19324807822704315,
              "predictive_entropy": 0.024311349195716758,
              "shannon_entropy": 0.13056006204857518
            }
          },
          {
            "text": "Fabi\u00e1n R\u00edos used to work",
            "logprob": -0.22974950767564906,
            "tokens": [
              {
                "text": "Fab",
                "logprob": -0.19324810802936554
              },
              {
                "text": "i",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "\u00e1n",
                "logprob": 0.0
              },
              {
                "text": "R",
                "logprob": 0.0
              },
              {
                "text": "\u00edos",
                "logprob": -1.5258672647178173e-05
              },
              {
                "text": "used",
                "logprob": -0.036392565816640854
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02871868207271433,
              "max_token_negative_log_likelihood": 0.19324807822704315,
              "predictive_entropy": 0.024311349195716758,
              "shannon_entropy": 0.13056006204857518
            }
          },
          {
            "text": "Based on the provided information, Fabi",
            "logprob": -8.47525633004534,
            "tokens": [
              {
                "text": "Based",
                "logprob": -3.0994980335235596
              },
              {
                "text": "on",
                "logprob": -0.00026675479602999985
              },
              {
                "text": "the",
                "logprob": -0.006707889027893543
              },
              {
                "text": "provided",
                "logprob": -2.345808982849121
              },
              {
                "text": "information",
                "logprob": -0.8684760332107544
              },
              {
                "text": ",",
                "logprob": -0.2661592364311218
              },
              {
                "text": "Fab",
                "logprob": -1.8883264064788818
              },
              {
                "text": "i",
                "logprob": -1.2993727978027891e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0594069861432445,
              "max_token_negative_log_likelihood": 3.0994977951049805,
              "predictive_entropy": 0.1531771897210774,
              "shannon_entropy": 0.7612528237768856
            }
          },
          {
            "text": "Based on the pattern established above where each",
            "logprob": -18.816937780735316,
            "tokens": [
              {
                "text": "Based",
                "logprob": -3.0994980335235596
              },
              {
                "text": "on",
                "logprob": -0.00026675479602999985
              },
              {
                "text": "the",
                "logprob": -0.006707889027893543
              },
              {
                "text": "pattern",
                "logprob": -0.2833089530467987
              },
              {
                "text": "established",
                "logprob": -2.304196834564209
              },
              {
                "text": "above",
                "logprob": -8.355917930603027
              },
              {
                "text": "where",
                "logprob": -3.907413959503174
              },
              {
                "text": "each",
                "logprob": -0.8596274256706238
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 2.3521117620621226,
              "max_token_negative_log_likelihood": 8.355875015258789,
              "predictive_entropy": 0.1293076855399704,
              "shannon_entropy": 0.8251128013362177
            }
          }
        ],
        "cached": false,
        "request_time": 1.0082871913909912,
        "request_datetime": 1755803166
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "John Webster used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Ottawa"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ottawa (Ontario)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bytown"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Ottawa"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ottawan"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id160"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJohn Webster used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "John Webster used to work in New",
            "logprob": -1.7650221726385098,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.12724383175373077
              },
              {
                "text": "Web",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "ster",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10012990236282349
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -1.2993727978027891e-05
              },
              {
                "text": "in",
                "logprob": -3.957670196541585e-05
              },
              {
                "text": "New",
                "logprob": -1.5375897884368896
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.22062776714454913,
              "max_token_negative_log_likelihood": 1.5375897884368896,
              "predictive_entropy": 0.06663929473677399,
              "shannon_entropy": 0.43049383181004064
            }
          },
          {
            "text": "John Webster used to work in New",
            "logprob": -1.7650221726385098,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.12724383175373077
              },
              {
                "text": "Web",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "ster",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10012990236282349
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -1.2993727978027891e-05
              },
              {
                "text": "in",
                "logprob": -3.957670196541585e-05
              },
              {
                "text": "New",
                "logprob": -1.5375897884368896
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.22062776714454913,
              "max_token_negative_log_likelihood": 1.5375897884368896,
              "predictive_entropy": 0.06663929473677399,
              "shannon_entropy": 0.43049383181004064
            }
          },
          {
            "text": "John Webster used to work in Boston",
            "logprob": -2.45252217263851,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.12724383175373077
              },
              {
                "text": "Web",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "ster",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10012990236282349
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -1.2993727978027891e-05
              },
              {
                "text": "in",
                "logprob": -3.957670196541585e-05
              },
              {
                "text": "Boston",
                "logprob": -2.2250897884368896
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3065652671445491,
              "max_token_negative_log_likelihood": 2.2250897884368896,
              "predictive_entropy": 0.05539085704901936,
              "shannon_entropy": 0.43049383181004064
            }
          },
          {
            "text": "It seems the information provided for John Web",
            "logprob": -9.436046406626645,
            "tokens": [
              {
                "text": "It",
                "logprob": -3.064743757247925
              },
              {
                "text": "seems",
                "logprob": -0.6130818128585815
              },
              {
                "text": "the",
                "logprob": -1.4125802516937256
              },
              {
                "text": "information",
                "logprob": -0.6495904922485352
              },
              {
                "text": "provided",
                "logprob": -2.5364551544189453
              },
              {
                "text": "for",
                "logprob": -1.017931580543518
              },
              {
                "text": "John",
                "logprob": -0.14166299998760223
              },
              {
                "text": "Web",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.179505767300732,
              "max_token_negative_log_likelihood": 3.0647435188293457,
              "predictive_entropy": 0.2312342962250007,
              "shannon_entropy": 0.959744336143217
            }
          },
          {
            "text": "John Webster used to work in his",
            "logprob": -4.796272411057089,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.12724383175373077
              },
              {
                "text": "Web",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "ster",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10012990236282349
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -1.2993727978027891e-05
              },
              {
                "text": "in",
                "logprob": -3.957670196541585e-05
              },
              {
                "text": "his",
                "logprob": -4.568840026855469
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5995338681329372,
              "max_token_negative_log_likelihood": 4.568838596343994,
              "predictive_entropy": 0.0312584404654217,
              "shannon_entropy": 0.43049383181004064
            }
          }
        ],
        "cached": false,
        "request_time": 1.0097229480743408,
        "request_datetime": 1755803166
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Shelley Moore Capito used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id412"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nShelley Moore Capito used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Shelley Moore Capito used to",
            "logprob": -0.4226192688213928,
            "tokens": [
              {
                "text": "Sh",
                "logprob": -0.17061835527420044
              },
              {
                "text": "elle",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "Moore",
                "logprob": -0.0007109498255886137
              },
              {
                "text": "Cap",
                "logprob": 0.0
              },
              {
                "text": "ito",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.2512885332107544
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.052827410319956414,
              "max_token_negative_log_likelihood": 0.251288503408432,
              "predictive_entropy": 0.04250241452237802,
              "shannon_entropy": 0.1654159501513056
            }
          },
          {
            "text": "Shelley Moore Capito used to",
            "logprob": -0.4226192688213928,
            "tokens": [
              {
                "text": "Sh",
                "logprob": -0.17061835527420044
              },
              {
                "text": "elle",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "Moore",
                "logprob": -0.0007109498255886137
              },
              {
                "text": "Cap",
                "logprob": 0.0
              },
              {
                "text": "ito",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.2512885332107544
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.052827410319956414,
              "max_token_negative_log_likelihood": 0.251288503408432,
              "predictive_entropy": 0.04250241452237802,
              "shannon_entropy": 0.1654159501513056
            }
          },
          {
            "text": "Shelley Moore Capito, whose",
            "logprob": -7.073107764648171,
            "tokens": [
              {
                "text": "Sh",
                "logprob": -0.17061835527420044
              },
              {
                "text": "elle",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "Moore",
                "logprob": -0.0007109498255886137
              },
              {
                "text": "Cap",
                "logprob": 0.0
              },
              {
                "text": "ito",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -1.7512885332107544
              },
              {
                "text": "whose",
                "logprob": -5.15048885345459
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8841382227038395,
              "max_token_negative_log_likelihood": 5.150486946105957,
              "predictive_entropy": 0.05979485818527053,
              "shannon_entropy": 0.41971462419954897
            }
          },
          {
            "text": "Shelley Moore Capito, a",
            "logprob": -3.8231076454388813,
            "tokens": [
              {
                "text": "Sh",
                "logprob": -0.17061835527420044
              },
              {
                "text": "elle",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "Moore",
                "logprob": -0.0007109498255886137
              },
              {
                "text": "Cap",
                "logprob": 0.0
              },
              {
                "text": "ito",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -1.7512885332107544
              },
              {
                "text": "a",
                "logprob": -1.9004887342453003
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4778884313200962,
              "max_token_negative_log_likelihood": 1.9004886150360107,
              "predictive_entropy": 0.0915772841253073,
              "shannon_entropy": 0.41971462419954897
            }
          },
          {
            "text": "It seems you've provided partial information",
            "logprob": -8.573532924987376,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.1081182956695557
              },
              {
                "text": "seems",
                "logprob": -0.5877293944358826
              },
              {
                "text": "you",
                "logprob": -3.147219657897949
              },
              {
                "text": "'",
                "logprob": -0.44945332407951355
              },
              {
                "text": "ve",
                "logprob": -0.1307350993156433
              },
              {
                "text": "provided",
                "logprob": -0.1905045211315155
              },
              {
                "text": "partial",
                "logprob": -1.9442214965820312
              },
              {
                "text": "information",
                "logprob": -0.015551135875284672
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0716915985103697,
              "max_token_negative_log_likelihood": 3.14721941947937,
              "predictive_entropy": 0.19628522894345224,
              "shannon_entropy": 0.8499359786510468
            }
          }
        ],
        "cached": false,
        "request_time": 1.0094599723815918,
        "request_datetime": 1755803166
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Scott Brown used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Beantown"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Liberty"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Modern America"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Athens of America"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Walking City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub of the Universe"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bostonia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, Massachusetts"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, MA"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, Mass."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Puritan City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bostonian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Beantown"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Liberty"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id742"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nScott Brown used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Scott Brown used to work in Toronto,",
            "logprob": -2.099091191721527,
            "tokens": [
              {
                "text": "Scott",
                "logprob": -0.059294089674949646
              },
              {
                "text": "Brown",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03046817146241665
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -1.3470558769768104e-05
              },
              {
                "text": "in",
                "logprob": -4.23184028477408e-05
              },
              {
                "text": "Toronto",
                "logprob": -1.9145163297653198
              },
              {
                "text": ",",
                "logprob": -0.09475681185722351
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.26238638431050276,
              "max_token_negative_log_likelihood": 1.9145162105560303,
              "predictive_entropy": 0.056738149484317546,
              "shannon_entropy": 0.43174222807766327
            }
          },
          {
            "text": "Scott Brown used to work in Toronto,",
            "logprob": -2.099091191721527,
            "tokens": [
              {
                "text": "Scott",
                "logprob": -0.059294089674949646
              },
              {
                "text": "Brown",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03046817146241665
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -1.3470558769768104e-05
              },
              {
                "text": "in",
                "logprob": -4.23184028477408e-05
              },
              {
                "text": "Toronto",
                "logprob": -1.9145163297653198
              },
              {
                "text": ",",
                "logprob": -0.09475681185722351
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.26238638431050276,
              "max_token_negative_log_likelihood": 1.9145162105560303,
              "predictive_entropy": 0.056738149484317546,
              "shannon_entropy": 0.43174222807766327
            }
          },
          {
            "text": "Scott Brown used to work in Toronto,",
            "logprob": -2.099091191721527,
            "tokens": [
              {
                "text": "Scott",
                "logprob": -0.059294089674949646
              },
              {
                "text": "Brown",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03046817146241665
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -1.3470558769768104e-05
              },
              {
                "text": "in",
                "logprob": -4.23184028477408e-05
              },
              {
                "text": "Toronto",
                "logprob": -1.9145163297653198
              },
              {
                "text": ",",
                "logprob": -0.09475681185722351
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.26238638431050276,
              "max_token_negative_log_likelihood": 1.9145162105560303,
              "predictive_entropy": 0.056738149484317546,
              "shannon_entropy": 0.43174222807766327
            }
          },
          {
            "text": "Scott Brown used to work in Seattle,",
            "logprob": -2.9066526265269204,
            "tokens": [
              {
                "text": "Scott",
                "logprob": -0.059294089674949646
              },
              {
                "text": "Brown",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03046817146241665
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -1.3470558769768104e-05
              },
              {
                "text": "in",
                "logprob": -4.23184028477408e-05
              },
              {
                "text": "Seattle",
                "logprob": -2.6957664489746094
              },
              {
                "text": ",",
                "logprob": -0.12106812745332718
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3633315534166286,
              "max_token_negative_log_likelihood": 2.6957662105560303,
              "predictive_entropy": 0.04683654393784309,
              "shannon_entropy": 0.4388416330087317
            }
          },
          {
            "text": "Scott Brown used to work in various locations",
            "logprob": -4.300060202313034,
            "tokens": [
              {
                "text": "Scott",
                "logprob": -0.059294089674949646
              },
              {
                "text": "Brown",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03046817146241665
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -1.3470558769768104e-05
              },
              {
                "text": "in",
                "logprob": -4.23184028477408e-05
              },
              {
                "text": "various",
                "logprob": -3.4457664489746094
              },
              {
                "text": "locations",
                "logprob": -0.7644757032394409
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5375074594116995,
              "max_token_negative_log_likelihood": 3.445765972137451,
              "predictive_entropy": 0.06890816531858945,
              "shannon_entropy": 0.6446660863924158
            }
          }
        ],
        "cached": false,
        "request_time": 1.0157580375671387,
        "request_datetime": 1755803166
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Lloyd Cole used to work in"
        },
        "references": [
          {
            "output": {
              "text": "New York City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "NYC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "the five boroughs"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Big Apple"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "NY City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York, New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York City, New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York, NY"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York City (NYC)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New Yorker"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Fort Neu-Amsterdam"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Big Apple"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The City That Never Sleeps"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gotham City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "NYC"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id600"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nLloyd Cole used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Lloyd Cole used to work in London,",
            "logprob": -1.165621680462209,
            "tokens": [
              {
                "text": "Lloyd",
                "logprob": -0.2816203832626343
              },
              {
                "text": "Cole",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.02781575918197632
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00010632903286023065
              },
              {
                "text": "in",
                "logprob": -0.00015352977789007127
              },
              {
                "text": "London",
                "logprob": -0.3131216764450073
              },
              {
                "text": ",",
                "logprob": -0.5428040027618408
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1457027153492163,
              "max_token_negative_log_likelihood": 0.5428040027618408,
              "predictive_entropy": 0.09802334514370159,
              "shannon_entropy": 0.3750753253055068
            }
          },
          {
            "text": "Lloyd Cole used to work in London,",
            "logprob": -1.165621680462209,
            "tokens": [
              {
                "text": "Lloyd",
                "logprob": -0.2816203832626343
              },
              {
                "text": "Cole",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.02781575918197632
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00010632903286023065
              },
              {
                "text": "in",
                "logprob": -0.00015352977789007127
              },
              {
                "text": "London",
                "logprob": -0.3131216764450073
              },
              {
                "text": ",",
                "logprob": -0.5428040027618408
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1457027153492163,
              "max_token_negative_log_likelihood": 0.5428040027618408,
              "predictive_entropy": 0.09802334514370159,
              "shannon_entropy": 0.3750753253055068
            }
          },
          {
            "text": "Lloyd Cole used to work in Liverpool,",
            "logprob": -3.5961532828150666,
            "tokens": [
              {
                "text": "Lloyd",
                "logprob": -0.2816203832626343
              },
              {
                "text": "Cole",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.02781575918197632
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00010632903286023065
              },
              {
                "text": "in",
                "logprob": -0.00015352977789007127
              },
              {
                "text": "Liverpool",
                "logprob": -3.250621795654297
              },
              {
                "text": ",",
                "logprob": -0.03583548590540886
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.44951910836698517,
              "max_token_negative_log_likelihood": 3.2506213188171387,
              "predictive_entropy": 0.050043507394548215,
              "shannon_entropy": 0.3042278643054219
            }
          },
          {
            "text": "Lloyd Cole used to work in London.",
            "logprob": -1.509371680462209,
            "tokens": [
              {
                "text": "Lloyd",
                "logprob": -0.2816203832626343
              },
              {
                "text": "Cole",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.02781575918197632
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00010632903286023065
              },
              {
                "text": "in",
                "logprob": -0.00015352977789007127
              },
              {
                "text": "London",
                "logprob": -0.3131216764450073
              },
              {
                "text": ".",
                "logprob": -0.8865540027618408
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1886714727997969,
              "max_token_negative_log_likelihood": 0.8865540623664856,
              "predictive_entropy": 0.10425995421519474,
              "shannon_entropy": 0.3750753253055068
            }
          },
          {
            "text": "Lloyd Cole used to work in London,",
            "logprob": -1.165621680462209,
            "tokens": [
              {
                "text": "Lloyd",
                "logprob": -0.2816203832626343
              },
              {
                "text": "Cole",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.02781575918197632
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00010632903286023065
              },
              {
                "text": "in",
                "logprob": -0.00015352977789007127
              },
              {
                "text": "London",
                "logprob": -0.3131216764450073
              },
              {
                "text": ",",
                "logprob": -0.5428040027618408
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1457027153492163,
              "max_token_negative_log_likelihood": 0.5428040027618408,
              "predictive_entropy": 0.09802334514370159,
              "shannon_entropy": 0.3750753253055068
            }
          }
        ],
        "cached": false,
        "request_time": 1.0021510124206543,
        "request_datetime": 1755803167
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Guillermo Mart\u00ednez Nolasco used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Mexico City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mexico D.F."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ciudad de M\u00e9xico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Mexico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mexico City, Mexico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "CDMX"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mexico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "capitalino"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id445"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nGuillermo Mart\u00ednez Nolasco used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Guillermo Mart\u00ednez Nolasco used",
            "logprob": -0.19577342889658667,
            "tokens": [
              {
                "text": "Gu",
                "logprob": -0.14243723452091217
              },
              {
                "text": "ill",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "ermo",
                "logprob": 0.0
              },
              {
                "text": "Mart\u00ednez",
                "logprob": -9.703165414975956e-05
              },
              {
                "text": "N",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "olas",
                "logprob": -2.3245540432981215e-05
              },
              {
                "text": "co",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.05320936068892479
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.024471685449341862,
              "max_token_negative_log_likelihood": 0.14243724942207336,
              "predictive_entropy": 0.02176331945655363,
              "shannon_entropy": 0.11028717534371157
            }
          },
          {
            "text": "Guillermo Mart\u00ednez Nolasco used",
            "logprob": -0.19577342889658667,
            "tokens": [
              {
                "text": "Gu",
                "logprob": -0.14243723452091217
              },
              {
                "text": "ill",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "ermo",
                "logprob": 0.0
              },
              {
                "text": "Mart\u00ednez",
                "logprob": -9.703165414975956e-05
              },
              {
                "text": "N",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "olas",
                "logprob": -2.3245540432981215e-05
              },
              {
                "text": "co",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.05320936068892479
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.024471685449341862,
              "max_token_negative_log_likelihood": 0.14243724942207336,
              "predictive_entropy": 0.02176331945655363,
              "shannon_entropy": 0.11028717534371157
            }
          },
          {
            "text": "According to the prompt, it seems there",
            "logprob": -18.66872875066474,
            "tokens": [
              {
                "text": "According",
                "logprob": -8.298686981201172
              },
              {
                "text": "to",
                "logprob": -0.005570721346884966
              },
              {
                "text": "the",
                "logprob": -0.019861042499542236
              },
              {
                "text": "prompt",
                "logprob": -5.366060256958008
              },
              {
                "text": ",",
                "logprob": -0.27506014704704285
              },
              {
                "text": "it",
                "logprob": -1.5716246366500854
              },
              {
                "text": "seems",
                "logprob": -0.5541111826896667
              },
              {
                "text": "there",
                "logprob": -2.577753782272339
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 2.3335857802885585,
              "max_token_negative_log_likelihood": 8.298646926879883,
              "predictive_entropy": 0.13770631223451346,
              "shannon_entropy": 1.014394343830645
            }
          },
          {
            "text": "Guillermo Mart\u00ednez Nolasco used",
            "logprob": -0.19577342889658667,
            "tokens": [
              {
                "text": "Gu",
                "logprob": -0.14243723452091217
              },
              {
                "text": "ill",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "ermo",
                "logprob": 0.0
              },
              {
                "text": "Mart\u00ednez",
                "logprob": -9.703165414975956e-05
              },
              {
                "text": "N",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "olas",
                "logprob": -2.3245540432981215e-05
              },
              {
                "text": "co",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.05320936068892479
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.024471685449341862,
              "max_token_negative_log_likelihood": 0.14243724942207336,
              "predictive_entropy": 0.02176331945655363,
              "shannon_entropy": 0.11028717534371157
            }
          },
          {
            "text": "Guillermo Mart\u00ednez Nolasco used",
            "logprob": -0.19577342889658667,
            "tokens": [
              {
                "text": "Gu",
                "logprob": -0.14243723452091217
              },
              {
                "text": "ill",
                "logprob": -6.079655122448457e-06
              },
              {
                "text": "ermo",
                "logprob": 0.0
              },
              {
                "text": "Mart\u00ednez",
                "logprob": -9.703165414975956e-05
              },
              {
                "text": "N",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "olas",
                "logprob": -2.3245540432981215e-05
              },
              {
                "text": "co",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.05320936068892479
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.024471685449341862,
              "max_token_negative_log_likelihood": 0.14243724942207336,
              "predictive_entropy": 0.02176331945655363,
              "shannon_entropy": 0.11028717534371157
            }
          }
        ],
        "cached": false,
        "request_time": 0.9942684173583984,
        "request_datetime": 1755803167
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Robert Finlay, 1st Viscount Finlay used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id451"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nRobert Finlay, 1st Viscount Finlay used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Robert Finlay, 1st Vis",
            "logprob": -0.16053335271854507,
            "tokens": [
              {
                "text": "Robert",
                "logprob": -0.1499500274658203
              },
              {
                "text": "Fin",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "lay",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": ",",
                "logprob": -8.583032467868179e-06
              },
              {
                "text": "",
                "logprob": -0.010574146173894405
              },
              {
                "text": "1",
                "logprob": 0.0
              },
              {
                "text": "st",
                "logprob": 0.0
              },
              {
                "text": "Vis",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.020066670379616625,
              "max_token_negative_log_likelihood": 0.1499500423669815,
              "predictive_entropy": 0.01744271732876257,
              "shannon_entropy": 0.09374717979779398
            }
          },
          {
            "text": "Robert Finlay, 1st Vis",
            "logprob": -0.16053335271854507,
            "tokens": [
              {
                "text": "Robert",
                "logprob": -0.1499500274658203
              },
              {
                "text": "Fin",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "lay",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": ",",
                "logprob": -8.583032467868179e-06
              },
              {
                "text": "",
                "logprob": -0.010574146173894405
              },
              {
                "text": "1",
                "logprob": 0.0
              },
              {
                "text": "st",
                "logprob": 0.0
              },
              {
                "text": "Vis",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.020066670379616625,
              "max_token_negative_log_likelihood": 0.1499500423669815,
              "predictive_entropy": 0.01744271732876257,
              "shannon_entropy": 0.09374717979779398
            }
          },
          {
            "text": "Robert Finlay, 1st Vis",
            "logprob": -0.16053335271854507,
            "tokens": [
              {
                "text": "Robert",
                "logprob": -0.1499500274658203
              },
              {
                "text": "Fin",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "lay",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": ",",
                "logprob": -8.583032467868179e-06
              },
              {
                "text": "",
                "logprob": -0.010574146173894405
              },
              {
                "text": "1",
                "logprob": 0.0
              },
              {
                "text": "st",
                "logprob": 0.0
              },
              {
                "text": "Vis",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.020066670379616625,
              "max_token_negative_log_likelihood": 0.1499500423669815,
              "predictive_entropy": 0.01744271732876257,
              "shannon_entropy": 0.09374717979779398
            }
          },
          {
            "text": "Robert Finlay, 1st Vis",
            "logprob": -0.16053335271854507,
            "tokens": [
              {
                "text": "Robert",
                "logprob": -0.1499500274658203
              },
              {
                "text": "Fin",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "lay",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": ",",
                "logprob": -8.583032467868179e-06
              },
              {
                "text": "",
                "logprob": -0.010574146173894405
              },
              {
                "text": "1",
                "logprob": 0.0
              },
              {
                "text": "st",
                "logprob": 0.0
              },
              {
                "text": "Vis",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.020066670379616625,
              "max_token_negative_log_likelihood": 0.1499500423669815,
              "predictive_entropy": 0.01744271732876257,
              "shannon_entropy": 0.09374717979779398
            }
          },
          {
            "text": "Henry St. John, 1st",
            "logprob": -5.266412786164381,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -4.11870002746582
              },
              {
                "text": "St",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ".",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "John",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.18217724561691284
              },
              {
                "text": "",
                "logprob": -0.9653762578964233
              },
              {
                "text": "1",
                "logprob": -0.0001255195093108341
              },
              {
                "text": "st",
                "logprob": -3.325883881188929e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6583015407723067,
              "max_token_negative_log_likelihood": 4.118699550628662,
              "predictive_entropy": 0.07333032774476322,
              "shannon_entropy": 0.43757254172205506
            }
          }
        ],
        "cached": false,
        "request_time": 0.9939498901367188,
        "request_datetime": 1755803167
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Jean Spencer Ashbrook used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id743"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJean Spencer Ashbrook used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Henry St. John, whose title indicates",
            "logprob": -12.936425298452313,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -2.5159857273101807
              },
              {
                "text": "St",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": ".",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "John",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.23971566557884216
              },
              {
                "text": "whose",
                "logprob": -4.4845380783081055
              },
              {
                "text": "title",
                "logprob": -2.8810718059539795
              },
              {
                "text": "indicates",
                "logprob": -2.8151135444641113
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.6170530095696538,
              "max_token_negative_log_likelihood": 4.484537601470947,
              "predictive_entropy": 0.09658000152557022,
              "shannon_entropy": 1.3424871630983333
            }
          },
          {
            "text": "Jean Spencer Ashbrook used to",
            "logprob": -0.9644681066268106,
            "tokens": [
              {
                "text": "Jean",
                "logprob": -0.7972356677055359
              },
              {
                "text": "Sp",
                "logprob": 0.0
              },
              {
                "text": "encer",
                "logprob": 0.0
              },
              {
                "text": "Ash",
                "logprob": 0.0
              },
              {
                "text": "bro",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "ok",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.16723065078258514
              },
              {
                "text": "to",
                "logprob": -5.960462772236497e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.12055851705380505,
              "max_token_negative_log_likelihood": 0.7972357273101807,
              "predictive_entropy": 0.06258654221884186,
              "shannon_entropy": 0.29286066651230713
            }
          },
          {
            "text": "It seems that your statement about Jean Sp",
            "logprob": -7.947500020265579,
            "tokens": [
              {
                "text": "It",
                "logprob": -1.3909857273101807
              },
              {
                "text": "seems",
                "logprob": -0.6439481973648071
              },
              {
                "text": "that",
                "logprob": -1.0618449449539185
              },
              {
                "text": "your",
                "logprob": -2.5592706203460693
              },
              {
                "text": "statement",
                "logprob": -1.5710762739181519
              },
              {
                "text": "about",
                "logprob": -0.7062873244285583
              },
              {
                "text": "Jean",
                "logprob": -0.014086931943893433
              },
              {
                "text": "Sp",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.9934374605072662,
              "max_token_negative_log_likelihood": 2.5592703819274902,
              "predictive_entropy": 0.24230612919200212,
              "shannon_entropy": 1.0470497812555561
            }
          },
          {
            "text": "Henry St. John, a notable historical",
            "logprob": -9.918141454458173,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -2.5159857273101807
              },
              {
                "text": "St",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": ".",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "John",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.23971566557884216
              },
              {
                "text": "a",
                "logprob": -3.9220383167266846
              },
              {
                "text": "notable",
                "logprob": -1.380086898803711
              },
              {
                "text": "historical",
                "logprob": -1.8603143692016602
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.2397676035761922,
              "max_token_negative_log_likelihood": 3.9220378398895264,
              "predictive_entropy": 0.13827609177677758,
              "shannon_entropy": 1.037917300315378
            }
          },
          {
            "text": "It seems the last entry is incomplete.",
            "logprob": -8.578028440475464,
            "tokens": [
              {
                "text": "It",
                "logprob": -1.3909857273101807
              },
              {
                "text": "seems",
                "logprob": -0.6439481973648071
              },
              {
                "text": "the",
                "logprob": -1.8118449449539185
              },
              {
                "text": "last",
                "logprob": -2.2235031127929688
              },
              {
                "text": "entry",
                "logprob": -1.369332194328308
              },
              {
                "text": "is",
                "logprob": -0.51020348072052
              },
              {
                "text": "incomplete",
                "logprob": -0.07501143217086792
              },
              {
                "text": ".",
                "logprob": -0.5531993508338928
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0722535764798522,
              "max_token_negative_log_likelihood": 2.2235031127929688,
              "predictive_entropy": 0.2828985806554556,
              "shannon_entropy": 1.2637569233775139
            }
          }
        ],
        "cached": false,
        "request_time": 1.1303308010101318,
        "request_datetime": 1755803167
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Arthur Hardwick Marsh used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id872"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nArthur Hardwick Marsh used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Arthur Hardwick Marsh used to work in",
            "logprob": -0.4152784921438837,
            "tokens": [
              {
                "text": "Arthur",
                "logprob": -0.38121289014816284
              },
              {
                "text": "Hard",
                "logprob": -2.145764938177308e-06
              },
              {
                "text": "wick",
                "logprob": -2.8013790142722428e-05
              },
              {
                "text": "Marsh",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.03381980583071709
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00014506718434859067
              },
              {
                "text": "in",
                "logprob": -7.033100700937212e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.05190982091909646,
              "max_token_negative_log_likelihood": 0.38121291995048523,
              "predictive_entropy": 0.0366652213996872,
              "shannon_entropy": 0.1729975188724353
            }
          },
          {
            "text": "It seems like the provided text is cut",
            "logprob": -10.962770357728004,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.0687129497528076
              },
              {
                "text": "seems",
                "logprob": -0.7008774876594543
              },
              {
                "text": "like",
                "logprob": -1.1448709964752197
              },
              {
                "text": "the",
                "logprob": -0.1851911097764969
              },
              {
                "text": "provided",
                "logprob": -2.9346704483032227
              },
              {
                "text": "text",
                "logprob": -1.7216885089874268
              },
              {
                "text": "is",
                "logprob": -0.974486231803894
              },
              {
                "text": "cut",
                "logprob": -1.2322726249694824
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3703462164849043,
              "max_token_negative_log_likelihood": 2.9346702098846436,
              "predictive_entropy": 0.2897809073328972,
              "shannon_entropy": 1.3869635313749313
            }
          },
          {
            "text": "Arthur Hardwick Marsh used to work in",
            "logprob": -0.4152784921438837,
            "tokens": [
              {
                "text": "Arthur",
                "logprob": -0.38121289014816284
              },
              {
                "text": "Hard",
                "logprob": -2.145764938177308e-06
              },
              {
                "text": "wick",
                "logprob": -2.8013790142722428e-05
              },
              {
                "text": "Marsh",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.03381980583071709
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00014506718434859067
              },
              {
                "text": "in",
                "logprob": -7.033100700937212e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.05190982091909646,
              "max_token_negative_log_likelihood": 0.38121291995048523,
              "predictive_entropy": 0.0366652213996872,
              "shannon_entropy": 0.1729975188724353
            }
          },
          {
            "text": "Arthur Hardwick Marsh used to work in",
            "logprob": -0.4152784921438837,
            "tokens": [
              {
                "text": "Arthur",
                "logprob": -0.38121289014816284
              },
              {
                "text": "Hard",
                "logprob": -2.145764938177308e-06
              },
              {
                "text": "wick",
                "logprob": -2.8013790142722428e-05
              },
              {
                "text": "Marsh",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.03381980583071709
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00014506718434859067
              },
              {
                "text": "in",
                "logprob": -7.033100700937212e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.05190982091909646,
              "max_token_negative_log_likelihood": 0.38121291995048523,
              "predictive_entropy": 0.0366652213996872,
              "shannon_entropy": 0.1729975188724353
            }
          },
          {
            "text": "Arthur Hardwick Marsh used to work in",
            "logprob": -0.4152784921438837,
            "tokens": [
              {
                "text": "Arthur",
                "logprob": -0.38121289014816284
              },
              {
                "text": "Hard",
                "logprob": -2.145764938177308e-06
              },
              {
                "text": "wick",
                "logprob": -2.8013790142722428e-05
              },
              {
                "text": "Marsh",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.03381980583071709
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00014506718434859067
              },
              {
                "text": "in",
                "logprob": -7.033100700937212e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.05190982091909646,
              "max_token_negative_log_likelihood": 0.38121291995048523,
              "predictive_entropy": 0.0366652213996872,
              "shannon_entropy": 0.1729975188724353
            }
          }
        ],
        "cached": false,
        "request_time": 0.9363911151885986,
        "request_datetime": 1755803168
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Isaac Hoyle used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id954"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nIsaac Hoyle used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "It appears that the provided list of individuals",
            "logprob": -12.227107234299183,
            "tokens": [
              {
                "text": "It",
                "logprob": -3.656834125518799
              },
              {
                "text": "appears",
                "logprob": -0.5820268392562866
              },
              {
                "text": "that",
                "logprob": -0.11211670190095901
              },
              {
                "text": "the",
                "logprob": -0.09597820043563843
              },
              {
                "text": "provided",
                "logprob": -2.814862012863159
              },
              {
                "text": "list",
                "logprob": -3.8388917446136475
              },
              {
                "text": "of",
                "logprob": -0.8397777080535889
              },
              {
                "text": "individuals",
                "logprob": -0.2866199016571045
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.528388292528689,
              "max_token_negative_log_likelihood": 3.8388912677764893,
              "predictive_entropy": 0.17951236944645643,
              "shannon_entropy": 0.8864452615380287
            }
          },
          {
            "text": "Isaac Hoyle used to work in London",
            "logprob": -0.6380222567895331,
            "tokens": [
              {
                "text": "Isaac",
                "logprob": -0.0630842074751854
              },
              {
                "text": "Ho",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "yle",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.1632923185825348
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -7.176141662057489e-05
              },
              {
                "text": "in",
                "logprob": -0.00011801023356383666
              },
              {
                "text": "London",
                "logprob": -0.41145560145378113
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07975278634603988,
              "max_token_negative_log_likelihood": 0.4114556312561035,
              "predictive_entropy": 0.0588467807692723,
              "shannon_entropy": 0.3136180674408422
            }
          },
          {
            "text": "Isaac Hoyle used to work in London",
            "logprob": -0.6380222567895331,
            "tokens": [
              {
                "text": "Isaac",
                "logprob": -0.0630842074751854
              },
              {
                "text": "Ho",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "yle",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.1632923185825348
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -7.176141662057489e-05
              },
              {
                "text": "in",
                "logprob": -0.00011801023356383666
              },
              {
                "text": "London",
                "logprob": -0.41145560145378113
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07975278634603988,
              "max_token_negative_log_likelihood": 0.4114556312561035,
              "predictive_entropy": 0.0588467807692723,
              "shannon_entropy": 0.3136180674408422
            }
          },
          {
            "text": "Isaac Hoyle used to work in England",
            "logprob": -2.9505222865918554,
            "tokens": [
              {
                "text": "Isaac",
                "logprob": -0.0630842074751854
              },
              {
                "text": "Ho",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "yle",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.1632923185825348
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -7.176141662057489e-05
              },
              {
                "text": "in",
                "logprob": -0.00011801023356383666
              },
              {
                "text": "England",
                "logprob": -2.7239556312561035
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3688152565437175,
              "max_token_negative_log_likelihood": 2.7239553928375244,
              "predictive_entropy": 0.04710504014019534,
              "shannon_entropy": 0.3136180674408422
            }
          },
          {
            "text": "Isaac Hoyle used to work in London",
            "logprob": -0.6380222567895331,
            "tokens": [
              {
                "text": "Isaac",
                "logprob": -0.0630842074751854
              },
              {
                "text": "Ho",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "yle",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.1632923185825348
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -7.176141662057489e-05
              },
              {
                "text": "in",
                "logprob": -0.00011801023356383666
              },
              {
                "text": "London",
                "logprob": -0.41145560145378113
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07975278634603988,
              "max_token_negative_log_likelihood": 0.4114556312561035,
              "predictive_entropy": 0.0588467807692723,
              "shannon_entropy": 0.3136180674408422
            }
          }
        ],
        "cached": false,
        "request_time": 0.9313461780548096,
        "request_datetime": 1755803168
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Ralph Stewart used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Ottawa"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ottawa (Ontario)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bytown"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Ottawa"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ottawan"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id114"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nRalph Stewart used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Ralph Stewart used to work in [City",
            "logprob": -6.7192761026890295,
            "tokens": [
              {
                "text": "Ralph",
                "logprob": -0.2300666719675064
              },
              {
                "text": "Stewart",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.044843096286058426
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.253030106658116e-05
              },
              {
                "text": "in",
                "logprob": -4.851700214203447e-05
              },
              {
                "text": "[",
                "logprob": -4.766166687011719
              },
              {
                "text": "City",
                "logprob": -1.6781284809112549
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8399093809466667,
              "max_token_negative_log_likelihood": 4.766165733337402,
              "predictive_entropy": 0.07245634757759944,
              "shannon_entropy": 0.6134919939631303
            }
          },
          {
            "text": "Ralph Stewart used to work in Toronto,",
            "logprob": -0.8466240041525381,
            "tokens": [
              {
                "text": "Ralph",
                "logprob": -0.2300666719675064
              },
              {
                "text": "Stewart",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.044843096286058426
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.253030106658116e-05
              },
              {
                "text": "in",
                "logprob": -4.851700214203447e-05
              },
              {
                "text": "Toronto",
                "logprob": -0.4849168062210083
              },
              {
                "text": ",",
                "logprob": -0.08672626316547394
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.10582800739666887,
              "max_token_negative_log_likelihood": 0.4849168360233307,
              "predictive_entropy": 0.07547997712003962,
              "shannon_entropy": 0.40115024205983474
            }
          },
          {
            "text": "Ralph Stewart used to work in Toronto,",
            "logprob": -0.8466240041525381,
            "tokens": [
              {
                "text": "Ralph",
                "logprob": -0.2300666719675064
              },
              {
                "text": "Stewart",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.044843096286058426
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.253030106658116e-05
              },
              {
                "text": "in",
                "logprob": -4.851700214203447e-05
              },
              {
                "text": "Toronto",
                "logprob": -0.4849168062210083
              },
              {
                "text": ",",
                "logprob": -0.08672626316547394
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.10582800739666887,
              "max_token_negative_log_likelihood": 0.4849168360233307,
              "predictive_entropy": 0.07547997712003962,
              "shannon_entropy": 0.40115024205983474
            }
          },
          {
            "text": "Ralph Stewart used to work in Toronto,",
            "logprob": -0.8466240041525381,
            "tokens": [
              {
                "text": "Ralph",
                "logprob": -0.2300666719675064
              },
              {
                "text": "Stewart",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.044843096286058426
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.253030106658116e-05
              },
              {
                "text": "in",
                "logprob": -4.851700214203447e-05
              },
              {
                "text": "Toronto",
                "logprob": -0.4849168062210083
              },
              {
                "text": ",",
                "logprob": -0.08672626316547394
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.10582800739666887,
              "max_token_negative_log_likelihood": 0.4849168360233307,
              "predictive_entropy": 0.07547997712003962,
              "shannon_entropy": 0.40115024205983474
            }
          },
          {
            "text": "Ralph Stewart used to work in Sydney,",
            "logprob": -5.768564971593143,
            "tokens": [
              {
                "text": "Ralph",
                "logprob": -0.2300666719675064
              },
              {
                "text": "Stewart",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.044843096286058426
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.253030106658116e-05
              },
              {
                "text": "in",
                "logprob": -4.851700214203447e-05
              },
              {
                "text": "Sydney",
                "logprob": -5.484916687011719
              },
              {
                "text": ",",
                "logprob": -0.008667349815368652
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.7210703283244602,
              "max_token_negative_log_likelihood": 5.484914302825928,
              "predictive_entropy": 0.03213501645564065,
              "shannon_entropy": 0.37126193578109934
            }
          }
        ],
        "cached": false,
        "request_time": 1.0085411071777344,
        "request_datetime": 1755803168
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Homer Earl Capehart used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id859"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nHomer Earl Capehart used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Henry St. John used to work in",
            "logprob": -3.5390897495635727,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -1.568740725517273
              },
              {
                "text": "St",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": 0.0
              },
              {
                "text": "John",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -1.8972584009170532
              },
              {
                "text": "to",
                "logprob": -4.327203714638017e-05
              },
              {
                "text": "work",
                "logprob": -0.047486480325460434
              },
              {
                "text": "in",
                "logprob": -0.02556087076663971
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.44238620635633197,
              "max_token_negative_log_likelihood": 1.8972582817077637,
              "predictive_entropy": 0.08519661042282678,
              "shannon_entropy": 0.2865066515984118
            }
          },
          {
            "text": "Homer Earl Capehart used to work",
            "logprob": -0.4895542209433188,
            "tokens": [
              {
                "text": "H",
                "logprob": -0.38124072551727295
              },
              {
                "text": "omer",
                "logprob": 0.0
              },
              {
                "text": "Earl",
                "logprob": -2.8967437174287625e-05
              },
              {
                "text": "Cape",
                "logprob": 0.0
              },
              {
                "text": "hart",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10818415880203247
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.0001003691868390888
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06119428177566988,
              "max_token_negative_log_likelihood": 0.38124075531959534,
              "predictive_entropy": 0.04470163515497916,
              "shannon_entropy": 0.16767378854238651
            }
          },
          {
            "text": "Homer Earl Capehart, like the",
            "logprob": -4.627801179465678,
            "tokens": [
              {
                "text": "H",
                "logprob": -0.38124072551727295
              },
              {
                "text": "omer",
                "logprob": 0.0
              },
              {
                "text": "Earl",
                "logprob": -2.8967437174287625e-05
              },
              {
                "text": "Cape",
                "logprob": 0.0
              },
              {
                "text": "hart",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -2.5456840991973877
              },
              {
                "text": "like",
                "logprob": -1.4468913078308105
              },
              {
                "text": "the",
                "logprob": -0.2539560794830322
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5784751400876758,
              "max_token_negative_log_likelihood": 2.5456840991973877,
              "predictive_entropy": 0.12468840362862466,
              "shannon_entropy": 0.5754789995421337
            }
          },
          {
            "text": "Homer Earl Capehart used to work",
            "logprob": -0.4895542209433188,
            "tokens": [
              {
                "text": "H",
                "logprob": -0.38124072551727295
              },
              {
                "text": "omer",
                "logprob": 0.0
              },
              {
                "text": "Earl",
                "logprob": -2.8967437174287625e-05
              },
              {
                "text": "Cape",
                "logprob": 0.0
              },
              {
                "text": "hart",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10818415880203247
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.0001003691868390888
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06119428177566988,
              "max_token_negative_log_likelihood": 0.38124075531959534,
              "predictive_entropy": 0.04470163515497916,
              "shannon_entropy": 0.16767378854238651
            }
          },
          {
            "text": "Homer Earl Capehart used to work",
            "logprob": -0.4895542209433188,
            "tokens": [
              {
                "text": "H",
                "logprob": -0.38124072551727295
              },
              {
                "text": "omer",
                "logprob": 0.0
              },
              {
                "text": "Earl",
                "logprob": -2.8967437174287625e-05
              },
              {
                "text": "Cape",
                "logprob": 0.0
              },
              {
                "text": "hart",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10818415880203247
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.0001003691868390888
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06119428177566988,
              "max_token_negative_log_likelihood": 0.38124075531959534,
              "predictive_entropy": 0.04470163515497916,
              "shannon_entropy": 0.16767378854238651
            }
          }
        ],
        "cached": false,
        "request_time": 1.0079925060272217,
        "request_datetime": 1755803169
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Gaetano Sabatini used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Bologna"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bologna, Italy"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bolognian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bolognese"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id792"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nGaetano Sabatini used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Gaetano Sabatini used to",
            "logprob": -0.114497777074547,
            "tokens": [
              {
                "text": "Ga",
                "logprob": -0.09002024680376053
              },
              {
                "text": "et",
                "logprob": 0.0
              },
              {
                "text": "ano",
                "logprob": 0.0
              },
              {
                "text": "Sab",
                "logprob": 0.0
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "ini",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.024477291852235794
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014312228653583503,
              "max_token_negative_log_likelihood": 0.09002027660608292,
              "predictive_entropy": 0.013269544346254492,
              "shannon_entropy": 0.07935360088197708
            }
          },
          {
            "text": "Gaetano Sabatini used to",
            "logprob": -0.114497777074547,
            "tokens": [
              {
                "text": "Ga",
                "logprob": -0.09002024680376053
              },
              {
                "text": "et",
                "logprob": 0.0
              },
              {
                "text": "ano",
                "logprob": 0.0
              },
              {
                "text": "Sab",
                "logprob": 0.0
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "ini",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.024477291852235794
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014312228653583503,
              "max_token_negative_log_likelihood": 0.09002027660608292,
              "predictive_entropy": 0.013269544346254492,
              "shannon_entropy": 0.07935360088197708
            }
          },
          {
            "text": "Gaetano Sabatini used to",
            "logprob": -0.114497777074547,
            "tokens": [
              {
                "text": "Ga",
                "logprob": -0.09002024680376053
              },
              {
                "text": "et",
                "logprob": 0.0
              },
              {
                "text": "ano",
                "logprob": 0.0
              },
              {
                "text": "Sab",
                "logprob": 0.0
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "ini",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.024477291852235794
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014312228653583503,
              "max_token_negative_log_likelihood": 0.09002027660608292,
              "predictive_entropy": 0.013269544346254492,
              "shannon_entropy": 0.07935360088197708
            }
          },
          {
            "text": "Gaetano Sabatini used to",
            "logprob": -0.114497777074547,
            "tokens": [
              {
                "text": "Ga",
                "logprob": -0.09002024680376053
              },
              {
                "text": "et",
                "logprob": 0.0
              },
              {
                "text": "ano",
                "logprob": 0.0
              },
              {
                "text": "Sab",
                "logprob": 0.0
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "ini",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.024477291852235794
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014312228653583503,
              "max_token_negative_log_likelihood": 0.09002027660608292,
              "predictive_entropy": 0.013269544346254492,
              "shannon_entropy": 0.07935360088197708
            }
          },
          {
            "text": "Gaetano Sabatini used to",
            "logprob": -0.114497777074547,
            "tokens": [
              {
                "text": "Ga",
                "logprob": -0.09002024680376053
              },
              {
                "text": "et",
                "logprob": 0.0
              },
              {
                "text": "ano",
                "logprob": 0.0
              },
              {
                "text": "Sab",
                "logprob": 0.0
              },
              {
                "text": "at",
                "logprob": 0.0
              },
              {
                "text": "ini",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.024477291852235794
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014312228653583503,
              "max_token_negative_log_likelihood": 0.09002027660608292,
              "predictive_entropy": 0.013269544346254492,
              "shannon_entropy": 0.07935360088197708
            }
          }
        ],
        "cached": false,
        "request_time": 1.0098278522491455,
        "request_datetime": 1755803169
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Matthias Kuhle used to work in"
        },
        "references": [
          {
            "output": {
              "text": "G\u00f6ttingen"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id881"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nMatthias Kuhle used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Matthias Kuhle, a well",
            "logprob": -5.217700937005475,
            "tokens": [
              {
                "text": "Matth",
                "logprob": -0.09296553581953049
              },
              {
                "text": "ias",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "uh",
                "logprob": -0.0007101159426383674
              },
              {
                "text": "le",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -1.646831750869751
              },
              {
                "text": "a",
                "logprob": -0.8076590895652771
              },
              {
                "text": "well",
                "logprob": -2.6695332527160645
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6522125833072039,
              "max_token_negative_log_likelihood": 2.6695330142974854,
              "predictive_entropy": 0.11847424802535045,
              "shannon_entropy": 0.7085282452420283
            }
          },
          {
            "text": "Matthias Kuhle used to work",
            "logprob": -0.4290092138682553,
            "tokens": [
              {
                "text": "Matth",
                "logprob": -0.09296553581953049
              },
              {
                "text": "ias",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "uh",
                "logprob": -0.0007101159426383674
              },
              {
                "text": "le",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.334331750869751
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.0010002615163102746
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.053626157307100186,
              "max_token_negative_log_likelihood": 0.33433178067207336,
              "predictive_entropy": 0.04071788497083517,
              "shannon_entropy": 0.1808092200031619
            }
          },
          {
            "text": "Matthias Kuhle used to work",
            "logprob": -0.4290092138682553,
            "tokens": [
              {
                "text": "Matth",
                "logprob": -0.09296553581953049
              },
              {
                "text": "ias",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "uh",
                "logprob": -0.0007101159426383674
              },
              {
                "text": "le",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.334331750869751
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.0010002615163102746
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.053626157307100186,
              "max_token_negative_log_likelihood": 0.33433178067207336,
              "predictive_entropy": 0.04071788497083517,
              "shannon_entropy": 0.1808092200031619
            }
          },
          {
            "text": "Matthias Kuhle worked professionally",
            "logprob": -11.131083765241101,
            "tokens": [
              {
                "text": "Matth",
                "logprob": -0.09296553581953049
              },
              {
                "text": "ias",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "uh",
                "logprob": -0.0007101159426383674
              },
              {
                "text": "le",
                "logprob": 0.0
              },
              {
                "text": "worked",
                "logprob": -4.990581512451172
              },
              {
                "text": "profession",
                "logprob": -6.046825408935547
              },
              {
                "text": "ally",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3913848184384676,
              "max_token_negative_log_likelihood": 6.046821117401123,
              "predictive_entropy": 0.016708839029789146,
              "shannon_entropy": 0.22844856058927787
            }
          },
          {
            "text": "Matthias Kuhle used to work",
            "logprob": -0.4290092138682553,
            "tokens": [
              {
                "text": "Matth",
                "logprob": -0.09296553581953049
              },
              {
                "text": "ias",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "K",
                "logprob": 0.0
              },
              {
                "text": "uh",
                "logprob": -0.0007101159426383674
              },
              {
                "text": "le",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.334331750869751
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.0010002615163102746
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.053626157307100186,
              "max_token_negative_log_likelihood": 0.33433178067207336,
              "predictive_entropy": 0.04071788497083517,
              "shannon_entropy": 0.1808092200031619
            }
          }
        ],
        "cached": false,
        "request_time": 1.0108962059020996,
        "request_datetime": 1755803169
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "James Alonzo Stahle used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id626"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJames Alonzo Stahle used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "James Alonzo Stahle used",
            "logprob": -0.09075087681270588,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.04968991503119469
              },
              {
                "text": "Al",
                "logprob": 0.0
              },
              {
                "text": "on",
                "logprob": 0.0
              },
              {
                "text": "zo",
                "logprob": 0.0
              },
              {
                "text": "St",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "ah",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "le",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.04105893522500992
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011343856342314496,
              "max_token_negative_log_likelihood": 0.04968991130590439,
              "predictive_entropy": 0.010836301371259793,
              "shannon_entropy": 0.06781090281999935
            }
          },
          {
            "text": "James Alonzo Stahle used",
            "logprob": -0.09075087681270588,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.04968991503119469
              },
              {
                "text": "Al",
                "logprob": 0.0
              },
              {
                "text": "on",
                "logprob": 0.0
              },
              {
                "text": "zo",
                "logprob": 0.0
              },
              {
                "text": "St",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "ah",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "le",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.04105893522500992
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011343856342314496,
              "max_token_negative_log_likelihood": 0.04968991130590439,
              "predictive_entropy": 0.010836301371259793,
              "shannon_entropy": 0.06781090281999935
            }
          },
          {
            "text": "James Alonzo Stahle used",
            "logprob": -0.09075087681270588,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.04968991503119469
              },
              {
                "text": "Al",
                "logprob": 0.0
              },
              {
                "text": "on",
                "logprob": 0.0
              },
              {
                "text": "zo",
                "logprob": 0.0
              },
              {
                "text": "St",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "ah",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "le",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.04105893522500992
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011343856342314496,
              "max_token_negative_log_likelihood": 0.04968991130590439,
              "predictive_entropy": 0.010836301371259793,
              "shannon_entropy": 0.06781090281999935
            }
          },
          {
            "text": "James Alonzo Stahle used",
            "logprob": -0.09075087681270588,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.04968991503119469
              },
              {
                "text": "Al",
                "logprob": 0.0
              },
              {
                "text": "on",
                "logprob": 0.0
              },
              {
                "text": "zo",
                "logprob": 0.0
              },
              {
                "text": "St",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "ah",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "le",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.04105893522500992
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011343856342314496,
              "max_token_negative_log_likelihood": 0.04968991130590439,
              "predictive_entropy": 0.010836301371259793,
              "shannon_entropy": 0.06781090281999935
            }
          },
          {
            "text": "James Alonzo Stahle used",
            "logprob": -0.09075087681270588,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.04968991503119469
              },
              {
                "text": "Al",
                "logprob": 0.0
              },
              {
                "text": "on",
                "logprob": 0.0
              },
              {
                "text": "zo",
                "logprob": 0.0
              },
              {
                "text": "St",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "ah",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "le",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.04105893522500992
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011343856342314496,
              "max_token_negative_log_likelihood": 0.04968991130590439,
              "predictive_entropy": 0.010836301371259793,
              "shannon_entropy": 0.06781090281999935
            }
          }
        ],
        "cached": false,
        "request_time": 1.022139549255371,
        "request_datetime": 1755803169
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "\u00c1ngel P\u00e9rez Mart\u00ednez used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Madrid"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Madrid"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Madrid, Spain"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Madrilenian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id203"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\n\u00c1ngel P\u00e9rez Mart\u00ednez used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "\u00c1quel \u00c1ngel P\u00e9rez Mart\u00ednez usaba",
            "logprob": -9.799997157928367,
            "tokens": [
              {
                "text": "\u00c1",
                "logprob": -3.5180609226226807
              },
              {
                "text": "quel",
                "logprob": -3.903452157974243
              },
              {
                "text": "\u00c1ng",
                "logprob": -0.12086901813745499
              },
              {
                "text": "el",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "P\u00e9rez",
                "logprob": -2.8967437174287625e-05
              },
              {
                "text": "Mart\u00ednez",
                "logprob": 0.0
              },
              {
                "text": "us",
                "logprob": -1.9378931522369385
              },
              {
                "text": "aba",
                "logprob": -0.31969282031059265
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.2249995135296121,
              "max_token_negative_log_likelihood": 3.903451681137085,
              "predictive_entropy": 0.10018739192173598,
              "shannon_entropy": 0.7287073754587965
            }
          },
          {
            "text": "\u00c1ngel P\u00e9rez Mart\u00ednez used to work in",
            "logprob": -0.2428169025869238,
            "tokens": [
              {
                "text": "\u00c1ng",
                "logprob": -0.2368108630180359
              },
              {
                "text": "el",
                "logprob": -1.311301275563892e-06
              },
              {
                "text": "P\u00e9rez",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "Mart\u00ednez",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.005866807885468006
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -7.545663538621739e-05
              },
              {
                "text": "in",
                "logprob": -6.19869097135961e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030352119370164132,
              "max_token_negative_log_likelihood": 0.23681087791919708,
              "predictive_entropy": 0.024106100710810097,
              "shannon_entropy": 0.11265347072664156
            }
          },
          {
            "text": "\u00c1ngel P\u00e9rez Mart\u00ednez used to work in",
            "logprob": -0.2428169025869238,
            "tokens": [
              {
                "text": "\u00c1ng",
                "logprob": -0.2368108630180359
              },
              {
                "text": "el",
                "logprob": -1.311301275563892e-06
              },
              {
                "text": "P\u00e9rez",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "Mart\u00ednez",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.005866807885468006
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -7.545663538621739e-05
              },
              {
                "text": "in",
                "logprob": -6.19869097135961e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030352119370164132,
              "max_token_negative_log_likelihood": 0.23681087791919708,
              "predictive_entropy": 0.024106100710810097,
              "shannon_entropy": 0.11265347072664156
            }
          },
          {
            "text": "\u00c1ngel P\u00e9rez Mart\u00ednez used to work in",
            "logprob": -0.2428169025869238,
            "tokens": [
              {
                "text": "\u00c1ng",
                "logprob": -0.2368108630180359
              },
              {
                "text": "el",
                "logprob": -1.311301275563892e-06
              },
              {
                "text": "P\u00e9rez",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "Mart\u00ednez",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.005866807885468006
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -7.545663538621739e-05
              },
              {
                "text": "in",
                "logprob": -6.19869097135961e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030352119370164132,
              "max_token_negative_log_likelihood": 0.23681087791919708,
              "predictive_entropy": 0.024106100710810097,
              "shannon_entropy": 0.11265347072664156
            }
          },
          {
            "text": "\u00c1ngel P\u00e9rez Mart\u00ednez used to work",
            "logprob": -4.242029752334808,
            "tokens": [
              {
                "text": "\u00c1",
                "logprob": -3.5180609226226807
              },
              {
                "text": "ng",
                "logprob": -0.7159521579742432
              },
              {
                "text": "el",
                "logprob": 0.0
              },
              {
                "text": "P\u00e9rez",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "Mart\u00ednez",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.007926911115646362
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -8.916457591112703e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5302536620602201,
              "max_token_negative_log_likelihood": 3.5180604457855225,
              "predictive_entropy": 0.05777420833781832,
              "shannon_entropy": 0.30571719297898525
            }
          }
        ],
        "cached": false,
        "request_time": 1.0094945430755615,
        "request_datetime": 1755803170
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Matthias Braun used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Prague"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Praha"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Hlavn\u00ed m\u011bsto Praha"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Prague"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Praguer"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id258"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nMatthias Braun used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Matthias Braun used to work in Mun",
            "logprob": -1.8866898308112354,
            "tokens": [
              {
                "text": "Matth",
                "logprob": -0.09479670971632004
              },
              {
                "text": "ias",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Braun",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.03208697959780693
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00011729506513802335
              },
              {
                "text": "in",
                "logprob": -0.0001248043408850208
              },
              {
                "text": "Mun",
                "logprob": -1.7595628499984741
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.23583621668517196,
              "max_token_negative_log_likelihood": 1.7595627307891846,
              "predictive_entropy": 0.05254952984883943,
              "shannon_entropy": 0.3436381283059404
            }
          },
          {
            "text": "Based on the pattern provided, it seems",
            "logprob": -6.499595983623294,
            "tokens": [
              {
                "text": "Based",
                "logprob": -3.407296657562256
              },
              {
                "text": "on",
                "logprob": -0.000386640167562291
              },
              {
                "text": "the",
                "logprob": -0.009039430879056454
              },
              {
                "text": "pattern",
                "logprob": -0.3997025787830353
              },
              {
                "text": "provided",
                "logprob": -1.0403927564620972
              },
              {
                "text": ",",
                "logprob": -0.29321742057800293
              },
              {
                "text": "it",
                "logprob": -0.45275819301605225
              },
              {
                "text": "seems",
                "logprob": -0.8968023061752319
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8124494487710763,
              "max_token_negative_log_likelihood": 3.4072964191436768,
              "predictive_entropy": 0.20377522739363485,
              "shannon_entropy": 0.8379765404970385
            }
          },
          {
            "text": "Matthias Braun used to work in Frankfurt",
            "logprob": -1.2304398308112354,
            "tokens": [
              {
                "text": "Matth",
                "logprob": -0.09479670971632004
              },
              {
                "text": "ias",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Braun",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.03208697959780693
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00011729506513802335
              },
              {
                "text": "in",
                "logprob": -0.0001248043408850208
              },
              {
                "text": "Frankfurt",
                "logprob": -1.1033128499984741
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.15380498158633316,
              "max_token_negative_log_likelihood": 1.1033128499984741,
              "predictive_entropy": 0.06044830012157121,
              "shannon_entropy": 0.3436381283059404
            }
          },
          {
            "text": "Matthias Braun used to work in Berlin",
            "logprob": -1.8554398308112354,
            "tokens": [
              {
                "text": "Matth",
                "logprob": -0.09479670971632004
              },
              {
                "text": "ias",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Braun",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.03208697959780693
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00011729506513802335
              },
              {
                "text": "in",
                "logprob": -0.0001248043408850208
              },
              {
                "text": "Berlin",
                "logprob": -1.7283128499984741
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.23192996668517196,
              "max_token_negative_log_likelihood": 1.7283127307891846,
              "predictive_entropy": 0.05305755141213098,
              "shannon_entropy": 0.3436381283059404
            }
          },
          {
            "text": "Matthias Braun used to work in Leipzig",
            "logprob": -2.230439950020525,
            "tokens": [
              {
                "text": "Matth",
                "logprob": -0.09479670971632004
              },
              {
                "text": "ias",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Braun",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.03208697959780693
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00011729506513802335
              },
              {
                "text": "in",
                "logprob": -0.0001248043408850208
              },
              {
                "text": "Leipzig",
                "logprob": -2.1033129692077637
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.27880496668517196,
              "max_token_negative_log_likelihood": 2.1033127307891846,
              "predictive_entropy": 0.04678155484631219,
              "shannon_entropy": 0.3436381283059404
            }
          }
        ],
        "cached": false,
        "request_time": 1.0117623805999756,
        "request_datetime": 1755803170
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Gordon Leo McDonough used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id821"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nGordon Leo McDonough used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Gordon Leo McDonough used to work",
            "logprob": -0.30670701344955376,
            "tokens": [
              {
                "text": "Gordon",
                "logprob": -0.24894143640995026
              },
              {
                "text": "Leo",
                "logprob": -2.4318398573086597e-05
              },
              {
                "text": "Mc",
                "logprob": -1.7881377516459906e-06
              },
              {
                "text": "Don",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ough",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.05765710026025772
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -8.21318244561553e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03833837108047433,
              "max_token_negative_log_likelihood": 0.24894140660762787,
              "predictive_entropy": 0.031077043626538625,
              "shannon_entropy": 0.14579395403412576
            }
          },
          {
            "text": "It appears that the text regarding \"G",
            "logprob": -12.844114884734147,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.030191421508789
              },
              {
                "text": "appears",
                "logprob": -0.7683281898498535
              },
              {
                "text": "that",
                "logprob": -0.19581298530101776
              },
              {
                "text": "the",
                "logprob": -0.10379797220230103
              },
              {
                "text": "text",
                "logprob": -4.301814079284668
              },
              {
                "text": "regarding",
                "logprob": -3.6059229373931885
              },
              {
                "text": "\"",
                "logprob": -1.8382471799850464
              },
              {
                "text": "G",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.605514172464611,
              "max_token_negative_log_likelihood": 4.301813125610352,
              "predictive_entropy": 0.16576856235042214,
              "shannon_entropy": 0.8656539529315523
            }
          },
          {
            "text": "Gordon Leo McDonough appears to be",
            "logprob": -4.726052509322692,
            "tokens": [
              {
                "text": "Gordon",
                "logprob": -0.24894143640995026
              },
              {
                "text": "Leo",
                "logprob": -2.4318398573086597e-05
              },
              {
                "text": "Mc",
                "logprob": -1.7881377516459906e-06
              },
              {
                "text": "Don",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ough",
                "logprob": 0.0
              },
              {
                "text": "appears",
                "logprob": -4.057657241821289
              },
              {
                "text": "to",
                "logprob": -0.000542493537068367
              },
              {
                "text": "be",
                "logprob": -0.41888511180877686
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.59075644406491,
              "max_token_negative_log_likelihood": 4.057656288146973,
              "predictive_entropy": 0.06754230728191146,
              "shannon_entropy": 0.23633487432353917
            }
          },
          {
            "text": "It seems that the information about Gordon Leo",
            "logprob": -5.189670546820707,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.030191421508789
              },
              {
                "text": "seems",
                "logprob": -0.6433281898498535
              },
              {
                "text": "that",
                "logprob": -0.9968270659446716
              },
              {
                "text": "the",
                "logprob": -0.1501404494047165
              },
              {
                "text": "information",
                "logprob": -0.5630260109901428
              },
              {
                "text": "about",
                "logprob": -0.7052364945411682
              },
              {
                "text": "Gordon",
                "logprob": -0.10087573528289795
              },
              {
                "text": "Leo",
                "logprob": -4.51792984677013e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6487087878745115,
              "max_token_negative_log_likelihood": 2.03019118309021,
              "predictive_entropy": 0.23275286784701166,
              "shannon_entropy": 0.8370545537181897
            }
          },
          {
            "text": "Gordon Leo McDonough used to work",
            "logprob": -0.30670701344955376,
            "tokens": [
              {
                "text": "Gordon",
                "logprob": -0.24894143640995026
              },
              {
                "text": "Leo",
                "logprob": -2.4318398573086597e-05
              },
              {
                "text": "Mc",
                "logprob": -1.7881377516459906e-06
              },
              {
                "text": "Don",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ough",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.05765710026025772
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -8.21318244561553e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03833837108047433,
              "max_token_negative_log_likelihood": 0.24894140660762787,
              "predictive_entropy": 0.031077043626538625,
              "shannon_entropy": 0.14579395403412576
            }
          }
        ],
        "cached": false,
        "request_time": 1.0121090412139893,
        "request_datetime": 1755803170
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Damasus II used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Rome"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Eternal City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Roma"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Rome, Italy"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Roman"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Papal States"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Papal State"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Church State"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "State of the Church"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Stato della Chiesa"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Status Ecclesiae"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ecclesiastical States"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id558"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nDamasus II used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Damasus II, also known as",
            "logprob": -1.7891270667308774,
            "tokens": [
              {
                "text": "Dam",
                "logprob": -0.1990564465522766
              },
              {
                "text": "as",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "II",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": ",",
                "logprob": -0.7811080813407898
              },
              {
                "text": "also",
                "logprob": -0.7578006386756897
              },
              {
                "text": "known",
                "logprob": -0.022143498063087463
              },
              {
                "text": "as",
                "logprob": -0.029017210006713867
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.22364088823094797,
              "max_token_negative_log_likelihood": 0.7811080813407898,
              "predictive_entropy": 0.11572760855771946,
              "shannon_entropy": 0.5775808614683218
            }
          },
          {
            "text": "Damasus II did not have any",
            "logprob": -10.058418213636621,
            "tokens": [
              {
                "text": "Dam",
                "logprob": -0.1990564465522766
              },
              {
                "text": "as",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "II",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "did",
                "logprob": -5.2811079025268555
              },
              {
                "text": "not",
                "logprob": -3.6954195820726454e-05
              },
              {
                "text": "have",
                "logprob": -0.5415536165237427
              },
              {
                "text": "any",
                "logprob": -4.0366621017456055
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.2573019751271932,
              "max_token_negative_log_likelihood": 5.281105995178223,
              "predictive_entropy": 0.0720501948693908,
              "shannon_entropy": 0.530383515329321
            }
          },
          {
            "text": "Damasus II is not a widely",
            "logprob": -5.803217053412816,
            "tokens": [
              {
                "text": "Dam",
                "logprob": -0.1990564465522766
              },
              {
                "text": "as",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "II",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "is",
                "logprob": -3.4061081409454346
              },
              {
                "text": "not",
                "logprob": -0.9811064004898071
              },
              {
                "text": "a",
                "logprob": -0.2921539545059204
              },
              {
                "text": "widely",
                "logprob": -0.9247909188270569
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.7254020869732631,
              "max_token_negative_log_likelihood": 3.4061076641082764,
              "predictive_entropy": 0.15360569208853292,
              "shannon_entropy": 0.8862023835074968
            }
          },
          {
            "text": "Damasus II (also known as",
            "logprob": -6.660170447080752,
            "tokens": [
              {
                "text": "Dam",
                "logprob": -0.1990564465522766
              },
              {
                "text": "as",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "II",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "(",
                "logprob": -5.1873579025268555
              },
              {
                "text": "also",
                "logprob": -1.202962875366211
              },
              {
                "text": "known",
                "logprob": -0.04643142223358154
              },
              {
                "text": "as",
                "logprob": -0.02436060830950737
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8325211298652722,
              "max_token_negative_log_likelihood": 5.187356472015381,
              "predictive_entropy": 0.07768272864625203,
              "shannon_entropy": 0.6270264235329694
            }
          },
          {
            "text": "Damasus II appears to have been",
            "logprob": -4.498418070841005,
            "tokens": [
              {
                "text": "Dam",
                "logprob": -0.1990564465522766
              },
              {
                "text": "as",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "II",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "appears",
                "logprob": -1.3436081409454346
              },
              {
                "text": "to",
                "logprob": -0.003491260576993227
              },
              {
                "text": "have",
                "logprob": -2.4470009803771973
              },
              {
                "text": "been",
                "logprob": -0.5052600502967834
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5623022439250054,
              "max_token_negative_log_likelihood": 2.4470009803771973,
              "predictive_entropy": 0.1292251626727392,
              "shannon_entropy": 0.4987750313714958
            }
          }
        ],
        "cached": false,
        "request_time": 1.0040011405944824,
        "request_datetime": 1755803170
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Dolph Briscoe used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Austin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Austin, Texas"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Austin, TX"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Austin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Austin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id649"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nDolph Briscoe used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "It appears that the information provided was cut",
            "logprob": -8.772728569805622,
            "tokens": [
              {
                "text": "It",
                "logprob": -0.48653537034988403
              },
              {
                "text": "appears",
                "logprob": -0.6762130260467529
              },
              {
                "text": "that",
                "logprob": -0.1953820437192917
              },
              {
                "text": "the",
                "logprob": -0.09965891391038895
              },
              {
                "text": "information",
                "logprob": -0.9391017556190491
              },
              {
                "text": "provided",
                "logprob": -3.007420063018799
              },
              {
                "text": "was",
                "logprob": -3.247654438018799
              },
              {
                "text": "cut",
                "logprob": -0.12076295912265778
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.096591000445187,
              "max_token_negative_log_likelihood": 3.2476541996002197,
              "predictive_entropy": 0.2053662883117795,
              "shannon_entropy": 1.0572527833282948
            }
          },
          {
            "text": "It appears that the last sentence of the",
            "logprob": -9.304884366691113,
            "tokens": [
              {
                "text": "It",
                "logprob": -0.48653537034988403
              },
              {
                "text": "appears",
                "logprob": -0.6762130260467529
              },
              {
                "text": "that",
                "logprob": -0.1953820437192917
              },
              {
                "text": "the",
                "logprob": -0.09965891391038895
              },
              {
                "text": "last",
                "logprob": -1.3453516960144043
              },
              {
                "text": "sentence",
                "logprob": -1.7920575141906738
              },
              {
                "text": "of",
                "logprob": -3.3499693870544434
              },
              {
                "text": "the",
                "logprob": -1.3597164154052734
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1631104731932282,
              "max_token_negative_log_likelihood": 3.3499691486358643,
              "predictive_entropy": 0.25118658784776926,
              "shannon_entropy": 1.090195994824171
            }
          },
          {
            "text": "It seems the statement about Dolph Br",
            "logprob": -5.302853350935031,
            "tokens": [
              {
                "text": "It",
                "logprob": -0.48653537034988403
              },
              {
                "text": "seems",
                "logprob": -0.7387130260467529
              },
              {
                "text": "the",
                "logprob": -1.6436842679977417
              },
              {
                "text": "statement",
                "logprob": -1.771864414215088
              },
              {
                "text": "about",
                "logprob": -0.6617258787155151
              },
              {
                "text": "Dol",
                "logprob": -0.0003302744007669389
              },
              {
                "text": "ph",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Br",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6628566377985425,
              "max_token_negative_log_likelihood": 1.7718642950057983,
              "predictive_entropy": 0.20158395234830095,
              "shannon_entropy": 0.7923173004529392
            }
          },
          {
            "text": "It seems that the information about Dolph",
            "logprob": -3.6433714712038565,
            "tokens": [
              {
                "text": "It",
                "logprob": -0.48653537034988403
              },
              {
                "text": "seems",
                "logprob": -0.7387130260467529
              },
              {
                "text": "that",
                "logprob": -1.0186842679977417
              },
              {
                "text": "the",
                "logprob": -0.13934864103794098
              },
              {
                "text": "information",
                "logprob": -0.6621319055557251
              },
              {
                "text": "about",
                "logprob": -0.5883671641349792
              },
              {
                "text": "Dol",
                "logprob": -0.009590976871550083
              },
              {
                "text": "ph",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4554214305244404,
              "max_token_negative_log_likelihood": 1.0186842679977417,
              "predictive_entropy": 0.2273396656382829,
              "shannon_entropy": 0.8526666041608166
            }
          },
          {
            "text": "It seems like the statement about Dolph",
            "logprob": -5.518714115722098,
            "tokens": [
              {
                "text": "It",
                "logprob": -0.48653537034988403
              },
              {
                "text": "seems",
                "logprob": -0.7387130260467529
              },
              {
                "text": "like",
                "logprob": -1.0186842679977417
              },
              {
                "text": "the",
                "logprob": -0.23943206667900085
              },
              {
                "text": "statement",
                "logprob": -2.2396905422210693
              },
              {
                "text": "about",
                "logprob": -0.7953620553016663
              },
              {
                "text": "Dol",
                "logprob": -0.00029666791670024395
              },
              {
                "text": "ph",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6898392680159322,
              "max_token_negative_log_likelihood": 2.2396905422210693,
              "predictive_entropy": 0.225764393893769,
              "shannon_entropy": 0.898056630331439
            }
          }
        ],
        "cached": false,
        "request_time": 1.013960361480713,
        "request_datetime": 1755803171
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "P\u00e9ter E\u00f6tv\u00f6s used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Cologne"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "K\u00f6ln"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Kreisfreie Stadt K\u00f6ln"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Cologne, Germany"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Cologne (Germany)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Cologner"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Karlsruhe"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id250"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nP\u00e9ter E\u00f6tv\u00f6s used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "It seems that the name \"P\u00e9ter",
            "logprob": -11.05279661628174,
            "tokens": [
              {
                "text": "It",
                "logprob": -3.0900864601135254
              },
              {
                "text": "seems",
                "logprob": -0.6212844848632812
              },
              {
                "text": "that",
                "logprob": -1.1570158004760742
              },
              {
                "text": "the",
                "logprob": -0.20290817320346832
              },
              {
                "text": "name",
                "logprob": -4.961607456207275
              },
              {
                "text": "\"",
                "logprob": -1.019845724105835
              },
              {
                "text": "P",
                "logprob": -7.510157047363464e-06
              },
              {
                "text": "\u00e9ter",
                "logprob": -4.100715523236431e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3815993760866832,
              "max_token_negative_log_likelihood": 4.961606025695801,
              "predictive_entropy": 0.1758016882309903,
              "shannon_entropy": 0.8522648407833913
            }
          },
          {
            "text": "P\u00e9ter E\u00f6tv\u00f6s used to",
            "logprob": -0.5000407621221825,
            "tokens": [
              {
                "text": "P",
                "logprob": -0.09008648246526718
              },
              {
                "text": "\u00e9ter",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "E",
                "logprob": 0.0
              },
              {
                "text": "\u00f6t",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "v",
                "logprob": 0.0
              },
              {
                "text": "\u00f6s",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "used",
                "logprob": -0.4099491536617279
              },
              {
                "text": "to",
                "logprob": -8.344646857949556e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06250509060972576,
              "max_token_negative_log_likelihood": 0.4099491238594055,
              "predictive_entropy": 0.0443009389558604,
              "shannon_entropy": 0.1744522192666773
            }
          },
          {
            "text": "P\u00e9ter E\u00f6tv\u00f6s used to",
            "logprob": -0.5000407621221825,
            "tokens": [
              {
                "text": "P",
                "logprob": -0.09008648246526718
              },
              {
                "text": "\u00e9ter",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "E",
                "logprob": 0.0
              },
              {
                "text": "\u00f6t",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "v",
                "logprob": 0.0
              },
              {
                "text": "\u00f6s",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "used",
                "logprob": -0.4099491536617279
              },
              {
                "text": "to",
                "logprob": -8.344646857949556e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06250509060972576,
              "max_token_negative_log_likelihood": 0.4099491238594055,
              "predictive_entropy": 0.0443009389558604,
              "shannon_entropy": 0.1744522192666773
            }
          },
          {
            "text": "P\u00e9ter E\u00f6tv\u00f6s, who",
            "logprob": -5.010105036195171,
            "tokens": [
              {
                "text": "P",
                "logprob": -0.09008648246526718
              },
              {
                "text": "\u00e9ter",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "E",
                "logprob": 0.0
              },
              {
                "text": "\u00f6t",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "v",
                "logprob": 0.0
              },
              {
                "text": "\u00f6s",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": ",",
                "logprob": -1.4099491834640503
              },
              {
                "text": "who",
                "logprob": -3.5100650787353516
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6262630838905707,
              "max_token_negative_log_likelihood": 3.5100648403167725,
              "predictive_entropy": 0.06643880065476893,
              "shannon_entropy": 0.46783200897042665
            }
          },
          {
            "text": "P\u00e9ter E\u00f6tv\u00f6s, known",
            "logprob": -4.260105036195171,
            "tokens": [
              {
                "text": "P",
                "logprob": -0.09008648246526718
              },
              {
                "text": "\u00e9ter",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "E",
                "logprob": 0.0
              },
              {
                "text": "\u00f6t",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": "v",
                "logprob": 0.0
              },
              {
                "text": "\u00f6s",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": ",",
                "logprob": -1.4099491834640503
              },
              {
                "text": "known",
                "logprob": -2.7600650787353516
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5325131136928931,
              "max_token_negative_log_likelihood": 2.7600650787353516,
              "predictive_entropy": 0.07515689264929293,
              "shannon_entropy": 0.46783200897042665
            }
          }
        ],
        "cached": false,
        "request_time": 1.0111453533172607,
        "request_datetime": 1755803171
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "James Randolph Hubbell used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id667"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJames Randolph Hubbell used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "James Randolph Hubbell used to work",
            "logprob": -0.09248992382480736,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.03861802816390991
              },
              {
                "text": "Rand",
                "logprob": -8.940656698541716e-06
              },
              {
                "text": "olph",
                "logprob": 0.0
              },
              {
                "text": "Hub",
                "logprob": 0.0
              },
              {
                "text": "bell",
                "logprob": -4.410734163684538e-06
              },
              {
                "text": "used",
                "logprob": -0.05376747250556946
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01156123733363934,
              "max_token_negative_log_likelihood": 0.05376744642853737,
              "predictive_entropy": 0.011026546767539003,
              "shannon_entropy": 0.06648103309473619
            }
          },
          {
            "text": "James Randolph Hubbell used to work",
            "logprob": -0.09248992382480736,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.03861802816390991
              },
              {
                "text": "Rand",
                "logprob": -8.940656698541716e-06
              },
              {
                "text": "olph",
                "logprob": 0.0
              },
              {
                "text": "Hub",
                "logprob": 0.0
              },
              {
                "text": "bell",
                "logprob": -4.410734163684538e-06
              },
              {
                "text": "used",
                "logprob": -0.05376747250556946
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01156123733363934,
              "max_token_negative_log_likelihood": 0.05376744642853737,
              "predictive_entropy": 0.011026546767539003,
              "shannon_entropy": 0.06648103309473619
            }
          },
          {
            "text": "James Randolph Hubbell used to work",
            "logprob": -0.09248992382480736,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.03861802816390991
              },
              {
                "text": "Rand",
                "logprob": -8.940656698541716e-06
              },
              {
                "text": "olph",
                "logprob": 0.0
              },
              {
                "text": "Hub",
                "logprob": 0.0
              },
              {
                "text": "bell",
                "logprob": -4.410734163684538e-06
              },
              {
                "text": "used",
                "logprob": -0.05376747250556946
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01156123733363934,
              "max_token_negative_log_likelihood": 0.05376744642853737,
              "predictive_entropy": 0.011026546767539003,
              "shannon_entropy": 0.06648103309473619
            }
          },
          {
            "text": "James Randolph Hubbell used to work",
            "logprob": -0.09248992382480736,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.03861802816390991
              },
              {
                "text": "Rand",
                "logprob": -8.940656698541716e-06
              },
              {
                "text": "olph",
                "logprob": 0.0
              },
              {
                "text": "Hub",
                "logprob": 0.0
              },
              {
                "text": "bell",
                "logprob": -4.410734163684538e-06
              },
              {
                "text": "used",
                "logprob": -0.05376747250556946
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01156123733363934,
              "max_token_negative_log_likelihood": 0.05376744642853737,
              "predictive_entropy": 0.011026546767539003,
              "shannon_entropy": 0.06648103309473619
            }
          },
          {
            "text": "James Randolph Hubbell used to work",
            "logprob": -0.09248992382480736,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.03861802816390991
              },
              {
                "text": "Rand",
                "logprob": -8.940656698541716e-06
              },
              {
                "text": "olph",
                "logprob": 0.0
              },
              {
                "text": "Hub",
                "logprob": 0.0
              },
              {
                "text": "bell",
                "logprob": -4.410734163684538e-06
              },
              {
                "text": "used",
                "logprob": -0.05376747250556946
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01156123733363934,
              "max_token_negative_log_likelihood": 0.05376744642853737,
              "predictive_entropy": 0.011026546767539003,
              "shannon_entropy": 0.06648103309473619
            }
          }
        ],
        "cached": false,
        "request_time": 1.0065114498138428,
        "request_datetime": 1755803171
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Gilbert Romme used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Love"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paree"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lutetia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paris, France"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisians"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id817"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nGilbert Romme used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Gilbert Romme used to work in Br",
            "logprob": -0.21086612991348375,
            "tokens": [
              {
                "text": "Gilbert",
                "logprob": -0.01532082911580801
              },
              {
                "text": "Rom",
                "logprob": 0.0
              },
              {
                "text": "me",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.11593947559595108
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00047291061491705477
              },
              {
                "text": "in",
                "logprob": -0.0002112165529979393
              },
              {
                "text": "Br",
                "logprob": -0.07892169803380966
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02635827031735971,
              "max_token_negative_log_likelihood": 0.11593950539827347,
              "predictive_entropy": 0.023993969549337635,
              "shannon_entropy": 0.12466276601677961
            }
          },
          {
            "text": "Gilbert Romme, based on the historical",
            "logprob": -7.7035985484253615,
            "tokens": [
              {
                "text": "Gilbert",
                "logprob": -0.01532082911580801
              },
              {
                "text": "Rom",
                "logprob": 0.0
              },
              {
                "text": "me",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -2.4909393787384033
              },
              {
                "text": "based",
                "logprob": -2.4453251361846924
              },
              {
                "text": "on",
                "logprob": -0.001998809864744544
              },
              {
                "text": "the",
                "logprob": -0.08261117339134216
              },
              {
                "text": "historical",
                "logprob": -2.667403221130371
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.9629498200374655,
              "max_token_negative_log_likelihood": 2.667403221130371,
              "predictive_entropy": 0.08708523481618613,
              "shannon_entropy": 0.658465658749062
            }
          },
          {
            "text": "Gilbert Romme used to work in Br",
            "logprob": -0.21086612991348375,
            "tokens": [
              {
                "text": "Gilbert",
                "logprob": -0.01532082911580801
              },
              {
                "text": "Rom",
                "logprob": 0.0
              },
              {
                "text": "me",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.11593947559595108
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00047291061491705477
              },
              {
                "text": "in",
                "logprob": -0.0002112165529979393
              },
              {
                "text": "Br",
                "logprob": -0.07892169803380966
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02635827031735971,
              "max_token_negative_log_likelihood": 0.11593950539827347,
              "predictive_entropy": 0.023993969549337635,
              "shannon_entropy": 0.12466276601677961
            }
          },
          {
            "text": "Gilbert Romme, originally from Belgium",
            "logprob": -7.77206712122279,
            "tokens": [
              {
                "text": "Gilbert",
                "logprob": -0.01532082911580801
              },
              {
                "text": "Rom",
                "logprob": 0.0
              },
              {
                "text": "me",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -2.4909393787384033
              },
              {
                "text": "originally",
                "logprob": -4.101574897766113
              },
              {
                "text": "from",
                "logprob": -0.5276409387588501
              },
              {
                "text": "Belg",
                "logprob": -0.6365872621536255
              },
              {
                "text": "ium",
                "logprob": -3.814689989667386e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.9715083318305915,
              "max_token_negative_log_likelihood": 4.101574420928955,
              "predictive_entropy": 0.11717615893485345,
              "shannon_entropy": 0.6955918607393663
            }
          },
          {
            "text": "Gilbert Romme used to work in Gene",
            "logprob": -4.9921162267710315,
            "tokens": [
              {
                "text": "Gilbert",
                "logprob": -0.01532082911580801
              },
              {
                "text": "Rom",
                "logprob": 0.0
              },
              {
                "text": "me",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.11593947559595108
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00047291061491705477
              },
              {
                "text": "in",
                "logprob": -0.0002112165529979393
              },
              {
                "text": "Gene",
                "logprob": -4.860171794891357
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6240143508166511,
              "max_token_negative_log_likelihood": 4.860170364379883,
              "predictive_entropy": 0.019585179750720272,
              "shannon_entropy": 0.12466276601677961
            }
          }
        ],
        "cached": false,
        "request_time": 1.0088577270507812,
        "request_datetime": 1755803171
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Erich Wagler used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Leipzig"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id503"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nErich Wagler used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Erich Wagler, based on",
            "logprob": -3.1332910555515667,
            "tokens": [
              {
                "text": "Er",
                "logprob": -0.020460030063986778
              },
              {
                "text": "ich",
                "logprob": -5.125986263010418e-06
              },
              {
                "text": "W",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ag",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ler",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -1.9637683629989624
              },
              {
                "text": "based",
                "logprob": -1.1476126909255981
              },
              {
                "text": "on",
                "logprob": -0.001444607158191502
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.39166138506135795,
              "max_token_negative_log_likelihood": 1.9637683629989624,
              "predictive_entropy": 0.08266391567138953,
              "shannon_entropy": 0.38696095975756406
            }
          },
          {
            "text": "Erich Wagler used to work",
            "logprob": -0.23514000866360618,
            "tokens": [
              {
                "text": "Er",
                "logprob": -0.020460030063986778
              },
              {
                "text": "ich",
                "logprob": -5.125986263010418e-06
              },
              {
                "text": "W",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ag",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ler",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.21376831829547882
              },
              {
                "text": "to",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "work",
                "logprob": -0.0009053422254510224
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.029392500395150734,
              "max_token_negative_log_likelihood": 0.21376830339431763,
              "predictive_entropy": 0.024197750279313368,
              "shannon_entropy": 0.10683171709461248
            }
          },
          {
            "text": "Erich Wagler used to work",
            "logprob": -0.23514000866360618,
            "tokens": [
              {
                "text": "Er",
                "logprob": -0.020460030063986778
              },
              {
                "text": "ich",
                "logprob": -5.125986263010418e-06
              },
              {
                "text": "W",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ag",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ler",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.21376831829547882
              },
              {
                "text": "to",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "work",
                "logprob": -0.0009053422254510224
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.029392500395150734,
              "max_token_negative_log_likelihood": 0.21376830339431763,
              "predictive_entropy": 0.024197750279313368,
              "shannon_entropy": 0.10683171709461248
            }
          },
          {
            "text": "Erich Wagler used to work",
            "logprob": -0.23514000866360618,
            "tokens": [
              {
                "text": "Er",
                "logprob": -0.020460030063986778
              },
              {
                "text": "ich",
                "logprob": -5.125986263010418e-06
              },
              {
                "text": "W",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ag",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ler",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.21376831829547882
              },
              {
                "text": "to",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "work",
                "logprob": -0.0009053422254510224
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.029392500395150734,
              "max_token_negative_log_likelihood": 0.21376830339431763,
              "predictive_entropy": 0.024197750279313368,
              "shannon_entropy": 0.10683171709461248
            }
          },
          {
            "text": "Erich Wagler used to work",
            "logprob": -0.23514000866360618,
            "tokens": [
              {
                "text": "Er",
                "logprob": -0.020460030063986778
              },
              {
                "text": "ich",
                "logprob": -5.125986263010418e-06
              },
              {
                "text": "W",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ag",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ler",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.21376831829547882
              },
              {
                "text": "to",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "work",
                "logprob": -0.0009053422254510224
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.029392500395150734,
              "max_token_negative_log_likelihood": 0.21376830339431763,
              "predictive_entropy": 0.024197750279313368,
              "shannon_entropy": 0.10683171709461248
            }
          }
        ],
        "cached": false,
        "request_time": 1.0059010982513428,
        "request_datetime": 1755803172
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Denis Healey used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id756"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nDenis Healey used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Denis Healey used to work",
            "logprob": -0.1477922148769366,
            "tokens": [
              {
                "text": "Den",
                "logprob": -0.038066316395998
              },
              {
                "text": "is",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "He",
                "logprob": 0.0
              },
              {
                "text": "ale",
                "logprob": -0.0022555168252438307
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10697352141141891
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00049650261644274
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01847403328429742,
              "max_token_negative_log_likelihood": 0.1069735512137413,
              "predictive_entropy": 0.016939074783291375,
              "shannon_entropy": 0.07797819031985793
            }
          },
          {
            "text": "Denis Healey used to work",
            "logprob": -0.1477922148769366,
            "tokens": [
              {
                "text": "Den",
                "logprob": -0.038066316395998
              },
              {
                "text": "is",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "He",
                "logprob": 0.0
              },
              {
                "text": "ale",
                "logprob": -0.0022555168252438307
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10697352141141891
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00049650261644274
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01847403328429742,
              "max_token_negative_log_likelihood": 0.1069735512137413,
              "predictive_entropy": 0.016939074783291375,
              "shannon_entropy": 0.07797819031985793
            }
          },
          {
            "text": "Denis Healey used to work",
            "logprob": -0.1477922148769366,
            "tokens": [
              {
                "text": "Den",
                "logprob": -0.038066316395998
              },
              {
                "text": "is",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "He",
                "logprob": 0.0
              },
              {
                "text": "ale",
                "logprob": -0.0022555168252438307
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10697352141141891
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00049650261644274
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01847403328429742,
              "max_token_negative_log_likelihood": 0.1069735512137413,
              "predictive_entropy": 0.016939074783291375,
              "shannon_entropy": 0.07797819031985793
            }
          },
          {
            "text": "Denis Healey used to work",
            "logprob": -0.1477922148769366,
            "tokens": [
              {
                "text": "Den",
                "logprob": -0.038066316395998
              },
              {
                "text": "is",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "He",
                "logprob": 0.0
              },
              {
                "text": "ale",
                "logprob": -0.0022555168252438307
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10697352141141891
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00049650261644274
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01847403328429742,
              "max_token_negative_log_likelihood": 0.1069735512137413,
              "predictive_entropy": 0.016939074783291375,
              "shannon_entropy": 0.07797819031985793
            }
          },
          {
            "text": "Denis Healey used to work",
            "logprob": -0.1477922148769366,
            "tokens": [
              {
                "text": "Den",
                "logprob": -0.038066316395998
              },
              {
                "text": "is",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "He",
                "logprob": 0.0
              },
              {
                "text": "ale",
                "logprob": -0.0022555168252438307
              },
              {
                "text": "y",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10697352141141891
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00049650261644274
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01847403328429742,
              "max_token_negative_log_likelihood": 0.1069735512137413,
              "predictive_entropy": 0.016939074783291375,
              "shannon_entropy": 0.07797819031985793
            }
          }
        ],
        "cached": false,
        "request_time": 1.0077495574951172,
        "request_datetime": 1755803172
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Detlef M\u00fcller used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Berlin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berlin, Germany"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berlin (Germany)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DE-BE"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berliner"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berliners"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id966"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nDetlef M\u00fcller used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Detlef M\u00fcller used to work in Berlin",
            "logprob": -0.44232064530297066,
            "tokens": [
              {
                "text": "Det",
                "logprob": -0.055932097136974335
              },
              {
                "text": "lef",
                "logprob": -9.023735765367746e-05
              },
              {
                "text": "M\u00fcller",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.07331325113773346
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.508615479106084e-05
              },
              {
                "text": "in",
                "logprob": -4.029192859889008e-05
              },
              {
                "text": "Berlin",
                "logprob": -0.31287968158721924
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.055290080551003484,
              "max_token_negative_log_likelihood": 0.31287968158721924,
              "predictive_entropy": 0.04375458281583633,
              "shannon_entropy": 0.22813952225660472
            }
          },
          {
            "text": "Detlef M\u00fcller used to work in Berlin",
            "logprob": -0.44232064530297066,
            "tokens": [
              {
                "text": "Det",
                "logprob": -0.055932097136974335
              },
              {
                "text": "lef",
                "logprob": -9.023735765367746e-05
              },
              {
                "text": "M\u00fcller",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.07331325113773346
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.508615479106084e-05
              },
              {
                "text": "in",
                "logprob": -4.029192859889008e-05
              },
              {
                "text": "Berlin",
                "logprob": -0.31287968158721924
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.055290080551003484,
              "max_token_negative_log_likelihood": 0.31287968158721924,
              "predictive_entropy": 0.04375458281583633,
              "shannon_entropy": 0.22813952225660472
            }
          },
          {
            "text": "Detlef M\u00fcller used to work in Berlin",
            "logprob": -0.44232064530297066,
            "tokens": [
              {
                "text": "Det",
                "logprob": -0.055932097136974335
              },
              {
                "text": "lef",
                "logprob": -9.023735765367746e-05
              },
              {
                "text": "M\u00fcller",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.07331325113773346
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.508615479106084e-05
              },
              {
                "text": "in",
                "logprob": -4.029192859889008e-05
              },
              {
                "text": "Berlin",
                "logprob": -0.31287968158721924
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.055290080551003484,
              "max_token_negative_log_likelihood": 0.31287968158721924,
              "predictive_entropy": 0.04375458281583633,
              "shannon_entropy": 0.22813952225660472
            }
          },
          {
            "text": "Detlef M\u00fcller used to work in Mun",
            "logprob": -3.848570526093681,
            "tokens": [
              {
                "text": "Det",
                "logprob": -0.055932097136974335
              },
              {
                "text": "lef",
                "logprob": -9.023735765367746e-05
              },
              {
                "text": "M\u00fcller",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.07331325113773346
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.508615479106084e-05
              },
              {
                "text": "in",
                "logprob": -4.029192859889008e-05
              },
              {
                "text": "Mun",
                "logprob": -3.7191295623779297
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4810712858475199,
              "max_token_negative_log_likelihood": 3.7191293239593506,
              "predictive_entropy": 0.026427954026530642,
              "shannon_entropy": 0.22813952225660472
            }
          },
          {
            "text": "Detlef M\u00fcller used to work in C",
            "logprob": -4.036070526093681,
            "tokens": [
              {
                "text": "Det",
                "logprob": -0.055932097136974335
              },
              {
                "text": "lef",
                "logprob": -9.023735765367746e-05
              },
              {
                "text": "M\u00fcller",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.07331325113773346
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.508615479106084e-05
              },
              {
                "text": "in",
                "logprob": -4.029192859889008e-05
              },
              {
                "text": "C",
                "logprob": -3.9066295623779297
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5045087858475199,
              "max_token_negative_log_likelihood": 3.9066293239593506,
              "predictive_entropy": 0.02497137669570293,
              "shannon_entropy": 0.22813952225660472
            }
          }
        ],
        "cached": false,
        "request_time": 1.0083048343658447,
        "request_datetime": 1755803172
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Paul J. Krebs used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id462"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nPaul J. Krebs used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Paul J. Krebs used to work",
            "logprob": -0.47902988175308536,
            "tokens": [
              {
                "text": "Paul",
                "logprob": -0.4105771481990814
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": 0.0
              },
              {
                "text": "Kre",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "bs",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.06825367361307144
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "work",
                "logprob": -0.00019786784832831472
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.05987873731832316,
              "max_token_negative_log_likelihood": 0.4105771780014038,
              "predictive_entropy": 0.04203399491776594,
              "shannon_entropy": 0.210069950873069
            }
          },
          {
            "text": "Paul J. Krebs used to work",
            "logprob": -0.47902988175308536,
            "tokens": [
              {
                "text": "Paul",
                "logprob": -0.4105771481990814
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": 0.0
              },
              {
                "text": "Kre",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "bs",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.06825367361307144
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "work",
                "logprob": -0.00019786784832831472
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.05987873731832316,
              "max_token_negative_log_likelihood": 0.4105771780014038,
              "predictive_entropy": 0.04203399491776594,
              "shannon_entropy": 0.210069950873069
            }
          },
          {
            "text": "Paul J. Krebs used to work",
            "logprob": -0.47902988175308536,
            "tokens": [
              {
                "text": "Paul",
                "logprob": -0.4105771481990814
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": 0.0
              },
              {
                "text": "Kre",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "bs",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.06825367361307144
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "work",
                "logprob": -0.00019786784832831472
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.05987873731832316,
              "max_token_negative_log_likelihood": 0.4105771780014038,
              "predictive_entropy": 0.04203399491776594,
              "shannon_entropy": 0.210069950873069
            }
          },
          {
            "text": "Based on the given pattern and structure,",
            "logprob": -12.637746631895425,
            "tokens": [
              {
                "text": "Based",
                "logprob": -2.1293270587921143
              },
              {
                "text": "on",
                "logprob": -0.0003293210465926677
              },
              {
                "text": "the",
                "logprob": -0.015426481142640114
              },
              {
                "text": "given",
                "logprob": -2.768707275390625
              },
              {
                "text": "pattern",
                "logprob": -0.7968363761901855
              },
              {
                "text": "and",
                "logprob": -3.8919155597686768
              },
              {
                "text": "structure",
                "logprob": -2.737293243408203
              },
              {
                "text": ",",
                "logprob": -0.29791131615638733
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.5797182468486426,
              "max_token_negative_log_likelihood": 3.8919150829315186,
              "predictive_entropy": 0.15992907502004527,
              "shannon_entropy": 1.0315845644799992
            }
          },
          {
            "text": "To complete the sentence about Paul J.",
            "logprob": -4.688829659484298,
            "tokens": [
              {
                "text": "To",
                "logprob": -3.2855770587921143
              },
              {
                "text": "complete",
                "logprob": -0.07484906911849976
              },
              {
                "text": "the",
                "logprob": -0.025488590821623802
              },
              {
                "text": "sentence",
                "logprob": -0.5607463121414185
              },
              {
                "text": "about",
                "logprob": -0.7379482388496399
              },
              {
                "text": "Paul",
                "logprob": -0.004220151342451572
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5861036796122825,
              "max_token_negative_log_likelihood": 3.285576820373535,
              "predictive_entropy": 0.11178960691904294,
              "shannon_entropy": 0.6041981385915518
            }
          }
        ],
        "cached": false,
        "request_time": 1.0088245868682861,
        "request_datetime": 1755803172
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Laurent Cars used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Love"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paree"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lutetia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paris, France"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisians"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id489"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nLaurent Cars used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Laurent Cars used to work in Lyon",
            "logprob": -0.9901051690976317,
            "tokens": [
              {
                "text": "Laurent",
                "logprob": -0.24295364320278168
              },
              {
                "text": "C",
                "logprob": -0.00041738382424227893
              },
              {
                "text": "ars",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08035190403461456
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00015948931104503572
              },
              {
                "text": "in",
                "logprob": -6.949660019017756e-05
              },
              {
                "text": "Lyon",
                "logprob": -0.6661530137062073
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.12376314002904465,
              "max_token_negative_log_likelihood": 0.6661529541015625,
              "predictive_entropy": 0.07594187770154903,
              "shannon_entropy": 0.3786255287030569
            }
          },
          {
            "text": "Laurent Cars used to work in Br",
            "logprob": -1.521355109492987,
            "tokens": [
              {
                "text": "Laurent",
                "logprob": -0.24295364320278168
              },
              {
                "text": "C",
                "logprob": -0.00041738382424227893
              },
              {
                "text": "ars",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08035190403461456
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00015948931104503572
              },
              {
                "text": "in",
                "logprob": -6.949660019017756e-05
              },
              {
                "text": "Br",
                "logprob": -1.1974029541015625
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.19016939002904465,
              "max_token_negative_log_likelihood": 1.1974029541015625,
              "predictive_entropy": 0.07836669895914028,
              "shannon_entropy": 0.3786255287030569
            }
          },
          {
            "text": "Laurent Cars used to work in Lyon",
            "logprob": -0.9901051690976317,
            "tokens": [
              {
                "text": "Laurent",
                "logprob": -0.24295364320278168
              },
              {
                "text": "C",
                "logprob": -0.00041738382424227893
              },
              {
                "text": "ars",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08035190403461456
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00015948931104503572
              },
              {
                "text": "in",
                "logprob": -6.949660019017756e-05
              },
              {
                "text": "Lyon",
                "logprob": -0.6661530137062073
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.12376314002904465,
              "max_token_negative_log_likelihood": 0.6661529541015625,
              "predictive_entropy": 0.07594187770154903,
              "shannon_entropy": 0.3786255287030569
            }
          },
          {
            "text": "Laurent Cars used to work in one",
            "logprob": -8.333855109492987,
            "tokens": [
              {
                "text": "Laurent",
                "logprob": -0.24295364320278168
              },
              {
                "text": "C",
                "logprob": -0.00041738382424227893
              },
              {
                "text": "ars",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08035190403461456
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00015948931104503572
              },
              {
                "text": "in",
                "logprob": -6.949660019017756e-05
              },
              {
                "text": "one",
                "logprob": -8.009902954101562
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.041728075331779,
              "max_token_negative_log_likelihood": 8.009872436523438,
              "predictive_entropy": 0.03350068366853165,
              "shannon_entropy": 0.3786255287030569
            }
          },
          {
            "text": "Laurent Cars used to work in the",
            "logprob": -5.083855109492987,
            "tokens": [
              {
                "text": "Laurent",
                "logprob": -0.24295364320278168
              },
              {
                "text": "C",
                "logprob": -0.00041738382424227893
              },
              {
                "text": "ars",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08035190403461456
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.00015948931104503572
              },
              {
                "text": "in",
                "logprob": -6.949660019017756e-05
              },
              {
                "text": "the",
                "logprob": -4.7599029541015625
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6354817708197551,
              "max_token_negative_log_likelihood": 4.759902000427246,
              "predictive_entropy": 0.038265043665884235,
              "shannon_entropy": 0.3786255287030569
            }
          }
        ],
        "cached": false,
        "request_time": 1.0059707164764404,
        "request_datetime": 1755803173
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Heinrich H\u00e4berlin used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Bern"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berne"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "city of Bern"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berna"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id930"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nHeinrich H\u00e4berlin used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Heinrich H\u00e4berlin used to work in",
            "logprob": -0.17346795460150588,
            "tokens": [
              {
                "text": "Heinrich",
                "logprob": -0.04393744468688965
              },
              {
                "text": "H\u00e4",
                "logprob": -0.00016485285595990717
              },
              {
                "text": "ber",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "lin",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.12917910516262054
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.0001380348257953301
              },
              {
                "text": "in",
                "logprob": -4.708655978902243e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.021683497123959228,
              "max_token_negative_log_likelihood": 0.12917910516262054,
              "predictive_entropy": 0.019490607313727537,
              "shannon_entropy": 0.08805376276092503
            }
          },
          {
            "text": "Heinrich H\u00e4berlin used to work in",
            "logprob": -0.17346795460150588,
            "tokens": [
              {
                "text": "Heinrich",
                "logprob": -0.04393744468688965
              },
              {
                "text": "H\u00e4",
                "logprob": -0.00016485285595990717
              },
              {
                "text": "ber",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "lin",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.12917910516262054
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.0001380348257953301
              },
              {
                "text": "in",
                "logprob": -4.708655978902243e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.021683497123959228,
              "max_token_negative_log_likelihood": 0.12917910516262054,
              "predictive_entropy": 0.019490607313727537,
              "shannon_entropy": 0.08805376276092503
            }
          },
          {
            "text": "Heinrich H\u00e4berlin used to work in",
            "logprob": -0.17346795460150588,
            "tokens": [
              {
                "text": "Heinrich",
                "logprob": -0.04393744468688965
              },
              {
                "text": "H\u00e4",
                "logprob": -0.00016485285595990717
              },
              {
                "text": "ber",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "lin",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.12917910516262054
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.0001380348257953301
              },
              {
                "text": "in",
                "logprob": -4.708655978902243e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.021683497123959228,
              "max_token_negative_log_likelihood": 0.12917910516262054,
              "predictive_entropy": 0.019490607313727537,
              "shannon_entropy": 0.08805376276092503
            }
          },
          {
            "text": "Heinrich H\u00e4berlin used to work in",
            "logprob": -0.17346795460150588,
            "tokens": [
              {
                "text": "Heinrich",
                "logprob": -0.04393744468688965
              },
              {
                "text": "H\u00e4",
                "logprob": -0.00016485285595990717
              },
              {
                "text": "ber",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "lin",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.12917910516262054
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.0001380348257953301
              },
              {
                "text": "in",
                "logprob": -4.708655978902243e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.021683497123959228,
              "max_token_negative_log_likelihood": 0.12917910516262054,
              "predictive_entropy": 0.019490607313727537,
              "shannon_entropy": 0.08805376276092503
            }
          },
          {
            "text": "Henry St. John, known as the",
            "logprob": -7.168602526187719,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -3.4501874446868896
              },
              {
                "text": "St",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": ".",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "John",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.13374316692352295
              },
              {
                "text": "known",
                "logprob": -2.100830316543579
              },
              {
                "text": "as",
                "logprob": -0.8033687472343445
              },
              {
                "text": "the",
                "logprob": -0.6804721355438232
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8960752449929945,
              "max_token_negative_log_likelihood": 3.4501869678497314,
              "predictive_entropy": 0.14848681725559487,
              "shannon_entropy": 0.676282817037059
            }
          }
        ],
        "cached": false,
        "request_time": 1.0082027912139893,
        "request_datetime": 1755803173
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Stefano Jacini used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Milan"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Milano"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Milan, Italy"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Milano, Italy"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Milano, Italia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mailand"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Milan Records"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Milanese"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id553"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nStefano Jacini used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Stefano Jacini used to work in",
            "logprob": -0.10911797730858552,
            "tokens": [
              {
                "text": "Stef",
                "logprob": -0.026499563828110695
              },
              {
                "text": "ano",
                "logprob": 0.0
              },
              {
                "text": "Jac",
                "logprob": -3.2186455882765586e-06
              },
              {
                "text": "ini",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08235760033130646
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.00011336160969221964
              },
              {
                "text": "in",
                "logprob": -0.0001438752660760656
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.013639756014278248,
              "max_token_negative_log_likelihood": 0.08235763013362885,
              "predictive_entropy": 0.01273925276042931,
              "shannon_entropy": 0.07128303336145558
            }
          },
          {
            "text": "Stefano Jacini used to work in",
            "logprob": -0.10911797730858552,
            "tokens": [
              {
                "text": "Stef",
                "logprob": -0.026499563828110695
              },
              {
                "text": "ano",
                "logprob": 0.0
              },
              {
                "text": "Jac",
                "logprob": -3.2186455882765586e-06
              },
              {
                "text": "ini",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08235760033130646
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.00011336160969221964
              },
              {
                "text": "in",
                "logprob": -0.0001438752660760656
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.013639756014278248,
              "max_token_negative_log_likelihood": 0.08235763013362885,
              "predictive_entropy": 0.01273925276042931,
              "shannon_entropy": 0.07128303336145558
            }
          },
          {
            "text": "Stefano Jacini used to work in",
            "logprob": -0.10911797730858552,
            "tokens": [
              {
                "text": "Stef",
                "logprob": -0.026499563828110695
              },
              {
                "text": "ano",
                "logprob": 0.0
              },
              {
                "text": "Jac",
                "logprob": -3.2186455882765586e-06
              },
              {
                "text": "ini",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08235760033130646
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.00011336160969221964
              },
              {
                "text": "in",
                "logprob": -0.0001438752660760656
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.013639756014278248,
              "max_token_negative_log_likelihood": 0.08235763013362885,
              "predictive_entropy": 0.01273925276042931,
              "shannon_entropy": 0.07128303336145558
            }
          },
          {
            "text": "Stefano Jacini used to work in",
            "logprob": -0.10911797730858552,
            "tokens": [
              {
                "text": "Stef",
                "logprob": -0.026499563828110695
              },
              {
                "text": "ano",
                "logprob": 0.0
              },
              {
                "text": "Jac",
                "logprob": -3.2186455882765586e-06
              },
              {
                "text": "ini",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08235760033130646
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.00011336160969221964
              },
              {
                "text": "in",
                "logprob": -0.0001438752660760656
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.013639756014278248,
              "max_token_negative_log_likelihood": 0.08235763013362885,
              "predictive_entropy": 0.01273925276042931,
              "shannon_entropy": 0.07128303336145558
            }
          },
          {
            "text": "Stefano Jacini used to work in",
            "logprob": -0.10911797730858552,
            "tokens": [
              {
                "text": "Stef",
                "logprob": -0.026499563828110695
              },
              {
                "text": "ano",
                "logprob": 0.0
              },
              {
                "text": "Jac",
                "logprob": -3.2186455882765586e-06
              },
              {
                "text": "ini",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08235760033130646
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.00011336160969221964
              },
              {
                "text": "in",
                "logprob": -0.0001438752660760656
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.013639756014278248,
              "max_token_negative_log_likelihood": 0.08235763013362885,
              "predictive_entropy": 0.01273925276042931,
              "shannon_entropy": 0.07128303336145558
            }
          }
        ],
        "cached": false,
        "request_time": 1.008707046508789,
        "request_datetime": 1755803173
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Jaak Allik used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Tallinn"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Reval"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Revel"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Rewel"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Kolywan"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lyndanisse"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lindan\u00e4s"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Reuel"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Tallinn, Estonia"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id776"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJaak Allik used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "It seems the information about Jaak Al",
            "logprob": -4.689595919100128,
            "tokens": [
              {
                "text": "It",
                "logprob": -1.297287940979004
              },
              {
                "text": "seems",
                "logprob": -0.6265175342559814
              },
              {
                "text": "the",
                "logprob": -1.5818934440612793
              },
              {
                "text": "information",
                "logprob": -0.6316052675247192
              },
              {
                "text": "about",
                "logprob": -0.529662549495697
              },
              {
                "text": "Ja",
                "logprob": -0.02262679859995842
              },
              {
                "text": "ak",
                "logprob": -2.145764938177308e-06
              },
              {
                "text": "Al",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.586199458921616,
              "max_token_negative_log_likelihood": 1.5818933248519897,
              "predictive_entropy": 0.2105508970559491,
              "shannon_entropy": 0.8273132091428863
            }
          },
          {
            "text": "Jaak Allik used to work in",
            "logprob": -0.6797534917131358,
            "tokens": [
              {
                "text": "Ja",
                "logprob": -0.6097878813743591
              },
              {
                "text": "ak",
                "logprob": 0.0
              },
              {
                "text": "Al",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "lik",
                "logprob": -0.004063326865434647
              },
              {
                "text": "used",
                "logprob": -0.06544028222560883
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.0002044230350293219
              },
              {
                "text": "in",
                "logprob": -0.0002571013756096363
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0849691841213005,
              "max_token_negative_log_likelihood": 0.6097878813743591,
              "predictive_entropy": 0.0496503466401812,
              "shannon_entropy": 0.22554153499111607
            }
          },
          {
            "text": "Assuming the blank needs to be completed with",
            "logprob": -15.707332026213408,
            "tokens": [
              {
                "text": "Assuming",
                "logprob": -5.797287940979004
              },
              {
                "text": "the",
                "logprob": -0.7372825145721436
              },
              {
                "text": "blank",
                "logprob": -4.679632663726807
              },
              {
                "text": "needs",
                "logprob": -2.5270836353302
              },
              {
                "text": "to",
                "logprob": -0.2601396143436432
              },
              {
                "text": "be",
                "logprob": -0.060228150337934494
              },
              {
                "text": "completed",
                "logprob": -1.361645221710205
              },
              {
                "text": "with",
                "logprob": -0.28403228521347046
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.9634159561246634,
              "max_token_negative_log_likelihood": 5.7972846031188965,
              "predictive_entropy": 0.17945323628373444,
              "shannon_entropy": 1.1175424680113792
            }
          },
          {
            "text": "It seems that the information about Jaak",
            "logprob": -4.365311220285548,
            "tokens": [
              {
                "text": "It",
                "logprob": -1.297287940979004
              },
              {
                "text": "seems",
                "logprob": -0.6265175342559814
              },
              {
                "text": "that",
                "logprob": -1.0193934440612793
              },
              {
                "text": "the",
                "logprob": -0.16904371976852417
              },
              {
                "text": "information",
                "logprob": -0.6754246950149536
              },
              {
                "text": "about",
                "logprob": -0.5589826703071594
              },
              {
                "text": "Ja",
                "logprob": -0.0186588317155838
              },
              {
                "text": "ak",
                "logprob": -2.3841830625315197e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5456638722684204,
              "max_token_negative_log_likelihood": 1.2972878217697144,
              "predictive_entropy": 0.23520080046694147,
              "shannon_entropy": 0.9174698708916367
            }
          },
          {
            "text": "It appears the information regarding Jaak Al",
            "logprob": -7.635321937499377,
            "tokens": [
              {
                "text": "It",
                "logprob": -1.297287940979004
              },
              {
                "text": "appears",
                "logprob": -0.8140175342559814
              },
              {
                "text": "the",
                "logprob": -2.322946071624756
              },
              {
                "text": "information",
                "logprob": -1.011634349822998
              },
              {
                "text": "regarding",
                "logprob": -2.113635778427124
              },
              {
                "text": "Ja",
                "logprob": -0.07579811662435532
              },
              {
                "text": "ak",
                "logprob": -2.0265558760002023e-06
              },
              {
                "text": "Al",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.9544151611628724,
              "max_token_negative_log_likelihood": 2.3229458332061768,
              "predictive_entropy": 0.2045300342140024,
              "shannon_entropy": 0.82334642053317
            }
          }
        ],
        "cached": false,
        "request_time": 1.0169904232025146,
        "request_datetime": 1755803173
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Arthur von Weissenberg used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Helsinki"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Helsingfors"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Helsingia"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id331"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nArthur von Weissenberg used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Henry St. John, the 1",
            "logprob": -9.25433896970906,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -4.750835418701172
              },
              {
                "text": "St",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": ".",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "John",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ",",
                "logprob": -0.16489289700984955
              },
              {
                "text": "the",
                "logprob": -4.0745086669921875
              },
              {
                "text": "",
                "logprob": -0.26222869753837585
              },
              {
                "text": "1",
                "logprob": -0.0018720973748713732
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1567920716916351,
              "max_token_negative_log_likelihood": 4.750833988189697,
              "predictive_entropy": 0.05672194118957208,
              "shannon_entropy": 0.7061941252290609
            }
          },
          {
            "text": "Arthur von Weissenberg used to work",
            "logprob": -0.43528527843675846,
            "tokens": [
              {
                "text": "Arthur",
                "logprob": -0.3758353888988495
              },
              {
                "text": "von",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "We",
                "logprob": 0.0
              },
              {
                "text": "issen",
                "logprob": -1.1801649634435307e-05
              },
              {
                "text": "berg",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.05882088840007782
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.000608854868914932
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.054410662863924486,
              "max_token_negative_log_likelihood": 0.3758353888988495,
              "predictive_entropy": 0.03927267027960468,
              "shannon_entropy": 0.1877247134206197
            }
          },
          {
            "text": "Arthur von Weissenberg used to work",
            "logprob": -0.43528527843675846,
            "tokens": [
              {
                "text": "Arthur",
                "logprob": -0.3758353888988495
              },
              {
                "text": "von",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "We",
                "logprob": 0.0
              },
              {
                "text": "issen",
                "logprob": -1.1801649634435307e-05
              },
              {
                "text": "berg",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.05882088840007782
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.000608854868914932
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.054410662863924486,
              "max_token_negative_log_likelihood": 0.3758353888988495,
              "predictive_entropy": 0.03927267027960468,
              "shannon_entropy": 0.1877247134206197
            }
          },
          {
            "text": "Arthur von Weissenberg used to work",
            "logprob": -0.43528527843675846,
            "tokens": [
              {
                "text": "Arthur",
                "logprob": -0.3758353888988495
              },
              {
                "text": "von",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "We",
                "logprob": 0.0
              },
              {
                "text": "issen",
                "logprob": -1.1801649634435307e-05
              },
              {
                "text": "berg",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.05882088840007782
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.000608854868914932
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.054410662863924486,
              "max_token_negative_log_likelihood": 0.3758353888988495,
              "predictive_entropy": 0.03927267027960468,
              "shannon_entropy": 0.1877247134206197
            }
          },
          {
            "text": "Arthur von Weissenberg, based on",
            "logprob": -5.997314614375675,
            "tokens": [
              {
                "text": "Arthur",
                "logprob": -0.3758353888988495
              },
              {
                "text": "von",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "We",
                "logprob": 0.0
              },
              {
                "text": "issen",
                "logprob": -1.1801649634435307e-05
              },
              {
                "text": "berg",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ",",
                "logprob": -3.121320962905884
              },
              {
                "text": "based",
                "logprob": -2.497934103012085
              },
              {
                "text": "on",
                "logprob": -0.002204370917752385
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.7496642636668884,
              "max_token_negative_log_likelihood": 3.1213204860687256,
              "predictive_entropy": 0.0754281136780719,
              "shannon_entropy": 0.5032124697967344
            }
          }
        ],
        "cached": false,
        "request_time": 1.008293867111206,
        "request_datetime": 1755803174
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "James Callan Graham used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Austin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Austin, Texas"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Austin, TX"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Austin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Austin"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id197"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJames Callan Graham used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "James Callan Graham used to work in",
            "logprob": -0.15653265544076334,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.03724087402224541
              },
              {
                "text": "Call",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "Graham",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.11894562840461731
              },
              {
                "text": "to",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "work",
                "logprob": -0.0002037079248111695
              },
              {
                "text": "in",
                "logprob": -0.00014149141497910023
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.019566581237112857,
              "max_token_negative_log_likelihood": 0.1189456358551979,
              "predictive_entropy": 0.017729022420073903,
              "shannon_entropy": 0.10031715241255057
            }
          },
          {
            "text": "James Callan Graham used to work in",
            "logprob": -0.15653265544076334,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.03724087402224541
              },
              {
                "text": "Call",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "Graham",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.11894562840461731
              },
              {
                "text": "to",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "work",
                "logprob": -0.0002037079248111695
              },
              {
                "text": "in",
                "logprob": -0.00014149141497910023
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.019566581237112857,
              "max_token_negative_log_likelihood": 0.1189456358551979,
              "predictive_entropy": 0.017729022420073903,
              "shannon_entropy": 0.10031715241255057
            }
          },
          {
            "text": "James Callan Graham used to work in",
            "logprob": -0.15653265544076334,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.03724087402224541
              },
              {
                "text": "Call",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "Graham",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.11894562840461731
              },
              {
                "text": "to",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "work",
                "logprob": -0.0002037079248111695
              },
              {
                "text": "in",
                "logprob": -0.00014149141497910023
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.019566581237112857,
              "max_token_negative_log_likelihood": 0.1189456358551979,
              "predictive_entropy": 0.017729022420073903,
              "shannon_entropy": 0.10031715241255057
            }
          },
          {
            "text": "James Callan Graham used to work in",
            "logprob": -0.15653265544076334,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.03724087402224541
              },
              {
                "text": "Call",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "Graham",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.11894562840461731
              },
              {
                "text": "to",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "work",
                "logprob": -0.0002037079248111695
              },
              {
                "text": "in",
                "logprob": -0.00014149141497910023
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.019566581237112857,
              "max_token_negative_log_likelihood": 0.1189456358551979,
              "predictive_entropy": 0.017729022420073903,
              "shannon_entropy": 0.10031715241255057
            }
          },
          {
            "text": "James Callan Graham used to work in",
            "logprob": -0.15653265544076334,
            "tokens": [
              {
                "text": "James",
                "logprob": -0.03724087402224541
              },
              {
                "text": "Call",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "Graham",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.11894562840461731
              },
              {
                "text": "to",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "work",
                "logprob": -0.0002037079248111695
              },
              {
                "text": "in",
                "logprob": -0.00014149141497910023
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.019566581237112857,
              "max_token_negative_log_likelihood": 0.1189456358551979,
              "predictive_entropy": 0.017729022420073903,
              "shannon_entropy": 0.10031715241255057
            }
          }
        ],
        "cached": false,
        "request_time": 1.0124359130859375,
        "request_datetime": 1755803174
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Steven W. Cappelli used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Harrisburg"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Capital of Pennsylvania"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Harrisburg, Pennsylvania"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id591"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nSteven W. Cappelli used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Steven W. Cappelli used to",
            "logprob": -0.8820903450245439,
            "tokens": [
              {
                "text": "Steven",
                "logprob": -0.807174801826477
              },
              {
                "text": "W",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "C",
                "logprob": 0.0
              },
              {
                "text": "app",
                "logprob": 0.0
              },
              {
                "text": "elli",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "used",
                "logprob": -0.07491399347782135
              },
              {
                "text": "to",
                "logprob": -5.960462772236497e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.11026129033423082,
              "max_token_negative_log_likelihood": 0.807174801826477,
              "predictive_entropy": 0.05370032601052088,
              "shannon_entropy": 0.2702151518900461
            }
          },
          {
            "text": "It seems like the sentence for Steven W",
            "logprob": -7.223198414780171,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.2134246826171875
              },
              {
                "text": "seems",
                "logprob": -0.5111470222473145
              },
              {
                "text": "like",
                "logprob": -0.99506676197052
              },
              {
                "text": "the",
                "logprob": -0.29368719458580017
              },
              {
                "text": "sentence",
                "logprob": -2.197634220123291
              },
              {
                "text": "for",
                "logprob": -1.0025650262832642
              },
              {
                "text": "Steven",
                "logprob": -0.009673268534243107
              },
              {
                "text": "W",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.9028998271096533,
              "max_token_negative_log_likelihood": 2.2134246826171875,
              "predictive_entropy": 0.21961693163029494,
              "shannon_entropy": 1.0428479267807234
            }
          },
          {
            "text": "It seems like the statement regarding Steven W",
            "logprob": -8.023939598351717,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.2134246826171875
              },
              {
                "text": "seems",
                "logprob": -0.5111470222473145
              },
              {
                "text": "like",
                "logprob": -0.99506676197052
              },
              {
                "text": "the",
                "logprob": -0.29368719458580017
              },
              {
                "text": "statement",
                "logprob": -2.322634220123291
              },
              {
                "text": "regarding",
                "logprob": -1.6795647144317627
              },
              {
                "text": "Steven",
                "logprob": -0.00841500237584114
              },
              {
                "text": "W",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0029924762202427,
              "max_token_negative_log_likelihood": 2.322634220123291,
              "predictive_entropy": 0.2105695349164307,
              "shannon_entropy": 1.014706913489654
            }
          },
          {
            "text": "Victor Leemans used to work in",
            "logprob": -2.994051815645861,
            "tokens": [
              {
                "text": "Victor",
                "logprob": -1.900924801826477
              },
              {
                "text": "Le",
                "logprob": -0.8260196447372437
              },
              {
                "text": "em",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ans",
                "logprob": -3.099436753473128e-06
              },
              {
                "text": "used",
                "logprob": -0.2632329761981964
              },
              {
                "text": "to",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "work",
                "logprob": -0.0007009433466009796
              },
              {
                "text": "in",
                "logprob": -0.0031693964265286922
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3742564640421726,
              "max_token_negative_log_likelihood": 1.9009246826171875,
              "predictive_entropy": 0.1064815766724756,
              "shannon_entropy": 0.43746993907817
            }
          },
          {
            "text": "Victor Leemans used to work in",
            "logprob": -2.994051815645861,
            "tokens": [
              {
                "text": "Victor",
                "logprob": -1.900924801826477
              },
              {
                "text": "Le",
                "logprob": -0.8260196447372437
              },
              {
                "text": "em",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ans",
                "logprob": -3.099436753473128e-06
              },
              {
                "text": "used",
                "logprob": -0.2632329761981964
              },
              {
                "text": "to",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "work",
                "logprob": -0.0007009433466009796
              },
              {
                "text": "in",
                "logprob": -0.0031693964265286922
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3742564640421726,
              "max_token_negative_log_likelihood": 1.9009246826171875,
              "predictive_entropy": 0.1064815766724756,
              "shannon_entropy": 0.43746993907817
            }
          }
        ],
        "cached": false,
        "request_time": 1.0079610347747803,
        "request_datetime": 1755803174
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Caldwell Edwards used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id720"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nCaldwell Edwards used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Henry St. John served as a Member",
            "logprob": -10.648834779858582,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -3.2115895748138428
              },
              {
                "text": "St",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "John",
                "logprob": 0.0
              },
              {
                "text": "served",
                "logprob": -4.3990678787231445
              },
              {
                "text": "as",
                "logprob": -0.6194454431533813
              },
              {
                "text": "a",
                "logprob": -0.24893958866596222
              },
              {
                "text": "Member",
                "logprob": -2.1697921752929688
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3311041891574877,
              "max_token_negative_log_likelihood": 4.399066925048828,
              "predictive_entropy": 0.1198434541001916,
              "shannon_entropy": 0.7427682430365827
            }
          },
          {
            "text": "Caldwell Edwards seems to be cut",
            "logprob": -6.945184741168703,
            "tokens": [
              {
                "text": "C",
                "logprob": -0.21158957481384277
              },
              {
                "text": "ald",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "well",
                "logprob": 0.0
              },
              {
                "text": "Edwards",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "seems",
                "logprob": -4.214815139770508
              },
              {
                "text": "to",
                "logprob": -0.0065023042261600494
              },
              {
                "text": "be",
                "logprob": -0.6263545751571655
              },
              {
                "text": "cut",
                "logprob": -1.885921835899353
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8681480132509662,
              "max_token_negative_log_likelihood": 4.21481466293335,
              "predictive_entropy": 0.1076072285649623,
              "shannon_entropy": 0.472395398267647
            }
          },
          {
            "text": "Caldwell Edwards used to work in",
            "logprob": -0.3015207540624374,
            "tokens": [
              {
                "text": "C",
                "logprob": -0.21158957481384277
              },
              {
                "text": "ald",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "well",
                "logprob": 0.0
              },
              {
                "text": "Edwards",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "used",
                "logprob": -0.08981519192457199
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -5.221230458118953e-05
              },
              {
                "text": "in",
                "logprob": -6.246371776796877e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03769009415515967,
              "max_token_negative_log_likelihood": 0.21158957481384277,
              "predictive_entropy": 0.03168185293263903,
              "shannon_entropy": 0.1558819223350092
            }
          },
          {
            "text": "Caldwell Edwards used to work in",
            "logprob": -0.3015207540624374,
            "tokens": [
              {
                "text": "C",
                "logprob": -0.21158957481384277
              },
              {
                "text": "ald",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "well",
                "logprob": 0.0
              },
              {
                "text": "Edwards",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "used",
                "logprob": -0.08981519192457199
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -5.221230458118953e-05
              },
              {
                "text": "in",
                "logprob": -6.246371776796877e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03769009415515967,
              "max_token_negative_log_likelihood": 0.21158957481384277,
              "predictive_entropy": 0.03168185293263903,
              "shannon_entropy": 0.1558819223350092
            }
          },
          {
            "text": "Caldwell Edwards used to work in",
            "logprob": -0.3015207540624374,
            "tokens": [
              {
                "text": "C",
                "logprob": -0.21158957481384277
              },
              {
                "text": "ald",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "well",
                "logprob": 0.0
              },
              {
                "text": "Edwards",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "used",
                "logprob": -0.08981519192457199
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -5.221230458118953e-05
              },
              {
                "text": "in",
                "logprob": -6.246371776796877e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03769009415515967,
              "max_token_negative_log_likelihood": 0.21158957481384277,
              "predictive_entropy": 0.03168185293263903,
              "shannon_entropy": 0.1558819223350092
            }
          }
        ],
        "cached": false,
        "request_time": 1.0141658782958984,
        "request_datetime": 1755803174
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Dieter Medicus used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Munich"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "M\u00fcnchen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Munchen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Muenchen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Minga"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Monachium"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "M\u00fcnich"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "T\u00fcbingen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Tuebingen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Tubingen"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id648"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nDieter Medicus used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Dieter Medicus used to work in",
            "logprob": -0.05677881358314352,
            "tokens": [
              {
                "text": "Di",
                "logprob": -0.021331291645765305
              },
              {
                "text": "eter",
                "logprob": 0.0
              },
              {
                "text": "Med",
                "logprob": 0.0
              },
              {
                "text": "icus",
                "logprob": -1.7404405298293568e-05
              },
              {
                "text": "used",
                "logprob": -0.035250358283519745
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -7.259582343976945e-05
              },
              {
                "text": "in",
                "logprob": -0.0001070442158379592
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00709735871601147,
              "max_token_negative_log_likelihood": 0.03525037690997124,
              "predictive_entropy": 0.006888463029099512,
              "shannon_entropy": 0.04336627742998278
            }
          },
          {
            "text": "Dieter Medicus used to work in",
            "logprob": -0.05677881358314352,
            "tokens": [
              {
                "text": "Di",
                "logprob": -0.021331291645765305
              },
              {
                "text": "eter",
                "logprob": 0.0
              },
              {
                "text": "Med",
                "logprob": 0.0
              },
              {
                "text": "icus",
                "logprob": -1.7404405298293568e-05
              },
              {
                "text": "used",
                "logprob": -0.035250358283519745
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -7.259582343976945e-05
              },
              {
                "text": "in",
                "logprob": -0.0001070442158379592
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00709735871601147,
              "max_token_negative_log_likelihood": 0.03525037690997124,
              "predictive_entropy": 0.006888463029099512,
              "shannon_entropy": 0.04336627742998278
            }
          },
          {
            "text": "Dieter Medicus used to work in",
            "logprob": -0.05677881358314352,
            "tokens": [
              {
                "text": "Di",
                "logprob": -0.021331291645765305
              },
              {
                "text": "eter",
                "logprob": 0.0
              },
              {
                "text": "Med",
                "logprob": 0.0
              },
              {
                "text": "icus",
                "logprob": -1.7404405298293568e-05
              },
              {
                "text": "used",
                "logprob": -0.035250358283519745
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -7.259582343976945e-05
              },
              {
                "text": "in",
                "logprob": -0.0001070442158379592
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00709735871601147,
              "max_token_negative_log_likelihood": 0.03525037690997124,
              "predictive_entropy": 0.006888463029099512,
              "shannon_entropy": 0.04336627742998278
            }
          },
          {
            "text": "Dieter Medicus used to work in",
            "logprob": -0.05677881358314352,
            "tokens": [
              {
                "text": "Di",
                "logprob": -0.021331291645765305
              },
              {
                "text": "eter",
                "logprob": 0.0
              },
              {
                "text": "Med",
                "logprob": 0.0
              },
              {
                "text": "icus",
                "logprob": -1.7404405298293568e-05
              },
              {
                "text": "used",
                "logprob": -0.035250358283519745
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -7.259582343976945e-05
              },
              {
                "text": "in",
                "logprob": -0.0001070442158379592
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00709735871601147,
              "max_token_negative_log_likelihood": 0.03525037690997124,
              "predictive_entropy": 0.006888463029099512,
              "shannon_entropy": 0.04336627742998278
            }
          },
          {
            "text": "Dieter Medicus used to work in",
            "logprob": -0.05677881358314352,
            "tokens": [
              {
                "text": "Di",
                "logprob": -0.021331291645765305
              },
              {
                "text": "eter",
                "logprob": 0.0
              },
              {
                "text": "Med",
                "logprob": 0.0
              },
              {
                "text": "icus",
                "logprob": -1.7404405298293568e-05
              },
              {
                "text": "used",
                "logprob": -0.035250358283519745
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -7.259582343976945e-05
              },
              {
                "text": "in",
                "logprob": -0.0001070442158379592
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00709735871601147,
              "max_token_negative_log_likelihood": 0.03525037690997124,
              "predictive_entropy": 0.006888463029099512,
              "shannon_entropy": 0.04336627742998278
            }
          }
        ],
        "cached": false,
        "request_time": 1.0159339904785156,
        "request_datetime": 1755803175
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Juan Manuel Urtubey used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Salta"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id304"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJuan Manuel Urtubey used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Juan Manuel Urtubey, who",
            "logprob": -6.202471468433366,
            "tokens": [
              {
                "text": "Juan",
                "logprob": -0.022283289581537247
              },
              {
                "text": "Manuel",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "U",
                "logprob": 0.0
              },
              {
                "text": "rt",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ub",
                "logprob": -1.811964830267243e-05
              },
              {
                "text": "ey",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -4.025446891784668
              },
              {
                "text": "who",
                "logprob": -2.154721975326538
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.775308873990598,
              "max_token_negative_log_likelihood": 4.02544641494751,
              "predictive_entropy": 0.04293703611726585,
              "shannon_entropy": 0.3396229138659379
            }
          },
          {
            "text": "Juan Manuel Urtubey used to",
            "logprob": -0.04774983024554302,
            "tokens": [
              {
                "text": "Juan",
                "logprob": -0.022283289581537247
              },
              {
                "text": "Manuel",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "U",
                "logprob": 0.0
              },
              {
                "text": "rt",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ub",
                "logprob": -1.811964830267243e-05
              },
              {
                "text": "ey",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.025446871295571327
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.005968725329319469,
              "max_token_negative_log_likelihood": 0.02544684335589409,
              "predictive_entropy": 0.005827422233014801,
              "shannon_entropy": 0.035925612014139574
            }
          },
          {
            "text": "Juan Manuel Urtubey used to",
            "logprob": -0.04774983024554302,
            "tokens": [
              {
                "text": "Juan",
                "logprob": -0.022283289581537247
              },
              {
                "text": "Manuel",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "U",
                "logprob": 0.0
              },
              {
                "text": "rt",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ub",
                "logprob": -1.811964830267243e-05
              },
              {
                "text": "ey",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.025446871295571327
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.005968725329319469,
              "max_token_negative_log_likelihood": 0.02544684335589409,
              "predictive_entropy": 0.005827422233014801,
              "shannon_entropy": 0.035925612014139574
            }
          },
          {
            "text": "Juan Manuel Urtubey used to",
            "logprob": -0.04774983024554302,
            "tokens": [
              {
                "text": "Juan",
                "logprob": -0.022283289581537247
              },
              {
                "text": "Manuel",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "U",
                "logprob": 0.0
              },
              {
                "text": "rt",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ub",
                "logprob": -1.811964830267243e-05
              },
              {
                "text": "ey",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.025446871295571327
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.005968725329319469,
              "max_token_negative_log_likelihood": 0.02544684335589409,
              "predictive_entropy": 0.005827422233014801,
              "shannon_entropy": 0.035925612014139574
            }
          },
          {
            "text": "Juan Manuel Urtubey used to",
            "logprob": -0.04774983024554302,
            "tokens": [
              {
                "text": "Juan",
                "logprob": -0.022283289581537247
              },
              {
                "text": "Manuel",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "U",
                "logprob": 0.0
              },
              {
                "text": "rt",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ub",
                "logprob": -1.811964830267243e-05
              },
              {
                "text": "ey",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.025446871295571327
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.005968725329319469,
              "max_token_negative_log_likelihood": 0.02544684335589409,
              "predictive_entropy": 0.005827422233014801,
              "shannon_entropy": 0.035925612014139574
            }
          }
        ],
        "cached": false,
        "request_time": 1.0186834335327148,
        "request_datetime": 1755803175
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Francisco de Paula Sousa e Melo used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Bras\u00edlia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Brasiliense"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id155"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nFrancisco de Paula Sousa e Melo used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Francisco de Paula Sousa e",
            "logprob": -0.026484483852868834,
            "tokens": [
              {
                "text": "Francisco",
                "logprob": -0.026484007015824318
              },
              {
                "text": "de",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "Pa",
                "logprob": 0.0
              },
              {
                "text": "ula",
                "logprob": 0.0
              },
              {
                "text": "S",
                "logprob": 0.0
              },
              {
                "text": "ous",
                "logprob": 0.0
              },
              {
                "text": "a",
                "logprob": 0.0
              },
              {
                "text": "e",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003310562577112819,
              "max_token_negative_log_likelihood": 0.02648402377963066,
              "predictive_entropy": 0.003224038053289746,
              "shannon_entropy": 0.02162292774815612
            }
          },
          {
            "text": "Francisco de Paula Sousa e",
            "logprob": -0.026484483852868834,
            "tokens": [
              {
                "text": "Francisco",
                "logprob": -0.026484007015824318
              },
              {
                "text": "de",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "Pa",
                "logprob": 0.0
              },
              {
                "text": "ula",
                "logprob": 0.0
              },
              {
                "text": "S",
                "logprob": 0.0
              },
              {
                "text": "ous",
                "logprob": 0.0
              },
              {
                "text": "a",
                "logprob": 0.0
              },
              {
                "text": "e",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003310562577112819,
              "max_token_negative_log_likelihood": 0.02648402377963066,
              "predictive_entropy": 0.003224038053289746,
              "shannon_entropy": 0.02162292774815612
            }
          },
          {
            "text": "Francisco de Paula Sousa e",
            "logprob": -0.026484483852868834,
            "tokens": [
              {
                "text": "Francisco",
                "logprob": -0.026484007015824318
              },
              {
                "text": "de",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "Pa",
                "logprob": 0.0
              },
              {
                "text": "ula",
                "logprob": 0.0
              },
              {
                "text": "S",
                "logprob": 0.0
              },
              {
                "text": "ous",
                "logprob": 0.0
              },
              {
                "text": "a",
                "logprob": 0.0
              },
              {
                "text": "e",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003310562577112819,
              "max_token_negative_log_likelihood": 0.02648402377963066,
              "predictive_entropy": 0.003224038053289746,
              "shannon_entropy": 0.02162292774815612
            }
          },
          {
            "text": "Francisco de Paula Sousa e",
            "logprob": -0.026484483852868834,
            "tokens": [
              {
                "text": "Francisco",
                "logprob": -0.026484007015824318
              },
              {
                "text": "de",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "Pa",
                "logprob": 0.0
              },
              {
                "text": "ula",
                "logprob": 0.0
              },
              {
                "text": "S",
                "logprob": 0.0
              },
              {
                "text": "ous",
                "logprob": 0.0
              },
              {
                "text": "a",
                "logprob": 0.0
              },
              {
                "text": "e",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003310562577112819,
              "max_token_negative_log_likelihood": 0.02648402377963066,
              "predictive_entropy": 0.003224038053289746,
              "shannon_entropy": 0.02162292774815612
            }
          },
          {
            "text": "Francisco de Paula Sousa e",
            "logprob": -0.026484483852868834,
            "tokens": [
              {
                "text": "Francisco",
                "logprob": -0.026484007015824318
              },
              {
                "text": "de",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "Pa",
                "logprob": 0.0
              },
              {
                "text": "ula",
                "logprob": 0.0
              },
              {
                "text": "S",
                "logprob": 0.0
              },
              {
                "text": "ous",
                "logprob": 0.0
              },
              {
                "text": "a",
                "logprob": 0.0
              },
              {
                "text": "e",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.003310562577112819,
              "max_token_negative_log_likelihood": 0.02648402377963066,
              "predictive_entropy": 0.003224038053289746,
              "shannon_entropy": 0.02162292774815612
            }
          }
        ],
        "cached": false,
        "request_time": 1.0122649669647217,
        "request_datetime": 1755803175
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Rufus E. Lester used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id165"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nRufus E. Lester used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Rufus E. Lester used",
            "logprob": -0.5515804886815872,
            "tokens": [
              {
                "text": "R",
                "logprob": -0.4551404118537903
              },
              {
                "text": "uf",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "E",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": 0.0
              },
              {
                "text": "L",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ester",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.09643912315368652
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0689475573599605,
              "max_token_negative_log_likelihood": 0.4551404118537903,
              "predictive_entropy": 0.047037038020764754,
              "shannon_entropy": 0.22548049672834897
            }
          },
          {
            "text": "Rufus E. Lester used",
            "logprob": -0.5515804886815872,
            "tokens": [
              {
                "text": "R",
                "logprob": -0.4551404118537903
              },
              {
                "text": "uf",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "E",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": 0.0
              },
              {
                "text": "L",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ester",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.09643912315368652
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0689475573599605,
              "max_token_negative_log_likelihood": 0.4551404118537903,
              "predictive_entropy": 0.047037038020764754,
              "shannon_entropy": 0.22548049672834897
            }
          },
          {
            "text": "Victor Leemans used to work in",
            "logprob": -2.6126728265952295,
            "tokens": [
              {
                "text": "Victor",
                "logprob": -2.2676403522491455
              },
              {
                "text": "Le",
                "logprob": -0.048688728362321854
              },
              {
                "text": "em",
                "logprob": 0.0
              },
              {
                "text": "ans",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.2942924201488495
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "work",
                "logprob": -0.000300600629998371
              },
              {
                "text": "in",
                "logprob": -0.0017500099493190646
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3265841011598418,
              "max_token_negative_log_likelihood": 2.2676403522491455,
              "predictive_entropy": 0.06281456317809031,
              "shannon_entropy": 0.32525095851219277
            }
          },
          {
            "text": "Rufus E. Lester used",
            "logprob": -0.5515804886815872,
            "tokens": [
              {
                "text": "R",
                "logprob": -0.4551404118537903
              },
              {
                "text": "uf",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "E",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": 0.0
              },
              {
                "text": "L",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ester",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.09643912315368652
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0689475573599605,
              "max_token_negative_log_likelihood": 0.4551404118537903,
              "predictive_entropy": 0.047037038020764754,
              "shannon_entropy": 0.22548049672834897
            }
          },
          {
            "text": "It appears the description of Rufus",
            "logprob": -10.686034683138132,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.0488903522491455
              },
              {
                "text": "appears",
                "logprob": -0.708729088306427
              },
              {
                "text": "the",
                "logprob": -2.4266607761383057
              },
              {
                "text": "description",
                "logprob": -4.696842193603516
              },
              {
                "text": "of",
                "logprob": -0.7453333139419556
              },
              {
                "text": "R",
                "logprob": -0.05957895889878273
              },
              {
                "text": "uf",
                "logprob": 0.0
              },
              {
                "text": "us",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.335754208266735,
              "max_token_negative_log_likelihood": 4.696841239929199,
              "predictive_entropy": 0.15999960014596581,
              "shannon_entropy": 0.7692125016679415
            }
          }
        ],
        "cached": false,
        "request_time": 1.009685754776001,
        "request_datetime": 1755803175
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Margarita Curmina Cervera used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Mexico City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mexico D.F."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ciudad de M\u00e9xico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Mexico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mexico City, Mexico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "CDMX"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mexico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "capitalino"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id836"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nMargarita Curmina Cervera used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Margarita Curmina Cervera used",
            "logprob": -0.5203225979011563,
            "tokens": [
              {
                "text": "Mar",
                "logprob": -0.4210934042930603
              },
              {
                "text": "gar",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "ita",
                "logprob": 0.0
              },
              {
                "text": "Cur",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "mina",
                "logprob": -3.313963316031732e-05
              },
              {
                "text": "Cer",
                "logprob": -1.1086402082582936e-05
              },
              {
                "text": "vera",
                "logprob": -2.861018856492592e-06
              },
              {
                "text": "used",
                "logprob": -0.09918079525232315
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06504032489159073,
              "max_token_negative_log_likelihood": 0.4210934042930603,
              "predictive_entropy": 0.045780022551742405,
              "shannon_entropy": 0.23249689408912122
            }
          },
          {
            "text": "Margarita Curmina Cervera used",
            "logprob": -0.5203225979011563,
            "tokens": [
              {
                "text": "Mar",
                "logprob": -0.4210934042930603
              },
              {
                "text": "gar",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "ita",
                "logprob": 0.0
              },
              {
                "text": "Cur",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "mina",
                "logprob": -3.313963316031732e-05
              },
              {
                "text": "Cer",
                "logprob": -1.1086402082582936e-05
              },
              {
                "text": "vera",
                "logprob": -2.861018856492592e-06
              },
              {
                "text": "used",
                "logprob": -0.09918079525232315
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06504032489159073,
              "max_token_negative_log_likelihood": 0.4210934042930603,
              "predictive_entropy": 0.045780022551742405,
              "shannon_entropy": 0.23249689408912122
            }
          },
          {
            "text": "Margarita Curmina Cervera might",
            "logprob": -8.110700490067416,
            "tokens": [
              {
                "text": "Marg",
                "logprob": -2.389843463897705
              },
              {
                "text": "ar",
                "logprob": -0.009081486612558365
              },
              {
                "text": "ita",
                "logprob": 0.0
              },
              {
                "text": "Cur",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "mina",
                "logprob": -3.0040289857424796e-05
              },
              {
                "text": "Cer",
                "logprob": -5.090107151772827e-05
              },
              {
                "text": "vera",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "might",
                "logprob": -5.711691856384277
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0138372017393493,
              "max_token_negative_log_likelihood": 5.711688995361328,
              "predictive_entropy": 0.030873365248865525,
              "shannon_entropy": 0.23499619764355284
            }
          },
          {
            "text": "Margarita Curmina Cervera used",
            "logprob": -0.5203225979011563,
            "tokens": [
              {
                "text": "Mar",
                "logprob": -0.4210934042930603
              },
              {
                "text": "gar",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "ita",
                "logprob": 0.0
              },
              {
                "text": "Cur",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "mina",
                "logprob": -3.313963316031732e-05
              },
              {
                "text": "Cer",
                "logprob": -1.1086402082582936e-05
              },
              {
                "text": "vera",
                "logprob": -2.861018856492592e-06
              },
              {
                "text": "used",
                "logprob": -0.09918079525232315
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06504032489159073,
              "max_token_negative_log_likelihood": 0.4210934042930603,
              "predictive_entropy": 0.045780022551742405,
              "shannon_entropy": 0.23249689408912122
            }
          },
          {
            "text": "Margarita Curmina Cervera used",
            "logprob": -0.5203225979011563,
            "tokens": [
              {
                "text": "Mar",
                "logprob": -0.4210934042930603
              },
              {
                "text": "gar",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "ita",
                "logprob": 0.0
              },
              {
                "text": "Cur",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "mina",
                "logprob": -3.313963316031732e-05
              },
              {
                "text": "Cer",
                "logprob": -1.1086402082582936e-05
              },
              {
                "text": "vera",
                "logprob": -2.861018856492592e-06
              },
              {
                "text": "used",
                "logprob": -0.09918079525232315
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06504032489159073,
              "max_token_negative_log_likelihood": 0.4210934042930603,
              "predictive_entropy": 0.045780022551742405,
              "shannon_entropy": 0.23249689408912122
            }
          }
        ],
        "cached": false,
        "request_time": 1.009129524230957,
        "request_datetime": 1755803176
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Josef Netzer used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Vienna"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Wien"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Vienna, Austria"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "W"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Viennese"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Leipzig"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id735"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJosef Netzer used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Josef Netzer used to work in Vienna",
            "logprob": -0.13768487141347663,
            "tokens": [
              {
                "text": "Josef",
                "logprob": -0.07674283534288406
              },
              {
                "text": "Net",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "zer",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.017689906060695648
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -3.755022044060752e-05
              },
              {
                "text": "in",
                "logprob": -0.0001081169830285944
              },
              {
                "text": "Vienna",
                "logprob": -0.04310610517859459
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01721061685021219,
              "max_token_negative_log_likelihood": 0.07674285769462585,
              "predictive_entropy": 0.016235865997256127,
              "shannon_entropy": 0.10226236905371877
            }
          },
          {
            "text": "Josef Netzer used to work in Vienna",
            "logprob": -0.13768487141347663,
            "tokens": [
              {
                "text": "Josef",
                "logprob": -0.07674283534288406
              },
              {
                "text": "Net",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "zer",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.017689906060695648
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -3.755022044060752e-05
              },
              {
                "text": "in",
                "logprob": -0.0001081169830285944
              },
              {
                "text": "Vienna",
                "logprob": -0.04310610517859459
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01721061685021219,
              "max_token_negative_log_likelihood": 0.07674285769462585,
              "predictive_entropy": 0.016235865997256127,
              "shannon_entropy": 0.10226236905371877
            }
          },
          {
            "text": "Josef Netzer used to work in Vienna",
            "logprob": -0.13768487141347663,
            "tokens": [
              {
                "text": "Josef",
                "logprob": -0.07674283534288406
              },
              {
                "text": "Net",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "zer",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.017689906060695648
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -3.755022044060752e-05
              },
              {
                "text": "in",
                "logprob": -0.0001081169830285944
              },
              {
                "text": "Vienna",
                "logprob": -0.04310610517859459
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01721061685021219,
              "max_token_negative_log_likelihood": 0.07674285769462585,
              "predictive_entropy": 0.016235865997256127,
              "shannon_entropy": 0.10226236905371877
            }
          },
          {
            "text": "Josef Netzer used to work in Vienna",
            "logprob": -0.13768487141347663,
            "tokens": [
              {
                "text": "Josef",
                "logprob": -0.07674283534288406
              },
              {
                "text": "Net",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "zer",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.017689906060695648
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -3.755022044060752e-05
              },
              {
                "text": "in",
                "logprob": -0.0001081169830285944
              },
              {
                "text": "Vienna",
                "logprob": -0.04310610517859459
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01721061685021219,
              "max_token_negative_log_likelihood": 0.07674285769462585,
              "predictive_entropy": 0.016235865997256127,
              "shannon_entropy": 0.10226236905371877
            }
          },
          {
            "text": "Josef Netzer used to work in Vienna",
            "logprob": -0.13768487141347663,
            "tokens": [
              {
                "text": "Josef",
                "logprob": -0.07674283534288406
              },
              {
                "text": "Net",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "zer",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.017689906060695648
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -3.755022044060752e-05
              },
              {
                "text": "in",
                "logprob": -0.0001081169830285944
              },
              {
                "text": "Vienna",
                "logprob": -0.04310610517859459
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01721061685021219,
              "max_token_negative_log_likelihood": 0.07674285769462585,
              "predictive_entropy": 0.016235865997256127,
              "shannon_entropy": 0.10226236905371877
            }
          }
        ],
        "cached": false,
        "request_time": 1.011382818222046,
        "request_datetime": 1755803176
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Michael Richards used to work in"
        },
        "references": [
          {
            "output": {
              "text": "New York City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "NYC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "the five boroughs"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Big Apple"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "NY City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York, New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York City, New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York, NY"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York City (NYC)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New Yorker"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Fort Neu-Amsterdam"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "New York"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Big Apple"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The City That Never Sleeps"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gotham City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "NYC"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id296"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nMichael Richards used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Michael Richards used to work in New",
            "logprob": -0.4835555438985466,
            "tokens": [
              {
                "text": "Michael",
                "logprob": -0.28709274530410767
              },
              {
                "text": "Rich",
                "logprob": -0.0007856381707824767
              },
              {
                "text": "ards",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03776629641652107
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.637133679352701e-05
              },
              {
                "text": "in",
                "logprob": -8.296622399939224e-05
              },
              {
                "text": "New",
                "logprob": -0.15778152644634247
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06044444583403674,
              "max_token_negative_log_likelihood": 0.2870927155017853,
              "predictive_entropy": 0.04843482886963102,
              "shannon_entropy": 0.24133348614545858
            }
          },
          {
            "text": "Michael Richards used to work in New",
            "logprob": -0.4835555438985466,
            "tokens": [
              {
                "text": "Michael",
                "logprob": -0.28709274530410767
              },
              {
                "text": "Rich",
                "logprob": -0.0007856381707824767
              },
              {
                "text": "ards",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03776629641652107
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.637133679352701e-05
              },
              {
                "text": "in",
                "logprob": -8.296622399939224e-05
              },
              {
                "text": "New",
                "logprob": -0.15778152644634247
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06044444583403674,
              "max_token_negative_log_likelihood": 0.2870927155017853,
              "predictive_entropy": 0.04843482886963102,
              "shannon_entropy": 0.24133348614545858
            }
          },
          {
            "text": "Michael Richards used to work in New",
            "logprob": -0.4835555438985466,
            "tokens": [
              {
                "text": "Michael",
                "logprob": -0.28709274530410767
              },
              {
                "text": "Rich",
                "logprob": -0.0007856381707824767
              },
              {
                "text": "ards",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03776629641652107
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.637133679352701e-05
              },
              {
                "text": "in",
                "logprob": -8.296622399939224e-05
              },
              {
                "text": "New",
                "logprob": -0.15778152644634247
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06044444583403674,
              "max_token_negative_log_likelihood": 0.2870927155017853,
              "predictive_entropy": 0.04843482886963102,
              "shannon_entropy": 0.24133348614545858
            }
          },
          {
            "text": "Michael Richards used to work in Los",
            "logprob": -2.8273056184043526,
            "tokens": [
              {
                "text": "Michael",
                "logprob": -0.28709274530410767
              },
              {
                "text": "Rich",
                "logprob": -0.0007856381707824767
              },
              {
                "text": "ards",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.03776629641652107
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.637133679352701e-05
              },
              {
                "text": "in",
                "logprob": -8.296622399939224e-05
              },
              {
                "text": "Los",
                "logprob": -2.5015316009521484
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.35341317348229495,
              "max_token_negative_log_likelihood": 2.5015313625335693,
              "predictive_entropy": 0.05721892742030832,
              "shannon_entropy": 0.24133348614545858
            }
          },
          {
            "text": "It appears that the information about Michael Rich",
            "logprob": -6.750385841151001,
            "tokens": [
              {
                "text": "It",
                "logprob": -3.224592685699463
              },
              {
                "text": "appears",
                "logprob": -0.9482437372207642
              },
              {
                "text": "that",
                "logprob": -0.23476211726665497
              },
              {
                "text": "the",
                "logprob": -0.12581034004688263
              },
              {
                "text": "information",
                "logprob": -1.3030027151107788
              },
              {
                "text": "about",
                "logprob": -0.8336290717124939
              },
              {
                "text": "Michael",
                "logprob": -0.08003932982683182
              },
              {
                "text": "Rich",
                "logprob": -0.0003058442671317607
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8437981971328554,
              "max_token_negative_log_likelihood": 3.224592447280884,
              "predictive_entropy": 0.1978269226165139,
              "shannon_entropy": 0.9234105494979303
            }
          }
        ],
        "cached": false,
        "request_time": 1.0119929313659668,
        "request_datetime": 1755803176
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Viktor Zvagelskiy used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Moscow"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moskva"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow, Russia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moskva Federal City, Russia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow, USSR"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moskva, Russia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Moscow"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow, Russian Federation"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow, Soviet Union"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow, Russian SFSR"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Muscovite"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscovite"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Muscovite"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id408"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nViktor Zvagelskiy used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Viktor Zvagelskiy",
            "logprob": -2.5910255846082464,
            "tokens": [
              {
                "text": "Vik",
                "logprob": -2.59084415435791
              },
              {
                "text": "tor",
                "logprob": 0.0
              },
              {
                "text": "Z",
                "logprob": -5.435795901576057e-05
              },
              {
                "text": "v",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "ag",
                "logprob": -3.0517112463712692e-05
              },
              {
                "text": "el",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "ski",
                "logprob": -9.321732068201527e-05
              },
              {
                "text": "y",
                "logprob": -1.4305104514278355e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.3238781996481208,
              "max_token_negative_log_likelihood": 2.59084415435791,
              "predictive_entropy": 0.02429783265664298,
              "shannon_entropy": 0.1402525248089781
            }
          },
          {
            "text": "Victor Zvagelskiy used",
            "logprob": -0.38430231865091,
            "tokens": [
              {
                "text": "Victor",
                "logprob": -0.3408440947532654
              },
              {
                "text": "Z",
                "logprob": -0.006007234565913677
              },
              {
                "text": "v",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ag",
                "logprob": -1.0609570381348021e-05
              },
              {
                "text": "el",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ski",
                "logprob": -6.603976362384856e-05
              },
              {
                "text": "y",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.0373738631606102
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.048037795571652,
              "max_token_negative_log_likelihood": 0.3408440947532654,
              "predictive_entropy": 0.03555616050766375,
              "shannon_entropy": 0.1714929806300347
            }
          },
          {
            "text": "It seems as though the statement about Vik",
            "logprob": -11.991350710391998,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.15334415435791
              },
              {
                "text": "seems",
                "logprob": -0.5692130327224731
              },
              {
                "text": "as",
                "logprob": -5.201003551483154
              },
              {
                "text": "though",
                "logprob": -0.11283491551876068
              },
              {
                "text": "the",
                "logprob": -0.14452029764652252
              },
              {
                "text": "statement",
                "logprob": -2.427670478820801
              },
              {
                "text": "about",
                "logprob": -1.0228636264801025
              },
              {
                "text": "Vik",
                "logprob": -0.35990065336227417
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.4989185715094209,
              "max_token_negative_log_likelihood": 5.2010016441345215,
              "predictive_entropy": 0.207476137438789,
              "shannon_entropy": 0.9390910305082798
            }
          },
          {
            "text": "Victor Zvagelskiy used",
            "logprob": -0.38430231865091,
            "tokens": [
              {
                "text": "Victor",
                "logprob": -0.3408440947532654
              },
              {
                "text": "Z",
                "logprob": -0.006007234565913677
              },
              {
                "text": "v",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ag",
                "logprob": -1.0609570381348021e-05
              },
              {
                "text": "el",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ski",
                "logprob": -6.603976362384856e-05
              },
              {
                "text": "y",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.0373738631606102
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.048037795571652,
              "max_token_negative_log_likelihood": 0.3408440947532654,
              "predictive_entropy": 0.03555616050766375,
              "shannon_entropy": 0.1714929806300347
            }
          },
          {
            "text": "Victor Zvagelskiy used",
            "logprob": -0.38430231865091,
            "tokens": [
              {
                "text": "Victor",
                "logprob": -0.3408440947532654
              },
              {
                "text": "Z",
                "logprob": -0.006007234565913677
              },
              {
                "text": "v",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ag",
                "logprob": -1.0609570381348021e-05
              },
              {
                "text": "el",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ski",
                "logprob": -6.603976362384856e-05
              },
              {
                "text": "y",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.0373738631606102
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.048037795571652,
              "max_token_negative_log_likelihood": 0.3408440947532654,
              "predictive_entropy": 0.03555616050766375,
              "shannon_entropy": 0.1714929806300347
            }
          }
        ],
        "cached": false,
        "request_time": 1.0143611431121826,
        "request_datetime": 1755803176
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Georges Mandel used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Love"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paree"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lutetia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paris, France"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisians"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id394"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nGeorges Mandel used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Georges Mandel used to work in Paris",
            "logprob": -0.5245994105640577,
            "tokens": [
              {
                "text": "Georges",
                "logprob": -0.4953058362007141
              },
              {
                "text": "Mand",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "el",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.021354397758841515
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.0002703301142901182
              },
              {
                "text": "in",
                "logprob": -0.00032658010604791343
              },
              {
                "text": "Paris",
                "logprob": -0.00734131271019578
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06557491962671413,
              "max_token_negative_log_likelihood": 0.49530577659606934,
              "predictive_entropy": 0.04132752749133317,
              "shannon_entropy": 0.14296333507855064
            }
          },
          {
            "text": "Georges Mandel used to work in Paris",
            "logprob": -0.5245994105640577,
            "tokens": [
              {
                "text": "Georges",
                "logprob": -0.4953058362007141
              },
              {
                "text": "Mand",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "el",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.021354397758841515
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.0002703301142901182
              },
              {
                "text": "in",
                "logprob": -0.00032658010604791343
              },
              {
                "text": "Paris",
                "logprob": -0.00734131271019578
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06557491962671413,
              "max_token_negative_log_likelihood": 0.49530577659606934,
              "predictive_entropy": 0.04132752749133317,
              "shannon_entropy": 0.14296333507855064
            }
          },
          {
            "text": "Georges Mandel used to work in Paris",
            "logprob": -0.5245994105640577,
            "tokens": [
              {
                "text": "Georges",
                "logprob": -0.4953058362007141
              },
              {
                "text": "Mand",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "el",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.021354397758841515
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.0002703301142901182
              },
              {
                "text": "in",
                "logprob": -0.00032658010604791343
              },
              {
                "text": "Paris",
                "logprob": -0.00734131271019578
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06557491962671413,
              "max_token_negative_log_likelihood": 0.49530577659606934,
              "predictive_entropy": 0.04132752749133317,
              "shannon_entropy": 0.14296333507855064
            }
          },
          {
            "text": "Based on the pattern provided, it seems",
            "logprob": -8.161147430422716,
            "tokens": [
              {
                "text": "Based",
                "logprob": -4.839056015014648
              },
              {
                "text": "on",
                "logprob": -0.00013731967192143202
              },
              {
                "text": "the",
                "logprob": -0.005455249920487404
              },
              {
                "text": "pattern",
                "logprob": -0.3906078338623047
              },
              {
                "text": "provided",
                "logprob": -0.8956355452537537
              },
              {
                "text": ",",
                "logprob": -0.3846229612827301
              },
              {
                "text": "it",
                "logprob": -0.6074094772338867
              },
              {
                "text": "seems",
                "logprob": -1.0382230281829834
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.02014323954063,
              "max_token_negative_log_likelihood": 4.839054584503174,
              "predictive_entropy": 0.20427766469947528,
              "shannon_entropy": 0.9108527457428863
            }
          },
          {
            "text": "Georges Mandel used to work in",
            "logprob": -1.19303650813481,
            "tokens": [
              {
                "text": "Georg",
                "logprob": -1.0890557765960693
              },
              {
                "text": "es",
                "logprob": -0.0887775868177414
              },
              {
                "text": "Mand",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "el",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.014776899479329586
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.0001685477327555418
              },
              {
                "text": "in",
                "logprob": -0.00025674383505247533
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.14912960045336376,
              "max_token_negative_log_likelihood": 1.0890560150146484,
              "predictive_entropy": 0.05784082928761336,
              "shannon_entropy": 0.17013852178546962
            }
          }
        ],
        "cached": false,
        "request_time": 1.0108752250671387,
        "request_datetime": 1755803177
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Augustus Owsley Stanley used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id801"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nAugustus Owsley Stanley used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Augustus Owsley Stanley used to",
            "logprob": -1.490448385443237,
            "tokens": [
              {
                "text": "August",
                "logprob": -1.2227096557617188
              },
              {
                "text": "us",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "O",
                "logprob": -8.106198947643861e-06
              },
              {
                "text": "ws",
                "logprob": 0.0
              },
              {
                "text": "ley",
                "logprob": 0.0
              },
              {
                "text": "Stanley",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.267728716135025
              },
              {
                "text": "to",
                "logprob": -1.4305104514278355e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.18630604818886276,
              "max_token_negative_log_likelihood": 1.2227096557617188,
              "predictive_entropy": 0.07060716300779646,
              "shannon_entropy": 0.27840659616794294
            }
          },
          {
            "text": "Unfortunately, the information provided for Augustus",
            "logprob": -4.838293675333091,
            "tokens": [
              {
                "text": "Unfortunately",
                "logprob": -2.9727096557617188
              },
              {
                "text": ",",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "the",
                "logprob": -0.09488420933485031
              },
              {
                "text": "information",
                "logprob": -0.5569499731063843
              },
              {
                "text": "provided",
                "logprob": -0.8873410224914551
              },
              {
                "text": "for",
                "logprob": -0.27081164717674255
              },
              {
                "text": "August",
                "logprob": -0.055596571415662766
              },
              {
                "text": "us",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6047866772860502,
              "max_token_negative_log_likelihood": 2.9727094173431396,
              "predictive_entropy": 0.14775196090338483,
              "shannon_entropy": 0.7104631753049713
            }
          },
          {
            "text": "Based on the given information about various individuals",
            "logprob": -9.98978273200919,
            "tokens": [
              {
                "text": "Based",
                "logprob": -2.8477096557617188
              },
              {
                "text": "on",
                "logprob": -0.00020680672605521977
              },
              {
                "text": "the",
                "logprob": -0.0115497512742877
              },
              {
                "text": "given",
                "logprob": -2.8535163402557373
              },
              {
                "text": "information",
                "logprob": -0.9747681021690369
              },
              {
                "text": "about",
                "logprob": -2.432630777359009
              },
              {
                "text": "various",
                "logprob": -0.8351753354072571
              },
              {
                "text": "individuals",
                "logprob": -0.034225963056087494
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.2487227950423403,
              "max_token_negative_log_likelihood": 2.853516101837158,
              "predictive_entropy": 0.1647420750286983,
              "shannon_entropy": 0.9714427692815661
            }
          },
          {
            "text": "It seems that the information about Augustus",
            "logprob": -3.8788098618388176,
            "tokens": [
              {
                "text": "It",
                "logprob": -0.7227096557617188
              },
              {
                "text": "seems",
                "logprob": -0.736466646194458
              },
              {
                "text": "that",
                "logprob": -1.042637586593628
              },
              {
                "text": "the",
                "logprob": -0.12240001559257507
              },
              {
                "text": "information",
                "logprob": -0.5488206744194031
              },
              {
                "text": "about",
                "logprob": -0.6061534881591797
              },
              {
                "text": "August",
                "logprob": -0.09962179511785507
              },
              {
                "text": "us",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4848512224853039,
              "max_token_negative_log_likelihood": 1.042637586593628,
              "predictive_entropy": 0.23963983729481697,
              "shannon_entropy": 0.9123887605745207
            }
          },
          {
            "text": "Augustus Owsley Stanley used to",
            "logprob": -1.490448385443237,
            "tokens": [
              {
                "text": "August",
                "logprob": -1.2227096557617188
              },
              {
                "text": "us",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "O",
                "logprob": -8.106198947643861e-06
              },
              {
                "text": "ws",
                "logprob": 0.0
              },
              {
                "text": "ley",
                "logprob": 0.0
              },
              {
                "text": "Stanley",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.267728716135025
              },
              {
                "text": "to",
                "logprob": -1.4305104514278355e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.18630604818886276,
              "max_token_negative_log_likelihood": 1.2227096557617188,
              "predictive_entropy": 0.07060716300779646,
              "shannon_entropy": 0.27840659616794294
            }
          }
        ],
        "cached": false,
        "request_time": 1.0081982612609863,
        "request_datetime": 1755803177
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Allan Heywood Bright used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id378"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nAllan Heywood Bright used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "To complete the profile for Allan Hey",
            "logprob": -10.583361178631776,
            "tokens": [
              {
                "text": "To",
                "logprob": -4.964593887329102
              },
              {
                "text": "complete",
                "logprob": -0.0542098730802536
              },
              {
                "text": "the",
                "logprob": -0.031213488429784775
              },
              {
                "text": "profile",
                "logprob": -4.99934196472168
              },
              {
                "text": "for",
                "logprob": -0.48424214124679565
              },
              {
                "text": "All",
                "logprob": -0.0497567243874073
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "Hey",
                "logprob": -3.099436753473128e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3229197412735232,
              "max_token_negative_log_likelihood": 4.999340057373047,
              "predictive_entropy": 0.06196064664922574,
              "shannon_entropy": 0.49097083139049025
            }
          },
          {
            "text": "Henry St. John, Lord Howard of",
            "logprob": -10.12607663869857,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -1.4958438873291016
              },
              {
                "text": "St",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "John",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.2227787971496582
              },
              {
                "text": "Lord",
                "logprob": -6.1778883934021
              },
              {
                "text": "Howard",
                "logprob": -1.77852463722229
              },
              {
                "text": "of",
                "logprob": -0.4510408043861389
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.265758942812683,
              "max_token_negative_log_likelihood": 6.177883625030518,
              "predictive_entropy": 0.13924138364382088,
              "shannon_entropy": 0.9125149542974
            }
          },
          {
            "text": "Allan Heywood Bright used to work",
            "logprob": -0.5543161129456564,
            "tokens": [
              {
                "text": "All",
                "logprob": -0.37084388732910156
              },
              {
                "text": "an",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "Hey",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "wood",
                "logprob": 0.0
              },
              {
                "text": "Bright",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.18307045102119446
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.0003997480380348861
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0692895080174658,
              "max_token_negative_log_likelihood": 0.3708438575267792,
              "predictive_entropy": 0.05109807781983733,
              "shannon_entropy": 0.18618373421790047
            }
          },
          {
            "text": "It seems the statement about Allan Hey",
            "logprob": -8.795926406978538,
            "tokens": [
              {
                "text": "It",
                "logprob": -3.0583438873291016
              },
              {
                "text": "seems",
                "logprob": -0.7012902498245239
              },
              {
                "text": "the",
                "logprob": -1.7284505367279053
              },
              {
                "text": "statement",
                "logprob": -2.236633777618408
              },
              {
                "text": "about",
                "logprob": -0.967739462852478
              },
              {
                "text": "All",
                "logprob": -0.10346706211566925
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "Hey",
                "logprob": -1.4305104514278355e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.099490745924541,
              "max_token_negative_log_likelihood": 3.0583436489105225,
              "predictive_entropy": 0.18727924302207555,
              "shannon_entropy": 0.8087811000304526
            }
          },
          {
            "text": "Henry St. John's historical background",
            "logprob": -9.277754426002495,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -1.4958438873291016
              },
              {
                "text": "St",
                "logprob": 0.0
              },
              {
                "text": ".",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "John",
                "logprob": 0.0
              },
              {
                "text": "'",
                "logprob": -4.379028797149658
              },
              {
                "text": "s",
                "logprob": 0.0
              },
              {
                "text": "historical",
                "logprob": -1.871751308441162
              },
              {
                "text": "background",
                "logprob": -1.531130313873291
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1597191393375414,
              "max_token_negative_log_likelihood": 4.379027843475342,
              "predictive_entropy": 0.1261507971212268,
              "shannon_entropy": 0.8682419598143056
            }
          }
        ],
        "cached": false,
        "request_time": 1.0032904148101807,
        "request_datetime": 1755803177
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "John Herkimer used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id177"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJohn Herkimer used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "John Herkimer used to work in",
            "logprob": -0.34080694527568767,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.12268844991922379
              },
              {
                "text": "Her",
                "logprob": -0.0003921216703020036
              },
              {
                "text": "k",
                "logprob": -4.410734163684538e-06
              },
              {
                "text": "imer",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "used",
                "logprob": -0.2175687849521637
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.651657167822123e-05
              },
              {
                "text": "in",
                "logprob": -8.630380034446716e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04260086837650334,
              "max_token_negative_log_likelihood": 0.2175687849521637,
              "predictive_entropy": 0.0355125431802783,
              "shannon_entropy": 0.17317064636570478
            }
          },
          {
            "text": "Given the context of locations, the information",
            "logprob": -21.62398301064968,
            "tokens": [
              {
                "text": "Given",
                "logprob": -4.528938293457031
              },
              {
                "text": "the",
                "logprob": -0.17225252091884613
              },
              {
                "text": "context",
                "logprob": -2.485699415206909
              },
              {
                "text": "of",
                "logprob": -0.5833652019500732
              },
              {
                "text": "locations",
                "logprob": -4.822025299072266
              },
              {
                "text": ",",
                "logprob": -2.88214373588562
              },
              {
                "text": "the",
                "logprob": -2.8635902404785156
              },
              {
                "text": "information",
                "logprob": -3.28596830368042
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 2.702997487038374,
              "max_token_negative_log_likelihood": 4.822023868560791,
              "predictive_entropy": 0.15161951957270503,
              "shannon_entropy": 1.2558218203485012
            }
          },
          {
            "text": "John Herkimer used to work in",
            "logprob": -0.34080694527568767,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.12268844991922379
              },
              {
                "text": "Her",
                "logprob": -0.0003921216703020036
              },
              {
                "text": "k",
                "logprob": -4.410734163684538e-06
              },
              {
                "text": "imer",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "used",
                "logprob": -0.2175687849521637
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.651657167822123e-05
              },
              {
                "text": "in",
                "logprob": -8.630380034446716e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04260086837650334,
              "max_token_negative_log_likelihood": 0.2175687849521637,
              "predictive_entropy": 0.0355125431802783,
              "shannon_entropy": 0.17317064636570478
            }
          },
          {
            "text": "John Herkimer used to work in",
            "logprob": -0.34080694527568767,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.12268844991922379
              },
              {
                "text": "Her",
                "logprob": -0.0003921216703020036
              },
              {
                "text": "k",
                "logprob": -4.410734163684538e-06
              },
              {
                "text": "imer",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "used",
                "logprob": -0.2175687849521637
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.651657167822123e-05
              },
              {
                "text": "in",
                "logprob": -8.630380034446716e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04260086837650334,
              "max_token_negative_log_likelihood": 0.2175687849521637,
              "predictive_entropy": 0.0355125431802783,
              "shannon_entropy": 0.17317064636570478
            }
          },
          {
            "text": "John Herkimer, based on the",
            "logprob": -3.148965776597322,
            "tokens": [
              {
                "text": "John",
                "logprob": -0.12268844991922379
              },
              {
                "text": "Her",
                "logprob": -0.0003921216703020036
              },
              {
                "text": "k",
                "logprob": -4.410734163684538e-06
              },
              {
                "text": "imer",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": ",",
                "logprob": -2.342568874359131
              },
              {
                "text": "based",
                "logprob": -0.6411097049713135
              },
              {
                "text": "on",
                "logprob": -0.0019547895062714815
              },
              {
                "text": "the",
                "logprob": -0.04024706780910492
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.39362069833925517,
              "max_token_negative_log_likelihood": 2.3425686359405518,
              "predictive_entropy": 0.08903530434928442,
              "shannon_entropy": 0.44395818109853735
            }
          }
        ],
        "cached": false,
        "request_time": 1.0097284317016602,
        "request_datetime": 1755803177
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Jeremiah Meyer used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id992"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJeremiah Meyer used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Jeremiah Meyer used to work in",
            "logprob": -0.023401497398481297,
            "tokens": [
              {
                "text": "Jer",
                "logprob": -0.016391737386584282
              },
              {
                "text": "em",
                "logprob": -0.0006101653561927378
              },
              {
                "text": "iah",
                "logprob": 0.0
              },
              {
                "text": "Meyer",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.00634654751047492
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.65590606938349e-06
              },
              {
                "text": "in",
                "logprob": -4.339123915997334e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002925187050891509,
              "max_token_negative_log_likelihood": 0.016391733661293983,
              "predictive_entropy": 0.0028868091976619326,
              "shannon_entropy": 0.02078720521292418
            }
          },
          {
            "text": "Jeremiah Meyer used to work in",
            "logprob": -0.023401497398481297,
            "tokens": [
              {
                "text": "Jer",
                "logprob": -0.016391737386584282
              },
              {
                "text": "em",
                "logprob": -0.0006101653561927378
              },
              {
                "text": "iah",
                "logprob": 0.0
              },
              {
                "text": "Meyer",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.00634654751047492
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.65590606938349e-06
              },
              {
                "text": "in",
                "logprob": -4.339123915997334e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002925187050891509,
              "max_token_negative_log_likelihood": 0.016391733661293983,
              "predictive_entropy": 0.0028868091976619326,
              "shannon_entropy": 0.02078720521292418
            }
          },
          {
            "text": "Jeremiah Meyer used to work in",
            "logprob": -0.023401497398481297,
            "tokens": [
              {
                "text": "Jer",
                "logprob": -0.016391737386584282
              },
              {
                "text": "em",
                "logprob": -0.0006101653561927378
              },
              {
                "text": "iah",
                "logprob": 0.0
              },
              {
                "text": "Meyer",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.00634654751047492
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.65590606938349e-06
              },
              {
                "text": "in",
                "logprob": -4.339123915997334e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002925187050891509,
              "max_token_negative_log_likelihood": 0.016391733661293983,
              "predictive_entropy": 0.0028868091976619326,
              "shannon_entropy": 0.02078720521292418
            }
          },
          {
            "text": "Jeremiah Meyer used to work in",
            "logprob": -0.023401497398481297,
            "tokens": [
              {
                "text": "Jer",
                "logprob": -0.016391737386584282
              },
              {
                "text": "em",
                "logprob": -0.0006101653561927378
              },
              {
                "text": "iah",
                "logprob": 0.0
              },
              {
                "text": "Meyer",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.00634654751047492
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.65590606938349e-06
              },
              {
                "text": "in",
                "logprob": -4.339123915997334e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002925187050891509,
              "max_token_negative_log_likelihood": 0.016391733661293983,
              "predictive_entropy": 0.0028868091976619326,
              "shannon_entropy": 0.02078720521292418
            }
          },
          {
            "text": "Jeremiah Meyer used to work in",
            "logprob": -0.023401497398481297,
            "tokens": [
              {
                "text": "Jer",
                "logprob": -0.016391737386584282
              },
              {
                "text": "em",
                "logprob": -0.0006101653561927378
              },
              {
                "text": "iah",
                "logprob": 0.0
              },
              {
                "text": "Meyer",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.00634654751047492
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.65590606938349e-06
              },
              {
                "text": "in",
                "logprob": -4.339123915997334e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.002925187050891509,
              "max_token_negative_log_likelihood": 0.016391733661293983,
              "predictive_entropy": 0.0028868091976619326,
              "shannon_entropy": 0.02078720521292418
            }
          }
        ],
        "cached": false,
        "request_time": 1.0228326320648193,
        "request_datetime": 1755803178
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Johan Ameln used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Oslo"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Christiania"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Kristiania"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "NOOSL"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Oslo, Norway"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id486"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJohan Ameln used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Johan Ameln used to work in Amsterdam",
            "logprob": -1.3590565615376988,
            "tokens": [
              {
                "text": "Johan",
                "logprob": -0.18194472789764404
              },
              {
                "text": "Am",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "eln",
                "logprob": -6.246371776796877e-05
              },
              {
                "text": "used",
                "logprob": -0.02712545171380043
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.0649541915627196e-05
              },
              {
                "text": "in",
                "logprob": -5.6503606174374e-05
              },
              {
                "text": "Amsterdam",
                "logprob": -1.1498265266418457
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.16988207151826273,
              "max_token_negative_log_likelihood": 1.1498265266418457,
              "predictive_entropy": 0.06779720952090074,
              "shannon_entropy": 0.3845315566541103
            }
          },
          {
            "text": "- Johan Ameln used to work in",
            "logprob": -8.627066976272538,
            "tokens": [
              {
                "text": "-",
                "logprob": -8.306944847106934
              },
              {
                "text": "Johan",
                "logprob": -0.2341635376214981
              },
              {
                "text": "Am",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "eln",
                "logprob": -2.8609820219571702e-05
              },
              {
                "text": "used",
                "logprob": -0.08570099622011185
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.496695277746767e-05
              },
              {
                "text": "in",
                "logprob": -0.00016389934171456844
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0783782528162664,
              "max_token_negative_log_likelihood": 8.306903839111328,
              "predictive_entropy": 0.03328097060125401,
              "shannon_entropy": 0.27063752273014074
            }
          },
          {
            "text": "Johan Ameln used to work in Amsterdam",
            "logprob": -1.3590565615376988,
            "tokens": [
              {
                "text": "Johan",
                "logprob": -0.18194472789764404
              },
              {
                "text": "Am",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "eln",
                "logprob": -6.246371776796877e-05
              },
              {
                "text": "used",
                "logprob": -0.02712545171380043
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.0649541915627196e-05
              },
              {
                "text": "in",
                "logprob": -5.6503606174374e-05
              },
              {
                "text": "Amsterdam",
                "logprob": -1.1498265266418457
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.16988207151826273,
              "max_token_negative_log_likelihood": 1.1498265266418457,
              "predictive_entropy": 0.06779720952090074,
              "shannon_entropy": 0.3845315566541103
            }
          },
          {
            "text": "Johan Ameln used to work in the",
            "logprob": -3.921556561537699,
            "tokens": [
              {
                "text": "Johan",
                "logprob": -0.18194472789764404
              },
              {
                "text": "Am",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "eln",
                "logprob": -6.246371776796877e-05
              },
              {
                "text": "used",
                "logprob": -0.02712545171380043
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.0649541915627196e-05
              },
              {
                "text": "in",
                "logprob": -5.6503606174374e-05
              },
              {
                "text": "the",
                "logprob": -3.7123265266418457
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.49019454171594035,
              "max_token_negative_log_likelihood": 3.7123262882232666,
              "predictive_entropy": 0.033611819532776366,
              "shannon_entropy": 0.3845315566541103
            }
          },
          {
            "text": "Johan Ameln used to work in a",
            "logprob": -4.765306561537699,
            "tokens": [
              {
                "text": "Johan",
                "logprob": -0.18194472789764404
              },
              {
                "text": "Am",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "eln",
                "logprob": -6.246371776796877e-05
              },
              {
                "text": "used",
                "logprob": -0.02712545171380043
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.0649541915627196e-05
              },
              {
                "text": "in",
                "logprob": -5.6503606174374e-05
              },
              {
                "text": "a",
                "logprob": -4.556076526641846
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5956632023089732,
              "max_token_negative_log_likelihood": 4.556075572967529,
              "predictive_entropy": 0.028261310339981804,
              "shannon_entropy": 0.3845315566541103
            }
          }
        ],
        "cached": false,
        "request_time": 1.0181314945220947,
        "request_datetime": 1755803178
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Flockina von Platen used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Germany"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "FRG"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "BRD"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bundesrepublik Deutschland"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Federal Republic of Germany"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "de"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Deutschland"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "GER"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "BR Deutschland"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DE"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "German"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Federal Republic of Germany"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id696"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nFlockina von Platen used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Flockina von Platen's",
            "logprob": -5.332224845863948,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.2159421443939209
              },
              {
                "text": "lock",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "ina",
                "logprob": 0.0
              },
              {
                "text": "von",
                "logprob": -5.8412379075889476e-06
              },
              {
                "text": "Pl",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "aten",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "'",
                "logprob": -5.116271495819092
              },
              {
                "text": "s",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6665278710452753,
              "max_token_negative_log_likelihood": 5.116269588470459,
              "predictive_entropy": 0.02558783255240371,
              "shannon_entropy": 0.22948082370680822
            }
          },
          {
            "text": "Flockina von Platen used to",
            "logprob": -0.5197248756662418,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.2159421443939209
              },
              {
                "text": "lock",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "ina",
                "logprob": 0.0
              },
              {
                "text": "von",
                "logprob": -5.8412379075889476e-06
              },
              {
                "text": "Pl",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "aten",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "used",
                "logprob": -0.3037712872028351
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06496560946385799,
              "max_token_negative_log_likelihood": 0.3037712574005127,
              "predictive_entropy": 0.04977574199160628,
              "shannon_entropy": 0.22948120768464264
            }
          },
          {
            "text": "Flockina von Platen used to",
            "logprob": -0.5197248756662418,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.2159421443939209
              },
              {
                "text": "lock",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "ina",
                "logprob": 0.0
              },
              {
                "text": "von",
                "logprob": -5.8412379075889476e-06
              },
              {
                "text": "Pl",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "aten",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "used",
                "logprob": -0.3037712872028351
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06496560946385799,
              "max_token_negative_log_likelihood": 0.3037712574005127,
              "predictive_entropy": 0.04977574199160628,
              "shannon_entropy": 0.22948120768464264
            }
          },
          {
            "text": "Flockina von Platen is associated",
            "logprob": -10.630584716774592,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.2159421443939209
              },
              {
                "text": "lock",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "ina",
                "logprob": 0.0
              },
              {
                "text": "von",
                "logprob": -5.8412379075889476e-06
              },
              {
                "text": "Pl",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "aten",
                "logprob": -1.1920922133867862e-06
              },
              {
                "text": "is",
                "logprob": -5.928771495819092
              },
              {
                "text": "associated",
                "logprob": -4.4858598709106445
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3288224972812372,
              "max_token_negative_log_likelihood": 5.928767681121826,
              "predictive_entropy": 0.030042181487218045,
              "shannon_entropy": 0.46888961685922936
            }
          },
          {
            "text": "It appears that the last name or the",
            "logprob": -9.599023930728436,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.215942144393921
              },
              {
                "text": "appears",
                "logprob": -0.8045260906219482
              },
              {
                "text": "that",
                "logprob": -0.19592666625976562
              },
              {
                "text": "the",
                "logprob": -0.08719824999570847
              },
              {
                "text": "last",
                "logprob": -1.1954412460327148
              },
              {
                "text": "name",
                "logprob": -2.021010398864746
              },
              {
                "text": "or",
                "logprob": -1.3315893411636353
              },
              {
                "text": "the",
                "logprob": -1.747389793395996
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.199877948500216,
              "max_token_negative_log_likelihood": 2.215942144393921,
              "predictive_entropy": 0.26601124182343483,
              "shannon_entropy": 1.245410829782486
            }
          }
        ],
        "cached": false,
        "request_time": 1.0175509452819824,
        "request_datetime": 1755803178
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Philip Sidney, 1st Baron De L\u2019Isle and Dudley used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id603"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nPhilip Sidney, 1st Baron De L\u2019Isle and Dudley used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Philip Sidney, 1st Baron",
            "logprob": -0.26755663443505995,
            "tokens": [
              {
                "text": "Philip",
                "logprob": -0.25264960527420044
              },
              {
                "text": "Sid",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "ney",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -2.3007127310847864e-05
              },
              {
                "text": "",
                "logprob": -0.014875796623528004
              },
              {
                "text": "1",
                "logprob": 0.0
              },
              {
                "text": "st",
                "logprob": 0.0
              },
              {
                "text": "Baron",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03344457332491935,
              "max_token_negative_log_likelihood": 0.25264957547187805,
              "predictive_entropy": 0.02636629909784105,
              "shannon_entropy": 0.11969925225033096
            }
          },
          {
            "text": "Philip Sidney, 1st Baron",
            "logprob": -0.26755663443505995,
            "tokens": [
              {
                "text": "Philip",
                "logprob": -0.25264960527420044
              },
              {
                "text": "Sid",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "ney",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -2.3007127310847864e-05
              },
              {
                "text": "",
                "logprob": -0.014875796623528004
              },
              {
                "text": "1",
                "logprob": 0.0
              },
              {
                "text": "st",
                "logprob": 0.0
              },
              {
                "text": "Baron",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03344457332491935,
              "max_token_negative_log_likelihood": 0.25264957547187805,
              "predictive_entropy": 0.02636629909784105,
              "shannon_entropy": 0.11969925225033096
            }
          },
          {
            "text": "Philip Sidney, 1st Baron",
            "logprob": -0.26755663443505995,
            "tokens": [
              {
                "text": "Philip",
                "logprob": -0.25264960527420044
              },
              {
                "text": "Sid",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "ney",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -2.3007127310847864e-05
              },
              {
                "text": "",
                "logprob": -0.014875796623528004
              },
              {
                "text": "1",
                "logprob": 0.0
              },
              {
                "text": "st",
                "logprob": 0.0
              },
              {
                "text": "Baron",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03344457332491935,
              "max_token_negative_log_likelihood": 0.25264957547187805,
              "predictive_entropy": 0.02636629909784105,
              "shannon_entropy": 0.11969925225033096
            }
          },
          {
            "text": "Philip Sidney, 1st Baron",
            "logprob": -0.26755663443505995,
            "tokens": [
              {
                "text": "Philip",
                "logprob": -0.25264960527420044
              },
              {
                "text": "Sid",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "ney",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -2.3007127310847864e-05
              },
              {
                "text": "",
                "logprob": -0.014875796623528004
              },
              {
                "text": "1",
                "logprob": 0.0
              },
              {
                "text": "st",
                "logprob": 0.0
              },
              {
                "text": "Baron",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03344457332491935,
              "max_token_negative_log_likelihood": 0.25264957547187805,
              "predictive_entropy": 0.02636629909784105,
              "shannon_entropy": 0.11969925225033096
            }
          },
          {
            "text": "Philip Sidney, 1st Baron",
            "logprob": -0.26755663443505995,
            "tokens": [
              {
                "text": "Philip",
                "logprob": -0.25264960527420044
              },
              {
                "text": "Sid",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "ney",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ",",
                "logprob": -2.3007127310847864e-05
              },
              {
                "text": "",
                "logprob": -0.014875796623528004
              },
              {
                "text": "1",
                "logprob": 0.0
              },
              {
                "text": "st",
                "logprob": 0.0
              },
              {
                "text": "Baron",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03344457332491935,
              "max_token_negative_log_likelihood": 0.25264957547187805,
              "predictive_entropy": 0.02636629909784105,
              "shannon_entropy": 0.11969925225033096
            }
          }
        ],
        "cached": false,
        "request_time": 1.0211608409881592,
        "request_datetime": 1755803178
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Jim Costa used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sacramento"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sac-Town"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sac"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Indomitable City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Trees"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Big Tomato"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Capitol City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sacramento, California"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Camellia City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "River City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sacramento"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sacramento"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id358"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJim Costa used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Given the information about where Henry St.",
            "logprob": -16.54898474916081,
            "tokens": [
              {
                "text": "Given",
                "logprob": -6.826992034912109
              },
              {
                "text": "the",
                "logprob": -0.2049776166677475
              },
              {
                "text": "information",
                "logprob": -3.6622936725616455
              },
              {
                "text": "about",
                "logprob": -1.104536533355713
              },
              {
                "text": "where",
                "logprob": -2.448265552520752
              },
              {
                "text": "Henry",
                "logprob": -2.301851511001587
              },
              {
                "text": "St",
                "logprob": -6.210611172718927e-05
              },
              {
                "text": ".",
                "logprob": -5.722029527532868e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 2.0686218424336857,
              "max_token_negative_log_likelihood": 6.826982498168945,
              "predictive_entropy": 0.13455948971818543,
              "shannon_entropy": 0.8810205124145796
            }
          },
          {
            "text": "Jim Costa used to work in Washington,",
            "logprob": -1.583210951223009,
            "tokens": [
              {
                "text": "Jim",
                "logprob": -0.014491898939013481
              },
              {
                "text": "Costa",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.013543154112994671
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.5748875486897305e-05
              },
              {
                "text": "in",
                "logprob": -6.258291978156194e-05
              },
              {
                "text": "Washington",
                "logprob": -1.5393972396850586
              },
              {
                "text": ",",
                "logprob": -0.015690326690673828
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.1979013560871863,
              "max_token_negative_log_likelihood": 1.539397120475769,
              "predictive_entropy": 0.04667442798859156,
              "shannon_entropy": 0.33082142198508135
            }
          },
          {
            "text": "Jim Costa used to work in Fres",
            "logprob": -3.73092115907275,
            "tokens": [
              {
                "text": "Jim",
                "logprob": -0.014491898939013481
              },
              {
                "text": "Costa",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.013543154112994671
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.5748875486897305e-05
              },
              {
                "text": "in",
                "logprob": -6.258291978156194e-05
              },
              {
                "text": "F",
                "logprob": -3.6956472396850586
              },
              {
                "text": "res",
                "logprob": -0.00715053454041481
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4663650830575534,
              "max_token_negative_log_likelihood": 3.6956467628479004,
              "predictive_entropy": 0.015825033192641058,
              "shannon_entropy": 0.3269633381259953
            }
          },
          {
            "text": "Jim Costa used to work in San Jose",
            "logprob": -3.321724957360857,
            "tokens": [
              {
                "text": "Jim",
                "logprob": -0.014491898939013481
              },
              {
                "text": "Costa",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.013543154112994671
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.5748875486897305e-05
              },
              {
                "text": "in",
                "logprob": -6.258291978156194e-05
              },
              {
                "text": "San",
                "logprob": -2.5081472396850586
              },
              {
                "text": "Jose",
                "logprob": -0.7854543328285217
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4152155889264577,
              "max_token_negative_log_likelihood": 2.5081470012664795,
              "predictive_entropy": 0.07375523349514879,
              "shannon_entropy": 0.48919431218927256
            }
          },
          {
            "text": "Jim Costa used to work in California,",
            "logprob": -2.0805193544765643,
            "tokens": [
              {
                "text": "Jim",
                "logprob": -0.014491898939013481
              },
              {
                "text": "Costa",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.013543154112994671
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -2.5748875486897305e-05
              },
              {
                "text": "in",
                "logprob": -6.258291978156194e-05
              },
              {
                "text": "California",
                "logprob": -1.7581472396850586
              },
              {
                "text": ",",
                "logprob": -0.2942487299442291
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.26006490346708233,
              "max_token_negative_log_likelihood": 1.758147120475769,
              "predictive_entropy": 0.06875199353567041,
              "shannon_entropy": 0.39900760451381556
            }
          }
        ],
        "cached": false,
        "request_time": 1.011869192123413,
        "request_datetime": 1755803179
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Israel Washburn used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Beantown"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Liberty"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Modern America"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Athens of America"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Walking City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub of the Universe"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bostonia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, Massachusetts"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, MA"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, Mass."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Puritan City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bostonian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Beantown"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Liberty"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id399"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nIsrael Washburn used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Israel Washburn used to work in",
            "logprob": -0.6773106972215146,
            "tokens": [
              {
                "text": "Israel",
                "logprob": -0.06654642522335052
              },
              {
                "text": "W",
                "logprob": 0.0
              },
              {
                "text": "ash",
                "logprob": 0.0
              },
              {
                "text": "burn",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "used",
                "logprob": -0.6103358864784241
              },
              {
                "text": "to",
                "logprob": -2.622600959512056e-06
              },
              {
                "text": "work",
                "logprob": -0.0002989322238136083
              },
              {
                "text": "in",
                "logprob": -0.00012635385792236775
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08466383634957708,
              "max_token_negative_log_likelihood": 0.6103358268737793,
              "predictive_entropy": 0.04927570319661356,
              "shannon_entropy": 0.2238927378018225
            }
          },
          {
            "text": "Israel Washburn, based on the",
            "logprob": -2.0727097021880354,
            "tokens": [
              {
                "text": "Israel",
                "logprob": -0.06654642522335052
              },
              {
                "text": "W",
                "logprob": 0.0
              },
              {
                "text": "ash",
                "logprob": 0.0
              },
              {
                "text": "burn",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": ",",
                "logprob": -1.5478358268737793
              },
              {
                "text": "based",
                "logprob": -0.42631837725639343
              },
              {
                "text": "on",
                "logprob": -0.0013669917825609446
              },
              {
                "text": "the",
                "logprob": -0.030641604214906693
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.25908872004949046,
              "max_token_negative_log_likelihood": 1.5478358268737793,
              "predictive_entropy": 0.0876160417246723,
              "shannon_entropy": 0.4232044641214152
            }
          },
          {
            "text": "Israel Washburn used to work in",
            "logprob": -0.6773106972215146,
            "tokens": [
              {
                "text": "Israel",
                "logprob": -0.06654642522335052
              },
              {
                "text": "W",
                "logprob": 0.0
              },
              {
                "text": "ash",
                "logprob": 0.0
              },
              {
                "text": "burn",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "used",
                "logprob": -0.6103358864784241
              },
              {
                "text": "to",
                "logprob": -2.622600959512056e-06
              },
              {
                "text": "work",
                "logprob": -0.0002989322238136083
              },
              {
                "text": "in",
                "logprob": -0.00012635385792236775
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08466383634957708,
              "max_token_negative_log_likelihood": 0.6103358268737793,
              "predictive_entropy": 0.04927570319661356,
              "shannon_entropy": 0.2238927378018225
            }
          },
          {
            "text": "Israel Washburn used to work in",
            "logprob": -0.6773106972215146,
            "tokens": [
              {
                "text": "Israel",
                "logprob": -0.06654642522335052
              },
              {
                "text": "W",
                "logprob": 0.0
              },
              {
                "text": "ash",
                "logprob": 0.0
              },
              {
                "text": "burn",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "used",
                "logprob": -0.6103358864784241
              },
              {
                "text": "to",
                "logprob": -2.622600959512056e-06
              },
              {
                "text": "work",
                "logprob": -0.0002989322238136083
              },
              {
                "text": "in",
                "logprob": -0.00012635385792236775
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08466383634957708,
              "max_token_negative_log_likelihood": 0.6103358268737793,
              "predictive_entropy": 0.04927570319661356,
              "shannon_entropy": 0.2238927378018225
            }
          },
          {
            "text": "Israel Washburn was presumably employed",
            "logprob": -15.639230932108944,
            "tokens": [
              {
                "text": "Israel",
                "logprob": -0.06654642522335052
              },
              {
                "text": "W",
                "logprob": 0.0
              },
              {
                "text": "ash",
                "logprob": 0.0
              },
              {
                "text": "burn",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "was",
                "logprob": -5.141585826873779
              },
              {
                "text": "pres",
                "logprob": -6.424051761627197
              },
              {
                "text": "umably",
                "logprob": -0.007850388996303082
              },
              {
                "text": "employed",
                "logprob": -3.9991960525512695
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.9549028538167619,
              "max_token_negative_log_likelihood": 6.424045562744141,
              "predictive_entropy": 0.0229810841847069,
              "shannon_entropy": 0.6687961850368147
            }
          }
        ],
        "cached": false,
        "request_time": 1.0074362754821777,
        "request_datetime": 1755803179
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Laurell K. Hamilton used to work in"
        },
        "references": [
          {
            "output": {
              "text": "St. Louis"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "St. Louis, Missouri"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of St. Louis"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "St. Louis City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Saint Louis"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "St Louis"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "St. Louis, MO"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "St. Louis"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "St. Louis"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id873"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nLaurell K. Hamilton used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Laurell K. Hamilton used to",
            "logprob": -0.07205449061061131,
            "tokens": [
              {
                "text": "La",
                "logprob": -0.013461061753332615
              },
              {
                "text": "ure",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "ll",
                "logprob": -2.455681169521995e-05
              },
              {
                "text": "K",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ".",
                "logprob": -0.0004737447015941143
              },
              {
                "text": "Hamilton",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.058094412088394165
              },
              {
                "text": "to",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.009006813028026528,
              "max_token_negative_log_likelihood": 0.058094434440135956,
              "predictive_entropy": 0.008574436679264608,
              "shannon_entropy": 0.051433422305435794
            }
          },
          {
            "text": "Laurell K. Hamilton used to",
            "logprob": -0.07205449061061131,
            "tokens": [
              {
                "text": "La",
                "logprob": -0.013461061753332615
              },
              {
                "text": "ure",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "ll",
                "logprob": -2.455681169521995e-05
              },
              {
                "text": "K",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ".",
                "logprob": -0.0004737447015941143
              },
              {
                "text": "Hamilton",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.058094412088394165
              },
              {
                "text": "to",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.009006813028026528,
              "max_token_negative_log_likelihood": 0.058094434440135956,
              "predictive_entropy": 0.008574436679264608,
              "shannon_entropy": 0.051433422305435794
            }
          },
          {
            "text": "Laurell K. Hamilton used to",
            "logprob": -0.07205449061061131,
            "tokens": [
              {
                "text": "La",
                "logprob": -0.013461061753332615
              },
              {
                "text": "ure",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "ll",
                "logprob": -2.455681169521995e-05
              },
              {
                "text": "K",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ".",
                "logprob": -0.0004737447015941143
              },
              {
                "text": "Hamilton",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.058094412088394165
              },
              {
                "text": "to",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.009006813028026528,
              "max_token_negative_log_likelihood": 0.058094434440135956,
              "predictive_entropy": 0.008574436679264608,
              "shannon_entropy": 0.051433422305435794
            }
          },
          {
            "text": "Laurell K. Hamilton used to",
            "logprob": -0.07205449061061131,
            "tokens": [
              {
                "text": "La",
                "logprob": -0.013461061753332615
              },
              {
                "text": "ure",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "ll",
                "logprob": -2.455681169521995e-05
              },
              {
                "text": "K",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ".",
                "logprob": -0.0004737447015941143
              },
              {
                "text": "Hamilton",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.058094412088394165
              },
              {
                "text": "to",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.009006813028026528,
              "max_token_negative_log_likelihood": 0.058094434440135956,
              "predictive_entropy": 0.008574436679264608,
              "shannon_entropy": 0.051433422305435794
            }
          },
          {
            "text": "Laurell K. Hamilton used to",
            "logprob": -0.07205449061061131,
            "tokens": [
              {
                "text": "La",
                "logprob": -0.013461061753332615
              },
              {
                "text": "ure",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "ll",
                "logprob": -2.455681169521995e-05
              },
              {
                "text": "K",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": ".",
                "logprob": -0.0004737447015941143
              },
              {
                "text": "Hamilton",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.058094412088394165
              },
              {
                "text": "to",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.009006813028026528,
              "max_token_negative_log_likelihood": 0.058094434440135956,
              "predictive_entropy": 0.008574436679264608,
              "shannon_entropy": 0.051433422305435794
            }
          }
        ],
        "cached": false,
        "request_time": 1.0032131671905518,
        "request_datetime": 1755803179
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Henry Crosby used to work in"
        },
        "references": [
          {
            "output": {
              "text": "South Australia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "SA"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "S.A."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "S. Aust."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "State of South Australia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Province of South Australia"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id242"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nHenry Crosby used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Based on the pattern provided, which lists",
            "logprob": -9.07683595494018,
            "tokens": [
              {
                "text": "Based",
                "logprob": -4.047602653503418
              },
              {
                "text": "on",
                "logprob": -0.00022671037004329264
              },
              {
                "text": "the",
                "logprob": -0.007026722654700279
              },
              {
                "text": "pattern",
                "logprob": -0.47676175832748413
              },
              {
                "text": "provided",
                "logprob": -1.0393260717391968
              },
              {
                "text": ",",
                "logprob": -0.26489174365997314
              },
              {
                "text": "which",
                "logprob": -1.782689094543457
              },
              {
                "text": "lists",
                "logprob": -1.4583112001419067
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1346044104539033,
              "max_token_negative_log_likelihood": 4.04760217666626,
              "predictive_entropy": 0.19797244154869986,
              "shannon_entropy": 1.067136415746063
            }
          },
          {
            "text": "Henry Crosby used to work in",
            "logprob": -0.08949642047809192,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -0.047602541744709015
              },
              {
                "text": "C",
                "logprob": 0.0
              },
              {
                "text": "ros",
                "logprob": 0.0
              },
              {
                "text": "by",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.04180280491709709
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -4.2199197196168825e-05
              },
              {
                "text": "in",
                "logprob": -4.875540980719961e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011187056805285422,
              "max_token_negative_log_likelihood": 0.047602567821741104,
              "predictive_entropy": 0.01069651005900596,
              "shannon_entropy": 0.05991186749848595
            }
          },
          {
            "text": "Henry Crosby used to work in",
            "logprob": -0.08949642047809192,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -0.047602541744709015
              },
              {
                "text": "C",
                "logprob": 0.0
              },
              {
                "text": "ros",
                "logprob": 0.0
              },
              {
                "text": "by",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.04180280491709709
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -4.2199197196168825e-05
              },
              {
                "text": "in",
                "logprob": -4.875540980719961e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011187056805285422,
              "max_token_negative_log_likelihood": 0.047602567821741104,
              "predictive_entropy": 0.01069651005900596,
              "shannon_entropy": 0.05991186749848595
            }
          },
          {
            "text": "Henry Crosby used to work in",
            "logprob": -0.08949642047809192,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -0.047602541744709015
              },
              {
                "text": "C",
                "logprob": 0.0
              },
              {
                "text": "ros",
                "logprob": 0.0
              },
              {
                "text": "by",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.04180280491709709
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -4.2199197196168825e-05
              },
              {
                "text": "in",
                "logprob": -4.875540980719961e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011187056805285422,
              "max_token_negative_log_likelihood": 0.047602567821741104,
              "predictive_entropy": 0.01069651005900596,
              "shannon_entropy": 0.05991186749848595
            }
          },
          {
            "text": "Henry Crosby used to work in",
            "logprob": -0.08949642047809192,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -0.047602541744709015
              },
              {
                "text": "C",
                "logprob": 0.0
              },
              {
                "text": "ros",
                "logprob": 0.0
              },
              {
                "text": "by",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.04180280491709709
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -4.2199197196168825e-05
              },
              {
                "text": "in",
                "logprob": -4.875540980719961e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.011187056805285422,
              "max_token_negative_log_likelihood": 0.047602567821741104,
              "predictive_entropy": 0.01069651005900596,
              "shannon_entropy": 0.05991186749848595
            }
          }
        ],
        "cached": false,
        "request_time": 1.011064052581787,
        "request_datetime": 1755803180
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "G\u00fcnter Kochan used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Berlin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berlin, Germany"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berlin (Germany)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DE-BE"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berliner"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berliners"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id724"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nG\u00fcnter Kochan used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "G\u00fcnter Kochan used to work in",
            "logprob": -0.18485484808476826,
            "tokens": [
              {
                "text": "G\u00fcn",
                "logprob": -0.10232022404670715
              },
              {
                "text": "ter",
                "logprob": -3.433168603805825e-05
              },
              {
                "text": "Koch",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08204806596040726
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.000276765669696033
              },
              {
                "text": "in",
                "logprob": -0.0001752223033690825
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.023106853738685373,
              "max_token_negative_log_likelihood": 0.10232023149728775,
              "predictive_entropy": 0.021054997780989737,
              "shannon_entropy": 0.09634416797027967
            }
          },
          {
            "text": "G\u00fcnter Kochan used to work in",
            "logprob": -0.18485484808476826,
            "tokens": [
              {
                "text": "G\u00fcn",
                "logprob": -0.10232022404670715
              },
              {
                "text": "ter",
                "logprob": -3.433168603805825e-05
              },
              {
                "text": "Koch",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08204806596040726
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.000276765669696033
              },
              {
                "text": "in",
                "logprob": -0.0001752223033690825
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.023106853738685373,
              "max_token_negative_log_likelihood": 0.10232023149728775,
              "predictive_entropy": 0.021054997780989737,
              "shannon_entropy": 0.09634416797027967
            }
          },
          {
            "text": "G\u00fcnter Kochan used to work in",
            "logprob": -0.18485484808476826,
            "tokens": [
              {
                "text": "G\u00fcn",
                "logprob": -0.10232022404670715
              },
              {
                "text": "ter",
                "logprob": -3.433168603805825e-05
              },
              {
                "text": "Koch",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08204806596040726
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.000276765669696033
              },
              {
                "text": "in",
                "logprob": -0.0001752223033690825
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.023106853738685373,
              "max_token_negative_log_likelihood": 0.10232023149728775,
              "predictive_entropy": 0.021054997780989737,
              "shannon_entropy": 0.09634416797027967
            }
          },
          {
            "text": "G\u00fcnter Kochan used to work in",
            "logprob": -0.18485484808476826,
            "tokens": [
              {
                "text": "G\u00fcn",
                "logprob": -0.10232022404670715
              },
              {
                "text": "ter",
                "logprob": -3.433168603805825e-05
              },
              {
                "text": "Koch",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08204806596040726
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.000276765669696033
              },
              {
                "text": "in",
                "logprob": -0.0001752223033690825
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.023106853738685373,
              "max_token_negative_log_likelihood": 0.10232023149728775,
              "predictive_entropy": 0.021054997780989737,
              "shannon_entropy": 0.09634416797027967
            }
          },
          {
            "text": "G\u00fcnter Kochan used to work in",
            "logprob": -0.18485484808476826,
            "tokens": [
              {
                "text": "G\u00fcn",
                "logprob": -0.10232022404670715
              },
              {
                "text": "ter",
                "logprob": -3.433168603805825e-05
              },
              {
                "text": "Koch",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08204806596040726
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.000276765669696033
              },
              {
                "text": "in",
                "logprob": -0.0001752223033690825
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.023106853738685373,
              "max_token_negative_log_likelihood": 0.10232023149728775,
              "predictive_entropy": 0.021054997780989737,
              "shannon_entropy": 0.09634416797027967
            }
          }
        ],
        "cached": false,
        "request_time": 1.006969690322876,
        "request_datetime": 1755803180
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "J\u00f6rg Jarnut used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Bonn"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bonn, Germany"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id623"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJ\u00f6rg Jarnut used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "J\u00f6rg Jarnut used to",
            "logprob": -0.5842900200923324,
            "tokens": [
              {
                "text": "J",
                "logprob": -0.5034623742103577
              },
              {
                "text": "\u00f6r",
                "logprob": -1.2278481335670222e-05
              },
              {
                "text": "g",
                "logprob": 0.0
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": "arn",
                "logprob": 0.0
              },
              {
                "text": "ut",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.08081524819135666
              },
              {
                "text": "to",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07303625625570653,
              "max_token_negative_log_likelihood": 0.5034623742103577,
              "predictive_entropy": 0.04735792613575995,
              "shannon_entropy": 0.19709778665870914
            }
          },
          {
            "text": "J\u00f6rg Jarnut used to",
            "logprob": -0.5842900200923324,
            "tokens": [
              {
                "text": "J",
                "logprob": -0.5034623742103577
              },
              {
                "text": "\u00f6r",
                "logprob": -1.2278481335670222e-05
              },
              {
                "text": "g",
                "logprob": 0.0
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": "arn",
                "logprob": 0.0
              },
              {
                "text": "ut",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.08081524819135666
              },
              {
                "text": "to",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07303625625570653,
              "max_token_negative_log_likelihood": 0.5034623742103577,
              "predictive_entropy": 0.04735792613575995,
              "shannon_entropy": 0.19709778665870914
            }
          },
          {
            "text": "J\u00f6rg Jarnut used to",
            "logprob": -0.5842900200923324,
            "tokens": [
              {
                "text": "J",
                "logprob": -0.5034623742103577
              },
              {
                "text": "\u00f6r",
                "logprob": -1.2278481335670222e-05
              },
              {
                "text": "g",
                "logprob": 0.0
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": "arn",
                "logprob": 0.0
              },
              {
                "text": "ut",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.08081524819135666
              },
              {
                "text": "to",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07303625625570653,
              "max_token_negative_log_likelihood": 0.5034623742103577,
              "predictive_entropy": 0.04735792613575995,
              "shannon_entropy": 0.19709778665870914
            }
          },
          {
            "text": "J\u00f6rg Jarnut used to",
            "logprob": -0.5842900200923324,
            "tokens": [
              {
                "text": "J",
                "logprob": -0.5034623742103577
              },
              {
                "text": "\u00f6r",
                "logprob": -1.2278481335670222e-05
              },
              {
                "text": "g",
                "logprob": 0.0
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": "arn",
                "logprob": 0.0
              },
              {
                "text": "ut",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.08081524819135666
              },
              {
                "text": "to",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07303625625570653,
              "max_token_negative_log_likelihood": 0.5034623742103577,
              "predictive_entropy": 0.04735792613575995,
              "shannon_entropy": 0.19709778665870914
            }
          },
          {
            "text": "J\u00f6rg Jarnut used to",
            "logprob": -0.5842900200923324,
            "tokens": [
              {
                "text": "J",
                "logprob": -0.5034623742103577
              },
              {
                "text": "\u00f6r",
                "logprob": -1.2278481335670222e-05
              },
              {
                "text": "g",
                "logprob": 0.0
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": "arn",
                "logprob": 0.0
              },
              {
                "text": "ut",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.08081524819135666
              },
              {
                "text": "to",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07303625625570653,
              "max_token_negative_log_likelihood": 0.5034623742103577,
              "predictive_entropy": 0.04735792613575995,
              "shannon_entropy": 0.19709778665870914
            }
          }
        ],
        "cached": false,
        "request_time": 1.0047099590301514,
        "request_datetime": 1755803180
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Leonid Pilunsky used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Crimea"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Kirim"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Q\u0131r\u0131m"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Kimmer\u00eda"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Taurik\u1e17"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "K\u0131r\u0131m"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Crimean Peninsula"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id984"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nLeonid Pilunsky used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Leonid Pilunsky used to work",
            "logprob": -0.07177089416063609,
            "tokens": [
              {
                "text": "Leon",
                "logprob": -0.05573571100831032
              },
              {
                "text": "id",
                "logprob": 0.0
              },
              {
                "text": "Pil",
                "logprob": -6.9141146923357155e-06
              },
              {
                "text": "un",
                "logprob": -1.9907753085135482e-05
              },
              {
                "text": "sky",
                "logprob": -4.291525328881107e-06
              },
              {
                "text": "used",
                "logprob": -0.01590811088681221
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.595887240720913e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00897136530767284,
              "max_token_negative_log_likelihood": 0.05573573708534241,
              "predictive_entropy": 0.008562295092986005,
              "shannon_entropy": 0.05322136930797061
            }
          },
          {
            "text": "Leonid Pilunsky used to work",
            "logprob": -0.07177089416063609,
            "tokens": [
              {
                "text": "Leon",
                "logprob": -0.05573571100831032
              },
              {
                "text": "id",
                "logprob": 0.0
              },
              {
                "text": "Pil",
                "logprob": -6.9141146923357155e-06
              },
              {
                "text": "un",
                "logprob": -1.9907753085135482e-05
              },
              {
                "text": "sky",
                "logprob": -4.291525328881107e-06
              },
              {
                "text": "used",
                "logprob": -0.01590811088681221
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.595887240720913e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00897136530767284,
              "max_token_negative_log_likelihood": 0.05573573708534241,
              "predictive_entropy": 0.008562295092986005,
              "shannon_entropy": 0.05322136930797061
            }
          },
          {
            "text": "Leonid Pilunsky used to work",
            "logprob": -0.07177089416063609,
            "tokens": [
              {
                "text": "Leon",
                "logprob": -0.05573571100831032
              },
              {
                "text": "id",
                "logprob": 0.0
              },
              {
                "text": "Pil",
                "logprob": -6.9141146923357155e-06
              },
              {
                "text": "un",
                "logprob": -1.9907753085135482e-05
              },
              {
                "text": "sky",
                "logprob": -4.291525328881107e-06
              },
              {
                "text": "used",
                "logprob": -0.01590811088681221
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.595887240720913e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00897136530767284,
              "max_token_negative_log_likelihood": 0.05573573708534241,
              "predictive_entropy": 0.008562295092986005,
              "shannon_entropy": 0.05322136930797061
            }
          },
          {
            "text": "Leonid Pilunsky used to work",
            "logprob": -0.07177089416063609,
            "tokens": [
              {
                "text": "Leon",
                "logprob": -0.05573571100831032
              },
              {
                "text": "id",
                "logprob": 0.0
              },
              {
                "text": "Pil",
                "logprob": -6.9141146923357155e-06
              },
              {
                "text": "un",
                "logprob": -1.9907753085135482e-05
              },
              {
                "text": "sky",
                "logprob": -4.291525328881107e-06
              },
              {
                "text": "used",
                "logprob": -0.01590811088681221
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.595887240720913e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00897136530767284,
              "max_token_negative_log_likelihood": 0.05573573708534241,
              "predictive_entropy": 0.008562295092986005,
              "shannon_entropy": 0.05322136930797061
            }
          },
          {
            "text": "Leonid Pilunsky used to work",
            "logprob": -0.07177089416063609,
            "tokens": [
              {
                "text": "Leon",
                "logprob": -0.05573571100831032
              },
              {
                "text": "id",
                "logprob": 0.0
              },
              {
                "text": "Pil",
                "logprob": -6.9141146923357155e-06
              },
              {
                "text": "un",
                "logprob": -1.9907753085135482e-05
              },
              {
                "text": "sky",
                "logprob": -4.291525328881107e-06
              },
              {
                "text": "used",
                "logprob": -0.01590811088681221
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.595887240720913e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00897136530767284,
              "max_token_negative_log_likelihood": 0.05573573708534241,
              "predictive_entropy": 0.008562295092986005,
              "shannon_entropy": 0.05322136930797061
            }
          }
        ],
        "cached": false,
        "request_time": 1.007004976272583,
        "request_datetime": 1755803180
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "George Washington Warren used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Beantown"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Liberty"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Modern America"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Athens of America"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Walking City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub of the Universe"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bostonia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, Massachusetts"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, MA"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston, Mass."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Puritan City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Boston"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bostonian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Beantown"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hub"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Cradle of Liberty"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id875"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nGeorge Washington Warren used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "George Washington Warren used to work in Washington",
            "logprob": -4.359322659249067,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.22102567553520203
              },
              {
                "text": "Washington",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Warren",
                "logprob": -0.0018553201807662845
              },
              {
                "text": "used",
                "logprob": -0.08236297965049744
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              },
              {
                "text": "in",
                "logprob": -0.00014244495832826942
              },
              {
                "text": "Washington",
                "logprob": -4.053844451904297
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5449152139727094,
              "max_token_negative_log_likelihood": 4.0538434982299805,
              "predictive_entropy": 0.040686159747536976,
              "shannon_entropy": 0.32472310773391655
            }
          },
          {
            "text": "George Washington Warren used to work in Boston",
            "logprob": -0.6718224506328099,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.22102567553520203
              },
              {
                "text": "Washington",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Warren",
                "logprob": -0.0018553201807662845
              },
              {
                "text": "used",
                "logprob": -0.08236297965049744
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              },
              {
                "text": "in",
                "logprob": -0.00014244495832826942
              },
              {
                "text": "Boston",
                "logprob": -0.36634424328804016
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08397780337967653,
              "max_token_negative_log_likelihood": 0.3663442134857178,
              "predictive_entropy": 0.06363824883371194,
              "shannon_entropy": 0.32472310773391655
            }
          },
          {
            "text": "George Washington Warren used to work in Boston",
            "logprob": -0.6718224506328099,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.22102567553520203
              },
              {
                "text": "Washington",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Warren",
                "logprob": -0.0018553201807662845
              },
              {
                "text": "used",
                "logprob": -0.08236297965049744
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              },
              {
                "text": "in",
                "logprob": -0.00014244495832826942
              },
              {
                "text": "Boston",
                "logprob": -0.36634424328804016
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08397780337967653,
              "max_token_negative_log_likelihood": 0.3663442134857178,
              "predictive_entropy": 0.06363824883371194,
              "shannon_entropy": 0.32472310773391655
            }
          },
          {
            "text": "George Washington Warren used to work in Boston",
            "logprob": -0.6718224506328099,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.22102567553520203
              },
              {
                "text": "Washington",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Warren",
                "logprob": -0.0018553201807662845
              },
              {
                "text": "used",
                "logprob": -0.08236297965049744
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              },
              {
                "text": "in",
                "logprob": -0.00014244495832826942
              },
              {
                "text": "Boston",
                "logprob": -0.36634424328804016
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08397780337967653,
              "max_token_negative_log_likelihood": 0.3663442134857178,
              "predictive_entropy": 0.06363824883371194,
              "shannon_entropy": 0.32472310773391655
            }
          },
          {
            "text": "George Washington Warren used to work in Cambridge",
            "logprob": -3.1718224208304875,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.22102567553520203
              },
              {
                "text": "Washington",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Warren",
                "logprob": -0.0018553201807662845
              },
              {
                "text": "used",
                "logprob": -0.08236297965049744
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -9.095255518332124e-05
              },
              {
                "text": "in",
                "logprob": -0.00014244495832826942
              },
              {
                "text": "Cambridge",
                "logprob": -2.8663442134857178
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.39647777357735414,
              "max_token_negative_log_likelihood": 2.8663439750671387,
              "predictive_entropy": 0.05228081660240491,
              "shannon_entropy": 0.32472310773391655
            }
          }
        ],
        "cached": false,
        "request_time": 1.0103280544281006,
        "request_datetime": 1755803181
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Rub\u00e9n Arellano used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Mexico City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mexico D.F."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ciudad de M\u00e9xico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Mexico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mexico City, Mexico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "CDMX"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mexico"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "capitalino"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id575"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nRub\u00e9n Arellano used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Rub\u00e9n Arellano, as with",
            "logprob": -9.157774642040742,
            "tokens": [
              {
                "text": "Rub",
                "logprob": -0.19011850655078888
              },
              {
                "text": "\u00e9n",
                "logprob": -9.894321920000948e-06
              },
              {
                "text": "Are",
                "logprob": -6.318072337307967e-06
              },
              {
                "text": "ll",
                "logprob": 0.0
              },
              {
                "text": "ano",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ",",
                "logprob": -4.178463935852051
              },
              {
                "text": "as",
                "logprob": -3.062073230743408
              },
              {
                "text": "with",
                "logprob": -1.7271026372909546
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1447217557665699,
              "max_token_negative_log_likelihood": 4.178463459014893,
              "predictive_entropy": 0.08394917751729736,
              "shannon_entropy": 0.6414626537997183
            }
          },
          {
            "text": "It seems you've left part of",
            "logprob": -14.199398040721462,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.5651185512542725
              },
              {
                "text": "seems",
                "logprob": -0.5628209710121155
              },
              {
                "text": "you",
                "logprob": -2.6316137313842773
              },
              {
                "text": "'",
                "logprob": -0.5292014479637146
              },
              {
                "text": "ve",
                "logprob": -0.0916743278503418
              },
              {
                "text": "left",
                "logprob": -3.8848259449005127
              },
              {
                "text": "part",
                "logprob": -3.9341330528259277
              },
              {
                "text": "of",
                "logprob": -1.0013530300057027e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.7749246470692697,
              "max_token_negative_log_likelihood": 3.9341325759887695,
              "predictive_entropy": 0.15742962247998094,
              "shannon_entropy": 0.7442272571533977
            }
          },
          {
            "text": "Rub\u00e9n Arellano used to work",
            "logprob": -0.21240251919878972,
            "tokens": [
              {
                "text": "Rub",
                "logprob": -0.19011850655078888
              },
              {
                "text": "\u00e9n",
                "logprob": -9.894321920000948e-06
              },
              {
                "text": "Are",
                "logprob": -6.318072337307967e-06
              },
              {
                "text": "ll",
                "logprob": 0.0
              },
              {
                "text": "ano",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.02221403829753399
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -5.352353764465079e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02655031737095115,
              "max_token_negative_log_likelihood": 0.19011850655078888,
              "predictive_entropy": 0.022374701032731537,
              "shannon_entropy": 0.11521137508927137
            }
          },
          {
            "text": "Rub\u00e9n Arellano used to work",
            "logprob": -0.21240251919878972,
            "tokens": [
              {
                "text": "Rub",
                "logprob": -0.19011850655078888
              },
              {
                "text": "\u00e9n",
                "logprob": -9.894321920000948e-06
              },
              {
                "text": "Are",
                "logprob": -6.318072337307967e-06
              },
              {
                "text": "ll",
                "logprob": 0.0
              },
              {
                "text": "ano",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.02221403829753399
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -5.352353764465079e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02655031737095115,
              "max_token_negative_log_likelihood": 0.19011850655078888,
              "predictive_entropy": 0.022374701032731537,
              "shannon_entropy": 0.11521137508927137
            }
          },
          {
            "text": "Rub\u00e9n Arellano used to work",
            "logprob": -0.21240251919878972,
            "tokens": [
              {
                "text": "Rub",
                "logprob": -0.19011850655078888
              },
              {
                "text": "\u00e9n",
                "logprob": -9.894321920000948e-06
              },
              {
                "text": "Are",
                "logprob": -6.318072337307967e-06
              },
              {
                "text": "ll",
                "logprob": 0.0
              },
              {
                "text": "ano",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.02221403829753399
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -5.352353764465079e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02655031737095115,
              "max_token_negative_log_likelihood": 0.19011850655078888,
              "predictive_entropy": 0.022374701032731537,
              "shannon_entropy": 0.11521137508927137
            }
          }
        ],
        "cached": false,
        "request_time": 1.0114567279815674,
        "request_datetime": 1755803181
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Francisque Joseph Duret used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Love"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paree"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lutetia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paris, France"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisians"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id942"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nFrancisque Joseph Duret used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Francisque Joseph Duret used to",
            "logprob": -0.09740552992274587,
            "tokens": [
              {
                "text": "Francis",
                "logprob": -0.06142953410744667
              },
              {
                "text": "que",
                "logprob": -3.433168603805825e-05
              },
              {
                "text": "Joseph",
                "logprob": 0.0
              },
              {
                "text": "D",
                "logprob": 0.0
              },
              {
                "text": "ure",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "t",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.035940829664468765
              },
              {
                "text": "to",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.012175694647377,
              "max_token_negative_log_likelihood": 0.061429549008607864,
              "predictive_entropy": 0.01155959062359102,
              "shannon_entropy": 0.07050721037955299
            }
          },
          {
            "text": "Francisque Joseph Duret used to",
            "logprob": -0.09740552992274587,
            "tokens": [
              {
                "text": "Francis",
                "logprob": -0.06142953410744667
              },
              {
                "text": "que",
                "logprob": -3.433168603805825e-05
              },
              {
                "text": "Joseph",
                "logprob": 0.0
              },
              {
                "text": "D",
                "logprob": 0.0
              },
              {
                "text": "ure",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "t",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.035940829664468765
              },
              {
                "text": "to",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.012175694647377,
              "max_token_negative_log_likelihood": 0.061429549008607864,
              "predictive_entropy": 0.01155959062359102,
              "shannon_entropy": 0.07050721037955299
            }
          },
          {
            "text": "Francisque Joseph Duret used to",
            "logprob": -0.09740552992274587,
            "tokens": [
              {
                "text": "Francis",
                "logprob": -0.06142953410744667
              },
              {
                "text": "que",
                "logprob": -3.433168603805825e-05
              },
              {
                "text": "Joseph",
                "logprob": 0.0
              },
              {
                "text": "D",
                "logprob": 0.0
              },
              {
                "text": "ure",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "t",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.035940829664468765
              },
              {
                "text": "to",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.012175694647377,
              "max_token_negative_log_likelihood": 0.061429549008607864,
              "predictive_entropy": 0.01155959062359102,
              "shannon_entropy": 0.07050721037955299
            }
          },
          {
            "text": "Francisque Joseph Duret used to",
            "logprob": -0.09740552992274587,
            "tokens": [
              {
                "text": "Francis",
                "logprob": -0.06142953410744667
              },
              {
                "text": "que",
                "logprob": -3.433168603805825e-05
              },
              {
                "text": "Joseph",
                "logprob": 0.0
              },
              {
                "text": "D",
                "logprob": 0.0
              },
              {
                "text": "ure",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "t",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.035940829664468765
              },
              {
                "text": "to",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.012175694647377,
              "max_token_negative_log_likelihood": 0.061429549008607864,
              "predictive_entropy": 0.01155959062359102,
              "shannon_entropy": 0.07050721037955299
            }
          },
          {
            "text": "Francisque Joseph Duret used to",
            "logprob": -0.09740552992274587,
            "tokens": [
              {
                "text": "Francis",
                "logprob": -0.06142953410744667
              },
              {
                "text": "que",
                "logprob": -3.433168603805825e-05
              },
              {
                "text": "Joseph",
                "logprob": 0.0
              },
              {
                "text": "D",
                "logprob": 0.0
              },
              {
                "text": "ure",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "t",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.035940829664468765
              },
              {
                "text": "to",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.012175694647377,
              "max_token_negative_log_likelihood": 0.061429549008607864,
              "predictive_entropy": 0.01155959062359102,
              "shannon_entropy": 0.07050721037955299
            }
          }
        ],
        "cached": false,
        "request_time": 1.0094141960144043,
        "request_datetime": 1755803181
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Edith Summerskill, Baroness Summerskill used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id722"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nEdith Summerskill, Baroness Summerskill used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Edith Summerskill, Baroness",
            "logprob": -0.023803659478119243,
            "tokens": [
              {
                "text": "Ed",
                "logprob": -0.023588858544826508
              },
              {
                "text": "ith",
                "logprob": 0.0
              },
              {
                "text": "Sum",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "mers",
                "logprob": 0.0
              },
              {
                "text": "kill",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -5.4834770708112046e-05
              },
              {
                "text": "Baron",
                "logprob": -0.00015937011630740017
              },
              {
                "text": "ess",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00297545982223113,
              "max_token_negative_log_likelihood": 0.02358884923160076,
              "predictive_entropy": 0.0029067160494165023,
              "shannon_entropy": 0.019536577177324377
            }
          },
          {
            "text": "Edith Summerskill, Baroness",
            "logprob": -0.023803659478119243,
            "tokens": [
              {
                "text": "Ed",
                "logprob": -0.023588858544826508
              },
              {
                "text": "ith",
                "logprob": 0.0
              },
              {
                "text": "Sum",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "mers",
                "logprob": 0.0
              },
              {
                "text": "kill",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -5.4834770708112046e-05
              },
              {
                "text": "Baron",
                "logprob": -0.00015937011630740017
              },
              {
                "text": "ess",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00297545982223113,
              "max_token_negative_log_likelihood": 0.02358884923160076,
              "predictive_entropy": 0.0029067160494165023,
              "shannon_entropy": 0.019536577177324377
            }
          },
          {
            "text": "Edith Summerskill, Baroness",
            "logprob": -0.023803659478119243,
            "tokens": [
              {
                "text": "Ed",
                "logprob": -0.023588858544826508
              },
              {
                "text": "ith",
                "logprob": 0.0
              },
              {
                "text": "Sum",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "mers",
                "logprob": 0.0
              },
              {
                "text": "kill",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -5.4834770708112046e-05
              },
              {
                "text": "Baron",
                "logprob": -0.00015937011630740017
              },
              {
                "text": "ess",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00297545982223113,
              "max_token_negative_log_likelihood": 0.02358884923160076,
              "predictive_entropy": 0.0029067160494165023,
              "shannon_entropy": 0.019536577177324377
            }
          },
          {
            "text": "Edith Summerskill, Baroness",
            "logprob": -0.023803659478119243,
            "tokens": [
              {
                "text": "Ed",
                "logprob": -0.023588858544826508
              },
              {
                "text": "ith",
                "logprob": 0.0
              },
              {
                "text": "Sum",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "mers",
                "logprob": 0.0
              },
              {
                "text": "kill",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -5.4834770708112046e-05
              },
              {
                "text": "Baron",
                "logprob": -0.00015937011630740017
              },
              {
                "text": "ess",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00297545982223113,
              "max_token_negative_log_likelihood": 0.02358884923160076,
              "predictive_entropy": 0.0029067160494165023,
              "shannon_entropy": 0.019536577177324377
            }
          },
          {
            "text": "Edith Summerskill, Baroness",
            "logprob": -0.023803659478119243,
            "tokens": [
              {
                "text": "Ed",
                "logprob": -0.023588858544826508
              },
              {
                "text": "ith",
                "logprob": 0.0
              },
              {
                "text": "Sum",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "mers",
                "logprob": 0.0
              },
              {
                "text": "kill",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -5.4834770708112046e-05
              },
              {
                "text": "Baron",
                "logprob": -0.00015937011630740017
              },
              {
                "text": "ess",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.00297545982223113,
              "max_token_negative_log_likelihood": 0.02358884923160076,
              "predictive_entropy": 0.0029067160494165023,
              "shannon_entropy": 0.019536577177324377
            }
          }
        ],
        "cached": false,
        "request_time": 1.0126557350158691,
        "request_datetime": 1755803181
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "George Devereux used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Love"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paree"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lutetia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paris, France"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisians"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id108"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nGeorge Devereux used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "George Devereux used to work in",
            "logprob": -0.1755223219086588,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.12806423008441925
              },
              {
                "text": "De",
                "logprob": -3.111314072157256e-05
              },
              {
                "text": "vere",
                "logprob": -5.8412379075889476e-06
              },
              {
                "text": "ux",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.04716676101088524
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00013600854435935616
              },
              {
                "text": "in",
                "logprob": -0.00011777184408856556
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02194029627380445,
              "max_token_negative_log_likelihood": 0.12806423008441925,
              "predictive_entropy": 0.019744445347136264,
              "shannon_entropy": 0.1029853992144325
            }
          },
          {
            "text": "George Devereux used to work in",
            "logprob": -0.1755223219086588,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.12806423008441925
              },
              {
                "text": "De",
                "logprob": -3.111314072157256e-05
              },
              {
                "text": "vere",
                "logprob": -5.8412379075889476e-06
              },
              {
                "text": "ux",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.04716676101088524
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00013600854435935616
              },
              {
                "text": "in",
                "logprob": -0.00011777184408856556
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02194029627380445,
              "max_token_negative_log_likelihood": 0.12806423008441925,
              "predictive_entropy": 0.019744445347136264,
              "shannon_entropy": 0.1029853992144325
            }
          },
          {
            "text": "George Devereux used to work in",
            "logprob": -0.1755223219086588,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.12806423008441925
              },
              {
                "text": "De",
                "logprob": -3.111314072157256e-05
              },
              {
                "text": "vere",
                "logprob": -5.8412379075889476e-06
              },
              {
                "text": "ux",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.04716676101088524
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00013600854435935616
              },
              {
                "text": "in",
                "logprob": -0.00011777184408856556
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02194029627380445,
              "max_token_negative_log_likelihood": 0.12806423008441925,
              "predictive_entropy": 0.019744445347136264,
              "shannon_entropy": 0.1029853992144325
            }
          },
          {
            "text": "George Devereux used to work in",
            "logprob": -0.1755223219086588,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.12806423008441925
              },
              {
                "text": "De",
                "logprob": -3.111314072157256e-05
              },
              {
                "text": "vere",
                "logprob": -5.8412379075889476e-06
              },
              {
                "text": "ux",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.04716676101088524
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00013600854435935616
              },
              {
                "text": "in",
                "logprob": -0.00011777184408856556
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02194029627380445,
              "max_token_negative_log_likelihood": 0.12806423008441925,
              "predictive_entropy": 0.019744445347136264,
              "shannon_entropy": 0.1029853992144325
            }
          },
          {
            "text": "George Devereux used to work in",
            "logprob": -0.1755223219086588,
            "tokens": [
              {
                "text": "George",
                "logprob": -0.12806423008441925
              },
              {
                "text": "De",
                "logprob": -3.111314072157256e-05
              },
              {
                "text": "vere",
                "logprob": -5.8412379075889476e-06
              },
              {
                "text": "ux",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.04716676101088524
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00013600854435935616
              },
              {
                "text": "in",
                "logprob": -0.00011777184408856556
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.02194029627380445,
              "max_token_negative_log_likelihood": 0.12806423008441925,
              "predictive_entropy": 0.019744445347136264,
              "shannon_entropy": 0.1029853992144325
            }
          }
        ],
        "cached": false,
        "request_time": 1.0092732906341553,
        "request_datetime": 1755803182
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Francine Raynault used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Ottawa"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ottawa (Ontario)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bytown"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Ottawa"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ottawan"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id871"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nFrancine Raynault used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Francine Raynault used to work",
            "logprob": -0.36503199041791845,
            "tokens": [
              {
                "text": "Franc",
                "logprob": -0.34464654326438904
              },
              {
                "text": "ine",
                "logprob": 0.0
              },
              {
                "text": "Ray",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "na",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "ult",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.02034229412674904
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -3.814624506048858e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04562900108173196,
              "max_token_negative_log_likelihood": 0.3446465730667114,
              "predictive_entropy": 0.03301847670340052,
              "shannon_entropy": 0.17091743703819162
            }
          },
          {
            "text": "It seems that the sentence for Francine",
            "logprob": -8.458953758934506,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.844646453857422
              },
              {
                "text": "seems",
                "logprob": -0.5897500514984131
              },
              {
                "text": "that",
                "logprob": -0.8786382079124451
              },
              {
                "text": "the",
                "logprob": -0.0841643437743187
              },
              {
                "text": "sentence",
                "logprob": -2.547368288040161
              },
              {
                "text": "for",
                "logprob": -1.5107016563415527
              },
              {
                "text": "Franc",
                "logprob": -0.003684638300910592
              },
              {
                "text": "ine",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0573691799945681,
              "max_token_negative_log_likelihood": 2.844646453857422,
              "predictive_entropy": 0.18391632672864944,
              "shannon_entropy": 0.8915420262103737
            }
          },
          {
            "text": "Francine Raynault used to work",
            "logprob": -0.36503199041791845,
            "tokens": [
              {
                "text": "Franc",
                "logprob": -0.34464654326438904
              },
              {
                "text": "ine",
                "logprob": 0.0
              },
              {
                "text": "Ray",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "na",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "ult",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "used",
                "logprob": -0.02034229412674904
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -3.814624506048858e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.04562900108173196,
              "max_token_negative_log_likelihood": 0.3446465730667114,
              "predictive_entropy": 0.03301847670340052,
              "shannon_entropy": 0.17091743703819162
            }
          },
          {
            "text": "Assuming that the pattern involves filling in the",
            "logprob": -14.76742748171091,
            "tokens": [
              {
                "text": "Assuming",
                "logprob": -4.407146453857422
              },
              {
                "text": "that",
                "logprob": -1.1764640808105469
              },
              {
                "text": "the",
                "logprob": -0.30248796939849854
              },
              {
                "text": "pattern",
                "logprob": -1.1907930374145508
              },
              {
                "text": "involves",
                "logprob": -1.685666799545288
              },
              {
                "text": "filling",
                "logprob": -5.487735271453857
              },
              {
                "text": "in",
                "logprob": -0.040687479078769684
              },
              {
                "text": "the",
                "logprob": -0.47644639015197754
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.845928062684834,
              "max_token_negative_log_likelihood": 5.487732887268066,
              "predictive_entropy": 0.20900495699606836,
              "shannon_entropy": 1.569408841431141
            }
          },
          {
            "text": "Based on the information given, it seems",
            "logprob": -9.863897894363618,
            "tokens": [
              {
                "text": "Based",
                "logprob": -2.688396453857422
              },
              {
                "text": "on",
                "logprob": -0.0002269487304147333
              },
              {
                "text": "the",
                "logprob": -0.006638378370553255
              },
              {
                "text": "information",
                "logprob": -3.3310108184814453
              },
              {
                "text": "given",
                "logprob": -2.31758189201355
              },
              {
                "text": ",",
                "logprob": -0.34801429510116577
              },
              {
                "text": "it",
                "logprob": -0.3224922716617584
              },
              {
                "text": "seems",
                "logprob": -0.8495368361473083
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.2329871899146383,
              "max_token_negative_log_likelihood": 3.331010580062866,
              "predictive_entropy": 0.17245210536566447,
              "shannon_entropy": 0.7717780044768006
            }
          }
        ],
        "cached": false,
        "request_time": 1.0107553005218506,
        "request_datetime": 1755803182
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Irene Dische used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Berlin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berlin, Germany"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berlin (Germany)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DE-BE"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berliner"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berliners"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id480"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nIrene Dische used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Irene Dische used to work in",
            "logprob": -0.1185947841795496,
            "tokens": [
              {
                "text": "I",
                "logprob": -0.02143724448978901
              },
              {
                "text": "rene",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "D",
                "logprob": 0.0
              },
              {
                "text": "ische",
                "logprob": -0.05052010715007782
              },
              {
                "text": "used",
                "logprob": -0.04627709835767746
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00011681827891152352
              },
              {
                "text": "in",
                "logprob": -0.00023946279543451965
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014824353870722007,
              "max_token_negative_log_likelihood": 0.05052012577652931,
              "predictive_entropy": 0.0141948046956486,
              "shannon_entropy": 0.0767235600779379
            }
          },
          {
            "text": "Irene Dische used to work in",
            "logprob": -0.1185947841795496,
            "tokens": [
              {
                "text": "I",
                "logprob": -0.02143724448978901
              },
              {
                "text": "rene",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "D",
                "logprob": 0.0
              },
              {
                "text": "ische",
                "logprob": -0.05052010715007782
              },
              {
                "text": "used",
                "logprob": -0.04627709835767746
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00011681827891152352
              },
              {
                "text": "in",
                "logprob": -0.00023946279543451965
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014824353870722007,
              "max_token_negative_log_likelihood": 0.05052012577652931,
              "predictive_entropy": 0.0141948046956486,
              "shannon_entropy": 0.0767235600779379
            }
          },
          {
            "text": "Irene Dische used to work in",
            "logprob": -0.1185947841795496,
            "tokens": [
              {
                "text": "I",
                "logprob": -0.02143724448978901
              },
              {
                "text": "rene",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "D",
                "logprob": 0.0
              },
              {
                "text": "ische",
                "logprob": -0.05052010715007782
              },
              {
                "text": "used",
                "logprob": -0.04627709835767746
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00011681827891152352
              },
              {
                "text": "in",
                "logprob": -0.00023946279543451965
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014824353870722007,
              "max_token_negative_log_likelihood": 0.05052012577652931,
              "predictive_entropy": 0.0141948046956486,
              "shannon_entropy": 0.0767235600779379
            }
          },
          {
            "text": "Irene Dische used to work in",
            "logprob": -0.1185947841795496,
            "tokens": [
              {
                "text": "I",
                "logprob": -0.02143724448978901
              },
              {
                "text": "rene",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "D",
                "logprob": 0.0
              },
              {
                "text": "ische",
                "logprob": -0.05052010715007782
              },
              {
                "text": "used",
                "logprob": -0.04627709835767746
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00011681827891152352
              },
              {
                "text": "in",
                "logprob": -0.00023946279543451965
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014824353870722007,
              "max_token_negative_log_likelihood": 0.05052012577652931,
              "predictive_entropy": 0.0141948046956486,
              "shannon_entropy": 0.0767235600779379
            }
          },
          {
            "text": "Irene Dische used to work in",
            "logprob": -0.1185947841795496,
            "tokens": [
              {
                "text": "I",
                "logprob": -0.02143724448978901
              },
              {
                "text": "rene",
                "logprob": -4.0531076592742465e-06
              },
              {
                "text": "D",
                "logprob": 0.0
              },
              {
                "text": "ische",
                "logprob": -0.05052010715007782
              },
              {
                "text": "used",
                "logprob": -0.04627709835767746
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00011681827891152352
              },
              {
                "text": "in",
                "logprob": -0.00023946279543451965
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.014824353870722007,
              "max_token_negative_log_likelihood": 0.05052012577652931,
              "predictive_entropy": 0.0141948046956486,
              "shannon_entropy": 0.0767235600779379
            }
          }
        ],
        "cached": false,
        "request_time": 1.0089726448059082,
        "request_datetime": 1755803182
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Avshalom Vilan used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Jerusalem"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Yerushalayim"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "J'lem"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Aelia Capitolina"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Al-Quds"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Jerusalem, Middle East"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Jerusalemite"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id653"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nAvshalom Vilan used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Henry St. John, also known as",
            "logprob": -4.737996917217622,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -3.1940371990203857
              },
              {
                "text": "St",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": ".",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "John",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ",",
                "logprob": -0.19031503796577454
              },
              {
                "text": "also",
                "logprob": -1.3326090574264526
              },
              {
                "text": "known",
                "logprob": -0.003926070407032967
              },
              {
                "text": "as",
                "logprob": -0.017108241096138954
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.592249577690426,
              "max_token_negative_log_likelihood": 3.1940369606018066,
              "predictive_entropy": 0.0825705349561332,
              "shannon_entropy": 0.5944321946191593
            }
          },
          {
            "text": "Avshalom Vilan used to work",
            "logprob": -0.721564390811011,
            "tokens": [
              {
                "text": "Av",
                "logprob": -0.4127872586250305
              },
              {
                "text": "sh",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "alom",
                "logprob": 0.0
              },
              {
                "text": "Vil",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "an",
                "logprob": -0.00017379203927703202
              },
              {
                "text": "used",
                "logprob": -0.30832645297050476
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.0002681849291548133
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09019554300018484,
              "max_token_negative_log_likelihood": 0.4127872586250305,
              "predictive_entropy": 0.06251928689355069,
              "shannon_entropy": 0.29212516059561633
            }
          },
          {
            "text": "Avshalom Vilan, based on",
            "logprob": -3.242558831812744,
            "tokens": [
              {
                "text": "Av",
                "logprob": -0.4127872586250305
              },
              {
                "text": "sh",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "alom",
                "logprob": 0.0
              },
              {
                "text": "Vil",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "an",
                "logprob": -0.00017379203927703202
              },
              {
                "text": ",",
                "logprob": -2.183326482772827
              },
              {
                "text": "based",
                "logprob": -0.6451268196105957
              },
              {
                "text": "on",
                "logprob": -0.0011361341457813978
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.40531985519761804,
              "max_token_negative_log_likelihood": 2.183326482772827,
              "predictive_entropy": 0.1073648365415778,
              "shannon_entropy": 0.5196797002992062
            }
          },
          {
            "text": "Avshalom Vilan used to work",
            "logprob": -0.721564390811011,
            "tokens": [
              {
                "text": "Av",
                "logprob": -0.4127872586250305
              },
              {
                "text": "sh",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "alom",
                "logprob": 0.0
              },
              {
                "text": "Vil",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "an",
                "logprob": -0.00017379203927703202
              },
              {
                "text": "used",
                "logprob": -0.30832645297050476
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.0002681849291548133
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09019554300018484,
              "max_token_negative_log_likelihood": 0.4127872586250305,
              "predictive_entropy": 0.06251928689355069,
              "shannon_entropy": 0.29212516059561633
            }
          },
          {
            "text": "Avshalom Vilan used to work",
            "logprob": -0.721564390811011,
            "tokens": [
              {
                "text": "Av",
                "logprob": -0.4127872586250305
              },
              {
                "text": "sh",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "alom",
                "logprob": 0.0
              },
              {
                "text": "Vil",
                "logprob": -7.867782187531702e-06
              },
              {
                "text": "an",
                "logprob": -0.00017379203927703202
              },
              {
                "text": "used",
                "logprob": -0.30832645297050476
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.0002681849291548133
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09019554300018484,
              "max_token_negative_log_likelihood": 0.4127872586250305,
              "predictive_entropy": 0.06251928689355069,
              "shannon_entropy": 0.29212516059561633
            }
          }
        ],
        "cached": false,
        "request_time": 1.0117683410644531,
        "request_datetime": 1755803182
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "David Daggett used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id962"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nDavid Daggett used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "David Daggett used to work",
            "logprob": -0.27474870689907505,
            "tokens": [
              {
                "text": "David",
                "logprob": -0.18522925674915314
              },
              {
                "text": "D",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ag",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "get",
                "logprob": 0.0
              },
              {
                "text": "t",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08935566991567612
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00016330339713022113
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03434358797131409,
              "max_token_negative_log_likelihood": 0.18522924184799194,
              "predictive_entropy": 0.029473859081914355,
              "shannon_entropy": 0.14582908261900762
            }
          },
          {
            "text": "David Daggett used to work",
            "logprob": -0.27474870689907505,
            "tokens": [
              {
                "text": "David",
                "logprob": -0.18522925674915314
              },
              {
                "text": "D",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ag",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "get",
                "logprob": 0.0
              },
              {
                "text": "t",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08935566991567612
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00016330339713022113
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03434358797131409,
              "max_token_negative_log_likelihood": 0.18522924184799194,
              "predictive_entropy": 0.029473859081914355,
              "shannon_entropy": 0.14582908261900762
            }
          },
          {
            "text": "David Daggett used to work",
            "logprob": -0.27474870689907505,
            "tokens": [
              {
                "text": "David",
                "logprob": -0.18522925674915314
              },
              {
                "text": "D",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ag",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "get",
                "logprob": 0.0
              },
              {
                "text": "t",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08935566991567612
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00016330339713022113
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03434358797131409,
              "max_token_negative_log_likelihood": 0.18522924184799194,
              "predictive_entropy": 0.029473859081914355,
              "shannon_entropy": 0.14582908261900762
            }
          },
          {
            "text": "David Daggett used to work",
            "logprob": -0.27474870689907505,
            "tokens": [
              {
                "text": "David",
                "logprob": -0.18522925674915314
              },
              {
                "text": "D",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ag",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "get",
                "logprob": 0.0
              },
              {
                "text": "t",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.08935566991567612
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00016330339713022113
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03434358797131409,
              "max_token_negative_log_likelihood": 0.18522924184799194,
              "predictive_entropy": 0.029473859081914355,
              "shannon_entropy": 0.14582908261900762
            }
          },
          {
            "text": "David Daggett, based on",
            "logprob": -4.025051283533649,
            "tokens": [
              {
                "text": "David",
                "logprob": -0.18522925674915314
              },
              {
                "text": "D",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ag",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "get",
                "logprob": 0.0
              },
              {
                "text": "t",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -2.901855707168579
              },
              {
                "text": "based",
                "logprob": -0.936404824256897
              },
              {
                "text": "on",
                "logprob": -0.0015611377311870456
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5031313779472892,
              "max_token_negative_log_likelihood": 2.90185546875,
              "predictive_entropy": 0.08524315303656849,
              "shannon_entropy": 0.38175033967730165
            }
          }
        ],
        "cached": false,
        "request_time": 1.0085277557373047,
        "request_datetime": 1755803183
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Martin Brau\u00df used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Hanover"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Hannover"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Hanover, Germany"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id244"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nMartin Brau\u00df used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "It appears that the information for \"Martin",
            "logprob": -7.658467978239052,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.014298439025879
              },
              {
                "text": "appears",
                "logprob": -0.8375210165977478
              },
              {
                "text": "that",
                "logprob": -0.2093883752822876
              },
              {
                "text": "the",
                "logprob": -0.15030530095100403
              },
              {
                "text": "information",
                "logprob": -1.0032027959823608
              },
              {
                "text": "for",
                "logprob": -1.259771704673767
              },
              {
                "text": "\"",
                "logprob": -2.1839802265167236
              },
              {
                "text": "Martin",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.9573085103184003,
              "max_token_negative_log_likelihood": 2.1839802265167236,
              "predictive_entropy": 0.23769477382302284,
              "shannon_entropy": 0.9311984712405632
            }
          },
          {
            "text": "Martin Brau\u00df used to work in Frankfurt",
            "logprob": -3.346636934034791,
            "tokens": [
              {
                "text": "Martin",
                "logprob": -0.45179855823516846
              },
              {
                "text": "Bra",
                "logprob": -3.802703940891661e-05
              },
              {
                "text": "u\u00df",
                "logprob": -0.00045753977610729635
              },
              {
                "text": "used",
                "logprob": -0.07202368974685669
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "work",
                "logprob": -0.0002097863471135497
              },
              {
                "text": "in",
                "logprob": -0.00013219437096267939
              },
              {
                "text": "Frankfurt",
                "logprob": -2.821976661682129
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.41832961725732787,
              "max_token_negative_log_likelihood": 2.821976661682129,
              "predictive_entropy": 0.06541157954823973,
              "shannon_entropy": 0.32041794376254984
            }
          },
          {
            "text": "Martin Brau\u00df used to work in Berlin",
            "logprob": -0.7528870383429194,
            "tokens": [
              {
                "text": "Martin",
                "logprob": -0.45179855823516846
              },
              {
                "text": "Bra",
                "logprob": -3.802703940891661e-05
              },
              {
                "text": "u\u00df",
                "logprob": -0.00045753977610729635
              },
              {
                "text": "used",
                "logprob": -0.07202368974685669
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "work",
                "logprob": -0.0002097863471135497
              },
              {
                "text": "in",
                "logprob": -0.00013219437096267939
              },
              {
                "text": "Berlin",
                "logprob": -0.22822676599025726
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09411088215848906,
              "max_token_negative_log_likelihood": 0.45179858803749084,
              "predictive_entropy": 0.06713423946392538,
              "shannon_entropy": 0.32041794376254984
            }
          },
          {
            "text": "Martin Brau\u00df used to work in Berlin",
            "logprob": -0.7528870383429194,
            "tokens": [
              {
                "text": "Martin",
                "logprob": -0.45179855823516846
              },
              {
                "text": "Bra",
                "logprob": -3.802703940891661e-05
              },
              {
                "text": "u\u00df",
                "logprob": -0.00045753977610729635
              },
              {
                "text": "used",
                "logprob": -0.07202368974685669
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "work",
                "logprob": -0.0002097863471135497
              },
              {
                "text": "in",
                "logprob": -0.00013219437096267939
              },
              {
                "text": "Berlin",
                "logprob": -0.22822676599025726
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09411088215848906,
              "max_token_negative_log_likelihood": 0.45179858803749084,
              "predictive_entropy": 0.06713423946392538,
              "shannon_entropy": 0.32041794376254984
            }
          },
          {
            "text": "Martin Brau\u00df used to work in Berlin",
            "logprob": -0.7528870383429194,
            "tokens": [
              {
                "text": "Martin",
                "logprob": -0.45179855823516846
              },
              {
                "text": "Bra",
                "logprob": -3.802703940891661e-05
              },
              {
                "text": "u\u00df",
                "logprob": -0.00045753977610729635
              },
              {
                "text": "used",
                "logprob": -0.07202368974685669
              },
              {
                "text": "to",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "work",
                "logprob": -0.0002097863471135497
              },
              {
                "text": "in",
                "logprob": -0.00013219437096267939
              },
              {
                "text": "Berlin",
                "logprob": -0.22822676599025726
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09411088215848906,
              "max_token_negative_log_likelihood": 0.45179858803749084,
              "predictive_entropy": 0.06713423946392538,
              "shannon_entropy": 0.32041794376254984
            }
          }
        ],
        "cached": false,
        "request_time": 1.0117278099060059,
        "request_datetime": 1755803183
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Felix Schreiner used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Lauchringen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Stuttgart"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berlin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berlin, Germany"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berlin (Germany)"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DE-BE"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berliner"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Berliners"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id245"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nFelix Schreiner used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Felix Schreiner used to work in",
            "logprob": -0.06486506960935401,
            "tokens": [
              {
                "text": "Felix",
                "logprob": -0.034036099910736084
              },
              {
                "text": "Sch",
                "logprob": 0.0
              },
              {
                "text": "re",
                "logprob": 0.0
              },
              {
                "text": "iner",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.03063848242163658
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00010597144137136638
              },
              {
                "text": "in",
                "logprob": -8.427741704508662e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.008108134363286723,
              "max_token_negative_log_likelihood": 0.034036070108413696,
              "predictive_entropy": 0.00785020135299419,
              "shannon_entropy": 0.04821245005814617
            }
          },
          {
            "text": "Felix Schreiner used to work in",
            "logprob": -0.06486506960935401,
            "tokens": [
              {
                "text": "Felix",
                "logprob": -0.034036099910736084
              },
              {
                "text": "Sch",
                "logprob": 0.0
              },
              {
                "text": "re",
                "logprob": 0.0
              },
              {
                "text": "iner",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.03063848242163658
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00010597144137136638
              },
              {
                "text": "in",
                "logprob": -8.427741704508662e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.008108134363286723,
              "max_token_negative_log_likelihood": 0.034036070108413696,
              "predictive_entropy": 0.00785020135299419,
              "shannon_entropy": 0.04821245005814617
            }
          },
          {
            "text": "Felix Schreiner used to work in",
            "logprob": -0.06486506960935401,
            "tokens": [
              {
                "text": "Felix",
                "logprob": -0.034036099910736084
              },
              {
                "text": "Sch",
                "logprob": 0.0
              },
              {
                "text": "re",
                "logprob": 0.0
              },
              {
                "text": "iner",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.03063848242163658
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00010597144137136638
              },
              {
                "text": "in",
                "logprob": -8.427741704508662e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.008108134363286723,
              "max_token_negative_log_likelihood": 0.034036070108413696,
              "predictive_entropy": 0.00785020135299419,
              "shannon_entropy": 0.04821245005814617
            }
          },
          {
            "text": "Felix Schreiner used to work in",
            "logprob": -0.06486506960935401,
            "tokens": [
              {
                "text": "Felix",
                "logprob": -0.034036099910736084
              },
              {
                "text": "Sch",
                "logprob": 0.0
              },
              {
                "text": "re",
                "logprob": 0.0
              },
              {
                "text": "iner",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.03063848242163658
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00010597144137136638
              },
              {
                "text": "in",
                "logprob": -8.427741704508662e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.008108134363286723,
              "max_token_negative_log_likelihood": 0.034036070108413696,
              "predictive_entropy": 0.00785020135299419,
              "shannon_entropy": 0.04821245005814617
            }
          },
          {
            "text": "Felix Schreiner used to work in",
            "logprob": -0.06486506960935401,
            "tokens": [
              {
                "text": "Felix",
                "logprob": -0.034036099910736084
              },
              {
                "text": "Sch",
                "logprob": 0.0
              },
              {
                "text": "re",
                "logprob": 0.0
              },
              {
                "text": "iner",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.03063848242163658
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.00010597144137136638
              },
              {
                "text": "in",
                "logprob": -8.427741704508662e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.008108134363286723,
              "max_token_negative_log_likelihood": 0.034036070108413696,
              "predictive_entropy": 0.00785020135299419,
              "shannon_entropy": 0.04821245005814617
            }
          }
        ],
        "cached": false,
        "request_time": 1.0085532665252686,
        "request_datetime": 1755803183
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Alexander Babakov used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Moscow"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moskva"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow, Russia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moskva Federal City, Russia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow, USSR"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moskva, Russia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Moscow"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow, Russian Federation"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow, Soviet Union"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow, Russian SFSR"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Muscovite"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscovite"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Muscovite"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Moscow"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id411"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nAlexander Babakov used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Alexander Babakov used to work in Moscow",
            "logprob": -0.5812332458080434,
            "tokens": [
              {
                "text": "Alexander",
                "logprob": -0.19861888885498047
              },
              {
                "text": "Bab",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "akov",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.019574448466300964
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.589452510117553e-05
              },
              {
                "text": "in",
                "logprob": -5.006664650863968e-05
              },
              {
                "text": "Moscow",
                "logprob": -0.36294347047805786
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07265414722270158,
              "max_token_negative_log_likelihood": 0.3629434406757355,
              "predictive_entropy": 0.05432554654861477,
              "shannon_entropy": 0.23474725839695054
            }
          },
          {
            "text": "Alexander Babakov used to work in Moscow",
            "logprob": -0.5812332458080434,
            "tokens": [
              {
                "text": "Alexander",
                "logprob": -0.19861888885498047
              },
              {
                "text": "Bab",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "akov",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.019574448466300964
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.589452510117553e-05
              },
              {
                "text": "in",
                "logprob": -5.006664650863968e-05
              },
              {
                "text": "Moscow",
                "logprob": -0.36294347047805786
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07265414722270158,
              "max_token_negative_log_likelihood": 0.3629434406757355,
              "predictive_entropy": 0.05432554654861477,
              "shannon_entropy": 0.23474725839695054
            }
          },
          {
            "text": "\"Saint Petersburg, Russia\"\n\n",
            "logprob": -12.981508602113536,
            "tokens": [
              {
                "text": "\"",
                "logprob": -8.82361888885498
              },
              {
                "text": "Saint",
                "logprob": -2.379594326019287
              },
              {
                "text": "Petersburg",
                "logprob": -0.00580731313675642
              },
              {
                "text": ",",
                "logprob": -0.09179440140724182
              },
              {
                "text": "Russia",
                "logprob": -0.0011692361440509558
              },
              {
                "text": "\"",
                "logprob": -1.6293988227844238
              },
              {
                "text": "\n",
                "logprob": -0.05011643469333649
              },
              {
                "text": "\n",
                "logprob": -9.179073458653875e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.6226801104692186,
              "max_token_negative_log_likelihood": 8.823551177978516,
              "predictive_entropy": 0.08492765975290695,
              "shannon_entropy": 0.5621170778358646
            }
          },
          {
            "text": "Alexander Babakov used to work in Saint",
            "logprob": -1.9249831862033986,
            "tokens": [
              {
                "text": "Alexander",
                "logprob": -0.19861888885498047
              },
              {
                "text": "Bab",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "akov",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.019574448466300964
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.589452510117553e-05
              },
              {
                "text": "in",
                "logprob": -5.006664650863968e-05
              },
              {
                "text": "Saint",
                "logprob": -1.706693410873413
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2406228785962501,
              "max_token_negative_log_likelihood": 1.7066932916641235,
              "predictive_entropy": 0.06147954560900715,
              "shannon_entropy": 0.23474725839695054
            }
          },
          {
            "text": "Alexander Babakov used to work in Moscow",
            "logprob": -0.5812332458080434,
            "tokens": [
              {
                "text": "Alexander",
                "logprob": -0.19861888885498047
              },
              {
                "text": "Bab",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "akov",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.019574448466300964
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -4.589452510117553e-05
              },
              {
                "text": "in",
                "logprob": -5.006664650863968e-05
              },
              {
                "text": "Moscow",
                "logprob": -0.36294347047805786
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.07265414722270158,
              "max_token_negative_log_likelihood": 0.3629434406757355,
              "predictive_entropy": 0.05432554654861477,
              "shannon_entropy": 0.23474725839695054
            }
          }
        ],
        "cached": false,
        "request_time": 1.0037407875061035,
        "request_datetime": 1755803183
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Jacobus Josephus Eeckhout used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Antwerp"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Antwerpen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Antwerp"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Anvers"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The Hague"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Den Haag"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "'s-Gravenhage"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Haag"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Hague"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mechelen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mechlin"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Malines"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Mechlinian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Brussels"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Brussels City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Brussels, Belgium"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bruxelles"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Brussel"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Stad Brussel"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ville de Bruxelles"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "02"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "BXL"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bru"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Brussels"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Love"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paree"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lutetia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paris, France"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisians"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id490"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJacobus Josephus Eeckhout used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Jacobus Josephus Eeckh",
            "logprob": -0.05992693082723122,
            "tokens": [
              {
                "text": "Jacob",
                "logprob": -0.05977459251880646
              },
              {
                "text": "us",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Joseph",
                "logprob": -2.0265558760002023e-06
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "E",
                "logprob": -0.00014935807848814875
              },
              {
                "text": "e",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ck",
                "logprob": 0.0
              },
              {
                "text": "h",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.007490868212993718,
              "max_token_negative_log_likelihood": 0.05977458506822586,
              "predictive_entropy": 0.0070573268491749275,
              "shannon_entropy": 0.0431318481786664
            }
          },
          {
            "text": "Based on the pattern of the initial list",
            "logprob": -10.760023000533693,
            "tokens": [
              {
                "text": "Based",
                "logprob": -4.278524398803711
              },
              {
                "text": "on",
                "logprob": -0.00029309268575161695
              },
              {
                "text": "the",
                "logprob": -0.012388304807245731
              },
              {
                "text": "pattern",
                "logprob": -0.43936407566070557
              },
              {
                "text": "of",
                "logprob": -1.0054974555969238
              },
              {
                "text": "the",
                "logprob": -0.6495076417922974
              },
              {
                "text": "initial",
                "logprob": -3.8883233070373535
              },
              {
                "text": "list",
                "logprob": -0.486124724149704
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3450027690414572,
              "max_token_negative_log_likelihood": 4.278523921966553,
              "predictive_entropy": 0.18008790093881544,
              "shannon_entropy": 1.1916570973407943
            }
          },
          {
            "text": "Jacobus Josephus Eeckh",
            "logprob": -0.05992693082723122,
            "tokens": [
              {
                "text": "Jacob",
                "logprob": -0.05977459251880646
              },
              {
                "text": "us",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Joseph",
                "logprob": -2.0265558760002023e-06
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "E",
                "logprob": -0.00014935807848814875
              },
              {
                "text": "e",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ck",
                "logprob": 0.0
              },
              {
                "text": "h",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.007490868212993718,
              "max_token_negative_log_likelihood": 0.05977458506822586,
              "predictive_entropy": 0.0070573268491749275,
              "shannon_entropy": 0.0431318481786664
            }
          },
          {
            "text": "Jacobus Josephus Eeckh",
            "logprob": -0.05992693082723122,
            "tokens": [
              {
                "text": "Jacob",
                "logprob": -0.05977459251880646
              },
              {
                "text": "us",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Joseph",
                "logprob": -2.0265558760002023e-06
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "E",
                "logprob": -0.00014935807848814875
              },
              {
                "text": "e",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ck",
                "logprob": 0.0
              },
              {
                "text": "h",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.007490868212993718,
              "max_token_negative_log_likelihood": 0.05977458506822586,
              "predictive_entropy": 0.0070573268491749275,
              "shannon_entropy": 0.0431318481786664
            }
          },
          {
            "text": "Jacobus Josephus Eeckh",
            "logprob": -0.05992693082723122,
            "tokens": [
              {
                "text": "Jacob",
                "logprob": -0.05977459251880646
              },
              {
                "text": "us",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "Joseph",
                "logprob": -2.0265558760002023e-06
              },
              {
                "text": "us",
                "logprob": 0.0
              },
              {
                "text": "E",
                "logprob": -0.00014935807848814875
              },
              {
                "text": "e",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ck",
                "logprob": 0.0
              },
              {
                "text": "h",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.007490868212993718,
              "max_token_negative_log_likelihood": 0.05977458506822586,
              "predictive_entropy": 0.0070573268491749275,
              "shannon_entropy": 0.0431318481786664
            }
          }
        ],
        "cached": false,
        "request_time": 1.0182650089263916,
        "request_datetime": 1755803184
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Walter Monslow, Baron Monslow used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id835"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nWalter Monslow, Baron Monslow used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Walter Monslow, Baron Mons",
            "logprob": -0.5595242128678919,
            "tokens": [
              {
                "text": "Walter",
                "logprob": -0.5590425729751587
              },
              {
                "text": "M",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ons",
                "logprob": 0.0
              },
              {
                "text": "low",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": ",",
                "logprob": -7.450303382938728e-05
              },
              {
                "text": "Baron",
                "logprob": -0.0004051103023812175
              },
              {
                "text": "M",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ons",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06994051801411239,
              "max_token_negative_log_likelihood": 0.5590425133705139,
              "predictive_entropy": 0.04001468850200851,
              "shannon_entropy": 0.18718763245236328
            }
          },
          {
            "text": "It appears that the provided information includes profession",
            "logprob": -15.942131400108337,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.590292453765869
              },
              {
                "text": "appears",
                "logprob": -0.6113986372947693
              },
              {
                "text": "that",
                "logprob": -0.17993655800819397
              },
              {
                "text": "the",
                "logprob": -0.1527557373046875
              },
              {
                "text": "provided",
                "logprob": -3.0911521911621094
              },
              {
                "text": "information",
                "logprob": -0.36901214718818665
              },
              {
                "text": "includes",
                "logprob": -4.444030284881592
              },
              {
                "text": "profession",
                "logprob": -4.50355339050293
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.99276614934206,
              "max_token_negative_log_likelihood": 4.503552436828613,
              "predictive_entropy": 0.1631404967047274,
              "shannon_entropy": 1.4464933797717094
            }
          },
          {
            "text": "Walter Monslow, Baron Mons",
            "logprob": -0.5595242128678919,
            "tokens": [
              {
                "text": "Walter",
                "logprob": -0.5590425729751587
              },
              {
                "text": "M",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ons",
                "logprob": 0.0
              },
              {
                "text": "low",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": ",",
                "logprob": -7.450303382938728e-05
              },
              {
                "text": "Baron",
                "logprob": -0.0004051103023812175
              },
              {
                "text": "M",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ons",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06994051801411239,
              "max_token_negative_log_likelihood": 0.5590425133705139,
              "predictive_entropy": 0.04001468850200851,
              "shannon_entropy": 0.18718763245236328
            }
          },
          {
            "text": "Walter Monslow, Baron Mons",
            "logprob": -0.5595242128678919,
            "tokens": [
              {
                "text": "Walter",
                "logprob": -0.5590425729751587
              },
              {
                "text": "M",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ons",
                "logprob": 0.0
              },
              {
                "text": "low",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": ",",
                "logprob": -7.450303382938728e-05
              },
              {
                "text": "Baron",
                "logprob": -0.0004051103023812175
              },
              {
                "text": "M",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ons",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06994051801411239,
              "max_token_negative_log_likelihood": 0.5590425133705139,
              "predictive_entropy": 0.04001468850200851,
              "shannon_entropy": 0.18718763245236328
            }
          },
          {
            "text": "Walter Monslow, Baron Mons",
            "logprob": -0.5595242128678919,
            "tokens": [
              {
                "text": "Walter",
                "logprob": -0.5590425729751587
              },
              {
                "text": "M",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ons",
                "logprob": 0.0
              },
              {
                "text": "low",
                "logprob": -1.6689286894688848e-06
              },
              {
                "text": ",",
                "logprob": -7.450303382938728e-05
              },
              {
                "text": "Baron",
                "logprob": -0.0004051103023812175
              },
              {
                "text": "M",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ons",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.06994051801411239,
              "max_token_negative_log_likelihood": 0.5590425133705139,
              "predictive_entropy": 0.04001468850200851,
              "shannon_entropy": 0.18718763245236328
            }
          }
        ],
        "cached": false,
        "request_time": 1.0141329765319824,
        "request_datetime": 1755803184
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Samuel H. Woodson used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id642"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nSamuel H. Woodson used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Samuel H. Woodson used to work",
            "logprob": -0.24745462004737107,
            "tokens": [
              {
                "text": "Samuel",
                "logprob": -0.08015244454145432
              },
              {
                "text": "H",
                "logprob": -1.311301275563892e-06
              },
              {
                "text": ".",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "Wood",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "son",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.1670496016740799
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.0002475670480635017
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030931820267971588,
              "max_token_negative_log_likelihood": 0.1670495718717575,
              "predictive_entropy": 0.026947689136378017,
              "shannon_entropy": 0.14318917206186654
            }
          },
          {
            "text": "Samuel H. Woodson used to work",
            "logprob": -0.24745462004737107,
            "tokens": [
              {
                "text": "Samuel",
                "logprob": -0.08015244454145432
              },
              {
                "text": "H",
                "logprob": -1.311301275563892e-06
              },
              {
                "text": ".",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "Wood",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "son",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.1670496016740799
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.0002475670480635017
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030931820267971588,
              "max_token_negative_log_likelihood": 0.1670495718717575,
              "predictive_entropy": 0.026947689136378017,
              "shannon_entropy": 0.14318917206186654
            }
          },
          {
            "text": "Samuel H. Woodson used to work",
            "logprob": -0.24745462004737107,
            "tokens": [
              {
                "text": "Samuel",
                "logprob": -0.08015244454145432
              },
              {
                "text": "H",
                "logprob": -1.311301275563892e-06
              },
              {
                "text": ".",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "Wood",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "son",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.1670496016740799
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.0002475670480635017
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030931820267971588,
              "max_token_negative_log_likelihood": 0.1670495718717575,
              "predictive_entropy": 0.026947689136378017,
              "shannon_entropy": 0.14318917206186654
            }
          },
          {
            "text": "Samuel H. Woodson used to work",
            "logprob": -0.24745462004737107,
            "tokens": [
              {
                "text": "Samuel",
                "logprob": -0.08015244454145432
              },
              {
                "text": "H",
                "logprob": -1.311301275563892e-06
              },
              {
                "text": ".",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "Wood",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "son",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.1670496016740799
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.0002475670480635017
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030931820267971588,
              "max_token_negative_log_likelihood": 0.1670495718717575,
              "predictive_entropy": 0.026947689136378017,
              "shannon_entropy": 0.14318917206186654
            }
          },
          {
            "text": "Samuel H. Woodson used to work",
            "logprob": -0.24745462004737107,
            "tokens": [
              {
                "text": "Samuel",
                "logprob": -0.08015244454145432
              },
              {
                "text": "H",
                "logprob": -1.311301275563892e-06
              },
              {
                "text": ".",
                "logprob": -3.3378546504536644e-06
              },
              {
                "text": "Wood",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "son",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "used",
                "logprob": -0.1670496016740799
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "work",
                "logprob": -0.0002475670480635017
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.030931820267971588,
              "max_token_negative_log_likelihood": 0.1670495718717575,
              "predictive_entropy": 0.026947689136378017,
              "shannon_entropy": 0.14318917206186654
            }
          }
        ],
        "cached": false,
        "request_time": 1.0099518299102783,
        "request_datetime": 1755803184
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Simon Emil Ammitzb\u00f8ll used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Copenhagen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "K\u00f8benhavn"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "CPH"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "K\u00f6penhamn"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "K\u00f6\u00f6penhamina"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Kopenhagen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Kobenhavn"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "K\u00f6benhavn"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Hafnia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Hafn"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Havn"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Copenhagen, Denmark"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id134"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nSimon Emil Ammitzb\u00f8ll used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Simon Emil Ammitzb\u00f8ll",
            "logprob": -0.3006410866885574,
            "tokens": [
              {
                "text": "Simon",
                "logprob": -0.3005397617816925
              },
              {
                "text": "Emil",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "Am",
                "logprob": 0.0
              },
              {
                "text": "mit",
                "logprob": -2.3483953555114567e-05
              },
              {
                "text": "z",
                "logprob": 0.0
              },
              {
                "text": "b",
                "logprob": -7.354942499659956e-05
              },
              {
                "text": "\u00f8",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "ll",
                "logprob": -3.4570634852570947e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03758014030867329,
              "max_token_negative_log_likelihood": 0.3005397915840149,
              "predictive_entropy": 0.027828316762114724,
              "shannon_entropy": 0.13311046738013488
            }
          },
          {
            "text": "Based on the provided information, Simon Emil",
            "logprob": -8.205193844215387,
            "tokens": [
              {
                "text": "Based",
                "logprob": -2.33178973197937
              },
              {
                "text": "on",
                "logprob": -0.00024959311122074723
              },
              {
                "text": "the",
                "logprob": -0.02235020510852337
              },
              {
                "text": "provided",
                "logprob": -2.2183542251586914
              },
              {
                "text": "information",
                "logprob": -0.6531527042388916
              },
              {
                "text": ",",
                "logprob": -0.21216295659542084
              },
              {
                "text": "Simon",
                "logprob": -2.7671329975128174
              },
              {
                "text": "Emil",
                "logprob": -1.4305104514278355e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0256491796391316,
              "max_token_negative_log_likelihood": 2.7671327590942383,
              "predictive_entropy": 0.1469129587711535,
              "shannon_entropy": 0.7707303431998298
            }
          },
          {
            "text": "From the incomplete sentence provided, it seems",
            "logprob": -11.722008260898292,
            "tokens": [
              {
                "text": "From",
                "logprob": -6.144289970397949
              },
              {
                "text": "the",
                "logprob": -0.00613816361874342
              },
              {
                "text": "incomplete",
                "logprob": -2.396956205368042
              },
              {
                "text": "sentence",
                "logprob": -0.7762433886528015
              },
              {
                "text": "provided",
                "logprob": -0.8704521059989929
              },
              {
                "text": ",",
                "logprob": -0.6220932602882385
              },
              {
                "text": "it",
                "logprob": -0.14690734446048737
              },
              {
                "text": "seems",
                "logprob": -0.7589278221130371
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.4652504188125022,
              "max_token_negative_log_likelihood": 6.144285202026367,
              "predictive_entropy": 0.2218967565568164,
              "shannon_entropy": 1.0969809386879206
            }
          },
          {
            "text": "Sim\u00f3n Emil Ammitzb\u00f8",
            "logprob": -4.691011481994792,
            "tokens": [
              {
                "text": "Sim",
                "logprob": -4.394289970397949
              },
              {
                "text": "\u00f3n",
                "logprob": -0.11593246459960938
              },
              {
                "text": "Emil",
                "logprob": -0.16330304741859436
              },
              {
                "text": "Am",
                "logprob": -0.008311208337545395
              },
              {
                "text": "mit",
                "logprob": -0.00030322244856506586
              },
              {
                "text": "z",
                "logprob": -1.811964830267243e-05
              },
              {
                "text": "b",
                "logprob": -0.008774297311902046
              },
              {
                "text": "\u00f8",
                "logprob": -7.915183232398704e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5863763111278786,
              "max_token_negative_log_likelihood": 4.394289016723633,
              "predictive_entropy": 0.03919253662684241,
              "shannon_entropy": 0.261632718887995
            }
          },
          {
            "text": "Simon Emil Ammitzb\u00f8ll",
            "logprob": -0.3006410866885574,
            "tokens": [
              {
                "text": "Simon",
                "logprob": -0.3005397617816925
              },
              {
                "text": "Emil",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "Am",
                "logprob": 0.0
              },
              {
                "text": "mit",
                "logprob": -2.3483953555114567e-05
              },
              {
                "text": "z",
                "logprob": 0.0
              },
              {
                "text": "b",
                "logprob": -7.354942499659956e-05
              },
              {
                "text": "\u00f8",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "ll",
                "logprob": -3.4570634852570947e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03758014030867329,
              "max_token_negative_log_likelihood": 0.3005397915840149,
              "predictive_entropy": 0.027828316762114724,
              "shannon_entropy": 0.13311046738013488
            }
          }
        ],
        "cached": false,
        "request_time": 1.0096783638000488,
        "request_datetime": 1755803184
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Eleanor Wadsworth used to work in"
        },
        "references": [
          {
            "output": {
              "text": "White Waltham Airfield"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "EGLM"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id894"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nEleanor Wadsworth used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Eleanor Wadsworth used",
            "logprob": -0.2980060912668634,
            "tokens": [
              {
                "text": "Ele",
                "logprob": -0.27433282136917114
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "W",
                "logprob": 0.0
              },
              {
                "text": "ad",
                "logprob": 0.0
              },
              {
                "text": "sw",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "orth",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.023673150688409805
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.037250755354763854,
              "max_token_negative_log_likelihood": 0.27433279156684875,
              "predictive_entropy": 0.028954253997653723,
              "shannon_entropy": 0.15267957919383823
            }
          },
          {
            "text": "Eleanor Wadsworth used",
            "logprob": -0.2980060912668634,
            "tokens": [
              {
                "text": "Ele",
                "logprob": -0.27433282136917114
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "W",
                "logprob": 0.0
              },
              {
                "text": "ad",
                "logprob": 0.0
              },
              {
                "text": "sw",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "orth",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.023673150688409805
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.037250755354763854,
              "max_token_negative_log_likelihood": 0.27433279156684875,
              "predictive_entropy": 0.028954253997653723,
              "shannon_entropy": 0.15267957919383823
            }
          },
          {
            "text": "It seems that the paragraph is cut off",
            "logprob": -12.152834296226501,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.7118327617645264
              },
              {
                "text": "seems",
                "logprob": -0.5640558004379272
              },
              {
                "text": "that",
                "logprob": -0.8961892127990723
              },
              {
                "text": "the",
                "logprob": -0.1239047572016716
              },
              {
                "text": "paragraph",
                "logprob": -5.633334636688232
              },
              {
                "text": "is",
                "logprob": -1.2149814367294312
              },
              {
                "text": "cut",
                "logprob": -0.9968657493591309
              },
              {
                "text": "off",
                "logprob": -0.011669941246509552
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.519103950704448,
              "max_token_negative_log_likelihood": 5.633331775665283,
              "predictive_entropy": 0.21703502477612346,
              "shannon_entropy": 1.3234762577340007
            }
          },
          {
            "text": "Eleanor Wadsworth used",
            "logprob": -0.2980060912668634,
            "tokens": [
              {
                "text": "Ele",
                "logprob": -0.27433282136917114
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "W",
                "logprob": 0.0
              },
              {
                "text": "ad",
                "logprob": 0.0
              },
              {
                "text": "sw",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "orth",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.023673150688409805
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.037250755354763854,
              "max_token_negative_log_likelihood": 0.27433279156684875,
              "predictive_entropy": 0.028954253997653723,
              "shannon_entropy": 0.15267957919383823
            }
          },
          {
            "text": "Eleanor Wadsworth used",
            "logprob": -0.2980060912668634,
            "tokens": [
              {
                "text": "Ele",
                "logprob": -0.27433282136917114
              },
              {
                "text": "an",
                "logprob": 0.0
              },
              {
                "text": "or",
                "logprob": 0.0
              },
              {
                "text": "W",
                "logprob": 0.0
              },
              {
                "text": "ad",
                "logprob": 0.0
              },
              {
                "text": "sw",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "orth",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.023673150688409805
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.037250755354763854,
              "max_token_negative_log_likelihood": 0.27433279156684875,
              "predictive_entropy": 0.028954253997653723,
              "shannon_entropy": 0.15267957919383823
            }
          }
        ],
        "cached": false,
        "request_time": 0.9908063411712646,
        "request_datetime": 1755803185
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "William Leach used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id582"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nWilliam Leach used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "William Leach used to work in Char",
            "logprob": -1.6267364357698781,
            "tokens": [
              {
                "text": "William",
                "logprob": -0.6319658160209656
              },
              {
                "text": "Le",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ach",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "used",
                "logprob": -0.05179772526025772
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.222531374078244e-05
              },
              {
                "text": "in",
                "logprob": -6.41325386823155e-05
              },
              {
                "text": "Char",
                "logprob": -0.9428459405899048
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.20334205872952005,
              "max_token_negative_log_likelihood": 0.9428460001945496,
              "predictive_entropy": 0.09406049965399177,
              "shannon_entropy": 0.4426244074996859
            }
          },
          {
            "text": "William Leach used to work in Richmond",
            "logprob": -1.7829864357698781,
            "tokens": [
              {
                "text": "William",
                "logprob": -0.6319658160209656
              },
              {
                "text": "Le",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ach",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "used",
                "logprob": -0.05179772526025772
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.222531374078244e-05
              },
              {
                "text": "in",
                "logprob": -6.41325386823155e-05
              },
              {
                "text": "Richmond",
                "logprob": -1.0990959405899048
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.22287328637777826,
              "max_token_negative_log_likelihood": 1.0990958213806152,
              "predictive_entropy": 0.09392711563485534,
              "shannon_entropy": 0.4426244074996859
            }
          },
          {
            "text": "It seems you've left the information",
            "logprob": -10.921892527490854,
            "tokens": [
              {
                "text": "It",
                "logprob": -1.5069658756256104
              },
              {
                "text": "seems",
                "logprob": -0.6131899356842041
              },
              {
                "text": "you",
                "logprob": -3.369175434112549
              },
              {
                "text": "'",
                "logprob": -0.5397646427154541
              },
              {
                "text": "ve",
                "logprob": -0.054895732551813126
              },
              {
                "text": "left",
                "logprob": -3.306293249130249
              },
              {
                "text": "the",
                "logprob": -0.2874148190021515
              },
              {
                "text": "information",
                "logprob": -1.2441928386688232
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3652364616282284,
              "max_token_negative_log_likelihood": 3.3691749572753906,
              "predictive_entropy": 0.23048996599391103,
              "shannon_entropy": 1.072736842557788
            }
          },
          {
            "text": "William Leach used to work in Char",
            "logprob": -1.6267364357698781,
            "tokens": [
              {
                "text": "William",
                "logprob": -0.6319658160209656
              },
              {
                "text": "Le",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ach",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "used",
                "logprob": -0.05179772526025772
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -6.222531374078244e-05
              },
              {
                "text": "in",
                "logprob": -6.41325386823155e-05
              },
              {
                "text": "Char",
                "logprob": -0.9428459405899048
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.20334205872952005,
              "max_token_negative_log_likelihood": 0.9428460001945496,
              "predictive_entropy": 0.09406049965399177,
              "shannon_entropy": 0.4426244074996859
            }
          },
          {
            "text": "Assuming that the pattern here is to mention",
            "logprob": -15.712088704109192,
            "tokens": [
              {
                "text": "Assuming",
                "logprob": -6.350715637207031
              },
              {
                "text": "that",
                "logprob": -1.1871025562286377
              },
              {
                "text": "the",
                "logprob": -0.25323286652565
              },
              {
                "text": "pattern",
                "logprob": -1.0645837783813477
              },
              {
                "text": "here",
                "logprob": -2.1414434909820557
              },
              {
                "text": "is",
                "logprob": -0.3259882628917694
              },
              {
                "text": "to",
                "logprob": -2.266064405441284
              },
              {
                "text": "mention",
                "logprob": -2.122957706451416
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.9640104472637177,
              "max_token_negative_log_likelihood": 6.350710391998291,
              "predictive_entropy": 0.23912451160140336,
              "shannon_entropy": 1.9151863157749176
            }
          }
        ],
        "cached": false,
        "request_time": 0.9858443737030029,
        "request_datetime": 1755803185
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Joseph McLaughlin used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id999"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJoseph McLaughlin used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Joseph McLaughlin used to work",
            "logprob": -0.9267845984920129,
            "tokens": [
              {
                "text": "Joseph",
                "logprob": -0.8901832699775696
              },
              {
                "text": "Mc",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "L",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "augh",
                "logprob": 0.0
              },
              {
                "text": "lin",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "used",
                "logprob": -0.03652658686041832
              },
              {
                "text": "to",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "work",
                "logprob": -7.164221460698172e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.11584806427826955,
              "max_token_negative_log_likelihood": 0.8901832103729248,
              "predictive_entropy": 0.050097881030257696,
              "shannon_entropy": 0.25438774400330644
            }
          },
          {
            "text": "Based on the pattern of individuals and the",
            "logprob": -7.155251407501055,
            "tokens": [
              {
                "text": "Based",
                "logprob": -1.7964332103729248
              },
              {
                "text": "on",
                "logprob": -0.0003097769513260573
              },
              {
                "text": "the",
                "logprob": -0.009223234839737415
              },
              {
                "text": "pattern",
                "logprob": -0.40157705545425415
              },
              {
                "text": "of",
                "logprob": -0.9675019383430481
              },
              {
                "text": "individuals",
                "logprob": -1.986541986465454
              },
              {
                "text": "and",
                "logprob": -0.484527051448822
              },
              {
                "text": "the",
                "logprob": -1.5091371536254883
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.894406420935411,
              "max_token_negative_log_likelihood": 1.9865418672561646,
              "predictive_entropy": 0.23106570524396375,
              "shannon_entropy": 1.2039064568234608
            }
          },
          {
            "text": "Unfortunately, the information about where Joseph Mc",
            "logprob": -7.17342590726895,
            "tokens": [
              {
                "text": "Unfortunately",
                "logprob": -4.265183448791504
              },
              {
                "text": ",",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "the",
                "logprob": -0.06514803320169449
              },
              {
                "text": "information",
                "logprob": -0.477914959192276
              },
              {
                "text": "about",
                "logprob": -1.285996913909912
              },
              {
                "text": "where",
                "logprob": -1.0642123222351074
              },
              {
                "text": "Joseph",
                "logprob": -0.014969633892178535
              },
              {
                "text": "Mc",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8966781325871338,
              "max_token_negative_log_likelihood": 4.2651824951171875,
              "predictive_entropy": 0.1443278467049609,
              "shannon_entropy": 0.7345548529446688
            }
          },
          {
            "text": "Joseph McLaughlin used to work",
            "logprob": -0.9267845984920129,
            "tokens": [
              {
                "text": "Joseph",
                "logprob": -0.8901832699775696
              },
              {
                "text": "Mc",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "L",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "augh",
                "logprob": 0.0
              },
              {
                "text": "lin",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "used",
                "logprob": -0.03652658686041832
              },
              {
                "text": "to",
                "logprob": -7.152555099310121e-07
              },
              {
                "text": "work",
                "logprob": -7.164221460698172e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.11584806427826955,
              "max_token_negative_log_likelihood": 0.8901832103729248,
              "predictive_entropy": 0.050097881030257696,
              "shannon_entropy": 0.25438774400330644
            }
          },
          {
            "text": "Based on the format and context provided,",
            "logprob": -9.234661543247057,
            "tokens": [
              {
                "text": "Based",
                "logprob": -1.7964332103729248
              },
              {
                "text": "on",
                "logprob": -0.0003097769513260573
              },
              {
                "text": "the",
                "logprob": -0.009223234839737415
              },
              {
                "text": "format",
                "logprob": -3.8703269958496094
              },
              {
                "text": "and",
                "logprob": -1.3169164657592773
              },
              {
                "text": "context",
                "logprob": -1.7078444957733154
              },
              {
                "text": "provided",
                "logprob": -0.30029091238975525
              },
              {
                "text": ",",
                "logprob": -0.23331645131111145
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1543326133978553,
              "max_token_negative_log_likelihood": 3.870326519012451,
              "predictive_entropy": 0.1822198357549496,
              "shannon_entropy": 1.0867061343742535
            }
          }
        ],
        "cached": false,
        "request_time": 0.9831364154815674,
        "request_datetime": 1755803185
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Joseph Jekyll used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id606"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJoseph Jekyll used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "It seems that the paragraph gets cut off",
            "logprob": -15.741680053062737,
            "tokens": [
              {
                "text": "It",
                "logprob": -1.940377116203308
              },
              {
                "text": "seems",
                "logprob": -0.705179750919342
              },
              {
                "text": "that",
                "logprob": -0.9050484895706177
              },
              {
                "text": "the",
                "logprob": -0.11592131853103638
              },
              {
                "text": "paragraph",
                "logprob": -5.937018394470215
              },
              {
                "text": "gets",
                "logprob": -6.085023880004883
              },
              {
                "text": "cut",
                "logprob": -0.043876294046640396
              },
              {
                "text": "off",
                "logprob": -0.009234809316694736
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.9677089779870585,
              "max_token_negative_log_likelihood": 6.085019588470459,
              "predictive_entropy": 0.14714031293988228,
              "shannon_entropy": 1.102391387335956
            }
          },
          {
            "text": "Joseph Jekyll used to work in",
            "logprob": -0.7513785057744187,
            "tokens": [
              {
                "text": "Joseph",
                "logprob": -0.5966271162033081
              },
              {
                "text": "J",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ek",
                "logprob": 0.0
              },
              {
                "text": "yll",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.15442025661468506
              },
              {
                "text": "to",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "work",
                "logprob": -0.00010954733443213627
              },
              {
                "text": "in",
                "logprob": -0.00022110878489911556
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09392231152106412,
              "max_token_negative_log_likelihood": 0.5966271162033081,
              "predictive_entropy": 0.05764972224368492,
              "shannon_entropy": 0.27527522840009966
            }
          },
          {
            "text": "Joseph Jekyll appears to be cut",
            "logprob": -7.093822462484233,
            "tokens": [
              {
                "text": "Joseph",
                "logprob": -0.5966271162033081
              },
              {
                "text": "J",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ek",
                "logprob": 0.0
              },
              {
                "text": "yll",
                "logprob": 0.0
              },
              {
                "text": "appears",
                "logprob": -4.216920375823975
              },
              {
                "text": "to",
                "logprob": -0.0021074246615171432
              },
              {
                "text": "be",
                "logprob": -0.3127172589302063
              },
              {
                "text": "cut",
                "logprob": -1.9654501676559448
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8867276402597799,
              "max_token_negative_log_likelihood": 4.216919422149658,
              "predictive_entropy": 0.112113000737736,
              "shannon_entropy": 0.5953366878430677
            }
          },
          {
            "text": "It appears as though the information about Joseph",
            "logprob": -9.697979032993317,
            "tokens": [
              {
                "text": "It",
                "logprob": -1.940377116203308
              },
              {
                "text": "appears",
                "logprob": -0.705179750919342
              },
              {
                "text": "as",
                "logprob": -5.0017290115356445
              },
              {
                "text": "though",
                "logprob": -0.19037573039531708
              },
              {
                "text": "the",
                "logprob": -0.07771766185760498
              },
              {
                "text": "information",
                "logprob": -0.8012141585350037
              },
              {
                "text": "about",
                "logprob": -0.7935594916343689
              },
              {
                "text": "Joseph",
                "logprob": -0.18782611191272736
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.2122471891343594,
              "max_token_negative_log_likelihood": 5.00172758102417,
              "predictive_entropy": 0.22051729867234826,
              "shannon_entropy": 0.9724491648375988
            }
          },
          {
            "text": "To complete the sentence regarding Joseph Jek",
            "logprob": -6.770474918186665,
            "tokens": [
              {
                "text": "To",
                "logprob": -3.5966272354125977
              },
              {
                "text": "complete",
                "logprob": -0.07456165552139282
              },
              {
                "text": "the",
                "logprob": -0.03857169300317764
              },
              {
                "text": "sentence",
                "logprob": -0.7028533816337585
              },
              {
                "text": "regarding",
                "logprob": -2.2871973514556885
              },
              {
                "text": "Joseph",
                "logprob": -0.07066360116004944
              },
              {
                "text": "J",
                "logprob": 0.0
              },
              {
                "text": "ek",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8463093065656722,
              "max_token_negative_log_likelihood": 3.5966267585754395,
              "predictive_entropy": 0.10638289339840412,
              "shannon_entropy": 0.6964067655883337
            }
          }
        ],
        "cached": false,
        "request_time": 0.9861695766448975,
        "request_datetime": 1755803185
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Agnieszka Fryckowska used to work in"
        },
        "references": [
          {
            "output": {
              "text": "British Antarctic Survey"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "BAS"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id127"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nAgnieszka Fryckowska used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Agnieszka Fryckow",
            "logprob": -0.13959056138958204,
            "tokens": [
              {
                "text": "Ag",
                "logprob": -0.13958972692489624
              },
              {
                "text": "n",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "iesz",
                "logprob": 0.0
              },
              {
                "text": "ka",
                "logprob": 0.0
              },
              {
                "text": "F",
                "logprob": 0.0
              },
              {
                "text": "ry",
                "logprob": 0.0
              },
              {
                "text": "ck",
                "logprob": 0.0
              },
              {
                "text": "ow",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01744882203642817,
              "max_token_negative_log_likelihood": 0.13958974182605743,
              "predictive_entropy": 0.015175515785770699,
              "shannon_entropy": 0.08221291651777507
            }
          },
          {
            "text": "Agnieszka Fryckow",
            "logprob": -0.13959056138958204,
            "tokens": [
              {
                "text": "Ag",
                "logprob": -0.13958972692489624
              },
              {
                "text": "n",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "iesz",
                "logprob": 0.0
              },
              {
                "text": "ka",
                "logprob": 0.0
              },
              {
                "text": "F",
                "logprob": 0.0
              },
              {
                "text": "ry",
                "logprob": 0.0
              },
              {
                "text": "ck",
                "logprob": 0.0
              },
              {
                "text": "ow",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01744882203642817,
              "max_token_negative_log_likelihood": 0.13958974182605743,
              "predictive_entropy": 0.015175515785770699,
              "shannon_entropy": 0.08221291651777507
            }
          },
          {
            "text": "Agnieszka Fryckow",
            "logprob": -0.13959056138958204,
            "tokens": [
              {
                "text": "Ag",
                "logprob": -0.13958972692489624
              },
              {
                "text": "n",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "iesz",
                "logprob": 0.0
              },
              {
                "text": "ka",
                "logprob": 0.0
              },
              {
                "text": "F",
                "logprob": 0.0
              },
              {
                "text": "ry",
                "logprob": 0.0
              },
              {
                "text": "ck",
                "logprob": 0.0
              },
              {
                "text": "ow",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01744882203642817,
              "max_token_negative_log_likelihood": 0.13958974182605743,
              "predictive_entropy": 0.015175515785770699,
              "shannon_entropy": 0.08221291651777507
            }
          },
          {
            "text": "Agnieszka Fryckow",
            "logprob": -0.13959056138958204,
            "tokens": [
              {
                "text": "Ag",
                "logprob": -0.13958972692489624
              },
              {
                "text": "n",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "iesz",
                "logprob": 0.0
              },
              {
                "text": "ka",
                "logprob": 0.0
              },
              {
                "text": "F",
                "logprob": 0.0
              },
              {
                "text": "ry",
                "logprob": 0.0
              },
              {
                "text": "ck",
                "logprob": 0.0
              },
              {
                "text": "ow",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.01744882203642817,
              "max_token_negative_log_likelihood": 0.13958974182605743,
              "predictive_entropy": 0.015175515785770699,
              "shannon_entropy": 0.08221291651777507
            }
          },
          {
            "text": "Henry St. John, known for his",
            "logprob": -8.147023711353306,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -4.639589786529541
              },
              {
                "text": "St",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": ".",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "John",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ",",
                "logprob": -0.19553714990615845
              },
              {
                "text": "known",
                "logprob": -1.945068597793579
              },
              {
                "text": "for",
                "logprob": -1.3328195810317993
              },
              {
                "text": "his",
                "logprob": -0.03400752320885658
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.0183778107166592,
              "max_token_negative_log_likelihood": 4.639588832855225,
              "predictive_entropy": 0.10851435689252398,
              "shannon_entropy": 0.7441304734640397
            }
          }
        ],
        "cached": false,
        "request_time": 1.0111191272735596,
        "request_datetime": 1755803186
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Constantine B. Kilgore used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Washington, D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "DC"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington D.C."
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The District"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington, District of Columbia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washington"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Washingtonian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id420"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nConstantine B. Kilgore used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Constantine B. Kilgore used",
            "logprob": -0.5436307936782043,
            "tokens": [
              {
                "text": "Const",
                "logprob": -0.437571257352829
              },
              {
                "text": "antine",
                "logprob": 0.0
              },
              {
                "text": "B",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": ".",
                "logprob": -4.887569048150908e-06
              },
              {
                "text": "Kil",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "g",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ore",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10605297982692719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0679538501442174,
              "max_token_negative_log_likelihood": 0.437571257352829,
              "predictive_entropy": 0.047235660253335254,
              "shannon_entropy": 0.2294153939240502
            }
          },
          {
            "text": "Henry St. John, who could be",
            "logprob": -10.538054123520816,
            "tokens": [
              {
                "text": "Henry",
                "logprob": -2.2188212871551514
              },
              {
                "text": "St",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": ".",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "John",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -0.20273162424564362
              },
              {
                "text": "who",
                "logprob": -2.4028494358062744
              },
              {
                "text": "could",
                "logprob": -4.697850227355957
              },
              {
                "text": "be",
                "logprob": -1.015801191329956
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3172566480934673,
              "max_token_negative_log_likelihood": 4.697849273681641,
              "predictive_entropy": 0.1293517686426604,
              "shannon_entropy": 1.118400347805732
            }
          },
          {
            "text": "Constantine B. Kilgore used",
            "logprob": -0.5436307936782043,
            "tokens": [
              {
                "text": "Const",
                "logprob": -0.437571257352829
              },
              {
                "text": "antine",
                "logprob": 0.0
              },
              {
                "text": "B",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": ".",
                "logprob": -4.887569048150908e-06
              },
              {
                "text": "Kil",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "g",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ore",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10605297982692719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0679538501442174,
              "max_token_negative_log_likelihood": 0.437571257352829,
              "predictive_entropy": 0.047235660253335254,
              "shannon_entropy": 0.2294153939240502
            }
          },
          {
            "text": "Constantine B. Kilgore,",
            "logprob": -3.856130689370076,
            "tokens": [
              {
                "text": "Const",
                "logprob": -0.437571257352829
              },
              {
                "text": "antine",
                "logprob": 0.0
              },
              {
                "text": "B",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": ".",
                "logprob": -4.887569048150908e-06
              },
              {
                "text": "Kil",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "g",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ore",
                "logprob": 0.0
              },
              {
                "text": ",",
                "logprob": -3.418552875518799
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4820163063720564,
              "max_token_negative_log_likelihood": 3.4185526371002197,
              "predictive_entropy": 0.04931184742437722,
              "shannon_entropy": 0.2294153939240502
            }
          },
          {
            "text": "Constantine B. Kilgore used",
            "logprob": -0.5436307936782043,
            "tokens": [
              {
                "text": "Const",
                "logprob": -0.437571257352829
              },
              {
                "text": "antine",
                "logprob": 0.0
              },
              {
                "text": "B",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": ".",
                "logprob": -4.887569048150908e-06
              },
              {
                "text": "Kil",
                "logprob": -1.0728830375228426e-06
              },
              {
                "text": "g",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ore",
                "logprob": 0.0
              },
              {
                "text": "used",
                "logprob": -0.10605297982692719
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0679538501442174,
              "max_token_negative_log_likelihood": 0.437571257352829,
              "predictive_entropy": 0.047235660253335254,
              "shannon_entropy": 0.2294153939240502
            }
          }
        ],
        "cached": false,
        "request_time": 1.0177664756774902,
        "request_datetime": 1755803186
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Ann Arleklo used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Stockholm"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sthlm"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "STHLM"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Stockholm, Sweden"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id130"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nAnn Arleklo used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "The sentence fragment about Ann Arleklo",
            "logprob": -10.97316463551806,
            "tokens": [
              {
                "text": "The",
                "logprob": -3.5413694381713867
              },
              {
                "text": "sentence",
                "logprob": -2.0235605239868164
              },
              {
                "text": "fragment",
                "logprob": -3.366856336593628
              },
              {
                "text": "about",
                "logprob": -2.0253257751464844
              },
              {
                "text": "Ann",
                "logprob": -0.015493622981011868
              },
              {
                "text": "Ar",
                "logprob": -5.960446742392378e-06
              },
              {
                "text": "lek",
                "logprob": -0.0005529781919904053
              },
              {
                "text": "lo",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3716454947302168,
              "max_token_negative_log_likelihood": 3.5413691997528076,
              "predictive_entropy": 0.09616194966434932,
              "shannon_entropy": 0.9560379856240502
            }
          },
          {
            "text": "Ann Arleklo appears to be a",
            "logprob": -2.283527529827552,
            "tokens": [
              {
                "text": "Ann",
                "logprob": -0.7288694977760315
              },
              {
                "text": "Ar",
                "logprob": -2.95634672511369e-05
              },
              {
                "text": "lek",
                "logprob": -0.210064098238945
              },
              {
                "text": "lo",
                "logprob": 0.0
              },
              {
                "text": "appears",
                "logprob": -0.9377189874649048
              },
              {
                "text": "to",
                "logprob": -0.0014287750236690044
              },
              {
                "text": "be",
                "logprob": -0.13096708059310913
              },
              {
                "text": "a",
                "logprob": -0.27444952726364136
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.2854409394749382,
              "max_token_negative_log_likelihood": 0.9377189874649048,
              "predictive_entropy": 0.1517463932575538,
              "shannon_entropy": 0.5737615946310086
            }
          },
          {
            "text": "To complete the sentence about Ann Arlek",
            "logprob": -6.724282577077247,
            "tokens": [
              {
                "text": "To",
                "logprob": -5.072619438171387
              },
              {
                "text": "complete",
                "logprob": -0.07665617018938065
              },
              {
                "text": "the",
                "logprob": -0.030077721923589706
              },
              {
                "text": "sentence",
                "logprob": -0.7100052237510681
              },
              {
                "text": "about",
                "logprob": -0.8298169374465942
              },
              {
                "text": "Ann",
                "logprob": -0.0013172292383387685
              },
              {
                "text": "Ar",
                "logprob": -2.9682672902708873e-05
              },
              {
                "text": "lek",
                "logprob": -0.0037601736839860678
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8405351455844539,
              "max_token_negative_log_likelihood": 5.072618007659912,
              "predictive_entropy": 0.10600472157557306,
              "shannon_entropy": 0.6168632631452056
            }
          },
          {
            "text": "It appears that the last statement is incomplete",
            "logprob": -5.394102081656456,
            "tokens": [
              {
                "text": "It",
                "logprob": -0.9163694977760315
              },
              {
                "text": "appears",
                "logprob": -0.7346140742301941
              },
              {
                "text": "that",
                "logprob": -0.26130399107933044
              },
              {
                "text": "the",
                "logprob": -0.2764178216457367
              },
              {
                "text": "last",
                "logprob": -1.0522280931472778
              },
              {
                "text": "statement",
                "logprob": -1.3112789392471313
              },
              {
                "text": "is",
                "logprob": -0.6991543173789978
              },
              {
                "text": "incomplete",
                "logprob": -0.1427353471517563
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6742627546191216,
              "max_token_negative_log_likelihood": 1.3112789392471313,
              "predictive_entropy": 0.2902211397886276,
              "shannon_entropy": 1.1649694591760635
            }
          },
          {
            "text": "It seems like your input has been cut",
            "logprob": -9.54203286767006,
            "tokens": [
              {
                "text": "It",
                "logprob": -0.9163694977760315
              },
              {
                "text": "seems",
                "logprob": -0.6721140742301941
              },
              {
                "text": "like",
                "logprob": -0.9049538969993591
              },
              {
                "text": "your",
                "logprob": -2.6063249111175537
              },
              {
                "text": "input",
                "logprob": -1.6411082744598389
              },
              {
                "text": "has",
                "logprob": -2.5490670204162598
              },
              {
                "text": "been",
                "logprob": -0.22032204270362854
              },
              {
                "text": "cut",
                "logprob": -0.031773149967193604
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1927541051991284,
              "max_token_negative_log_likelihood": 2.6063249111175537,
              "predictive_entropy": 0.24911677977070212,
              "shannon_entropy": 1.162057489156723
            }
          }
        ],
        "cached": false,
        "request_time": 1.0149672031402588,
        "request_datetime": 1755803186
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Arnold Gehlen used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Aachen"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Oche"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Aix-la-Chapelle"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Aix la Chapelle"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Leipzig"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id518"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nArnold Gehlen used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Arnold Gehlen used to work in C",
            "logprob": -0.9029727713928537,
            "tokens": [
              {
                "text": "Arnold",
                "logprob": -0.014758693054318428
              },
              {
                "text": "Ge",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "hlen",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "used",
                "logprob": -0.3700065612792969
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00010406429646536708
              },
              {
                "text": "in",
                "logprob": -0.0002348147245356813
              },
              {
                "text": "C",
                "logprob": -0.5178674459457397
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.11287160071156421,
              "max_token_negative_log_likelihood": 0.5178674459457397,
              "predictive_entropy": 0.07237464650365055,
              "shannon_entropy": 0.3256716169232732
            }
          },
          {
            "text": "Arnold Gehlen used to work in C",
            "logprob": -0.9029727713928537,
            "tokens": [
              {
                "text": "Arnold",
                "logprob": -0.014758693054318428
              },
              {
                "text": "Ge",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "hlen",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "used",
                "logprob": -0.3700065612792969
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00010406429646536708
              },
              {
                "text": "in",
                "logprob": -0.0002348147245356813
              },
              {
                "text": "C",
                "logprob": -0.5178674459457397
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.11287160071156421,
              "max_token_negative_log_likelihood": 0.5178674459457397,
              "predictive_entropy": 0.07237464650365055,
              "shannon_entropy": 0.3256716169232732
            }
          },
          {
            "text": "Arnold Gehlen was a German social anth",
            "logprob": -3.568554848432143,
            "tokens": [
              {
                "text": "Arnold",
                "logprob": -0.014758693054318428
              },
              {
                "text": "Ge",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "hlen",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "was",
                "logprob": -3.026256561279297
              },
              {
                "text": "a",
                "logprob": -0.012950951233506203
              },
              {
                "text": "German",
                "logprob": -0.0420316644012928
              },
              {
                "text": "social",
                "logprob": -0.13584169745445251
              },
              {
                "text": "anth",
                "logprob": -0.33671408891677856
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.4460693546571335,
              "max_token_negative_log_likelihood": 3.026256561279297,
              "predictive_entropy": 0.07167907152319586,
              "shannon_entropy": 0.34696286505328544
            }
          },
          {
            "text": "Arnold Gehlen was a German sociologist",
            "logprob": -6.5778159755278125,
            "tokens": [
              {
                "text": "Arnold",
                "logprob": -0.014758693054318428
              },
              {
                "text": "Ge",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "hlen",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "was",
                "logprob": -3.026256561279297
              },
              {
                "text": "a",
                "logprob": -0.012950951233506203
              },
              {
                "text": "German",
                "logprob": -0.0420316644012928
              },
              {
                "text": "soci",
                "logprob": -3.4795916080474854
              },
              {
                "text": "ologist",
                "logprob": -0.0022253054194152355
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.8222269719117818,
              "max_token_negative_log_likelihood": 3.4795913696289062,
              "predictive_entropy": 0.04048185530695392,
              "shannon_entropy": 0.23424847501570412
            }
          },
          {
            "text": "Arnold Gehlen used to work in Germany",
            "logprob": -2.2779727713928537,
            "tokens": [
              {
                "text": "Arnold",
                "logprob": -0.014758693054318428
              },
              {
                "text": "Ge",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "hlen",
                "logprob": -3.576278118089249e-07
              },
              {
                "text": "used",
                "logprob": -0.3700065612792969
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00010406429646536708
              },
              {
                "text": "in",
                "logprob": -0.0002348147245356813
              },
              {
                "text": "Germany",
                "logprob": -1.8928674459457397
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.284746585810403,
              "max_token_negative_log_likelihood": 1.8928673267364502,
              "predictive_entropy": 0.06944964541884602,
              "shannon_entropy": 0.3256716169232732
            }
          }
        ],
        "cached": false,
        "request_time": 1.0107781887054443,
        "request_datetime": 1755803186
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Arthur Cowell-Stepney used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id552"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nArthur Cowell-Stepney used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "It appears that the list of individuals and",
            "logprob": -8.823591388761997,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.403761386871338
              },
              {
                "text": "appears",
                "logprob": -0.7322468757629395
              },
              {
                "text": "that",
                "logprob": -0.15297631919384003
              },
              {
                "text": "the",
                "logprob": -0.1372034251689911
              },
              {
                "text": "list",
                "logprob": -4.189713478088379
              },
              {
                "text": "of",
                "logprob": -0.8658196926116943
              },
              {
                "text": "individuals",
                "logprob": -0.11304169148206711
              },
              {
                "text": "and",
                "logprob": -0.2288285195827484
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1029488006606698,
              "max_token_negative_log_likelihood": 4.1897125244140625,
              "predictive_entropy": 0.19136705622076988,
              "shannon_entropy": 0.9821197092533112
            }
          },
          {
            "text": "Victor Leemans's work location",
            "logprob": -13.08437377181496,
            "tokens": [
              {
                "text": "Victor",
                "logprob": -6.091261386871338
              },
              {
                "text": "Le",
                "logprob": -2.5629668016335927e-05
              },
              {
                "text": "em",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ans",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "'",
                "logprob": -4.00529670715332
              },
              {
                "text": "s",
                "logprob": -0.555718719959259
              },
              {
                "text": "work",
                "logprob": -1.2835979461669922
              },
              {
                "text": "location",
                "logprob": -1.148472785949707
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.635546118062182,
              "max_token_negative_log_likelihood": 6.091257095336914,
              "predictive_entropy": 0.1406730450280378,
              "shannon_entropy": 1.0469313959210353
            }
          },
          {
            "text": "Arthur Cowell-Stepney used to",
            "logprob": -0.29941445588886495,
            "tokens": [
              {
                "text": "Arthur",
                "logprob": -0.21626147627830505
              },
              {
                "text": "Cow",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ell",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "-",
                "logprob": 0.0
              },
              {
                "text": "Step",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "ney",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.08314916491508484
              },
              {
                "text": "to",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03742680605524029,
              "max_token_negative_log_likelihood": 0.21626147627830505,
              "predictive_entropy": 0.03134034667141705,
              "shannon_entropy": 0.15073597497542846
            }
          },
          {
            "text": "It seems that the information about Arthur Cow",
            "logprob": -5.357300890609622,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.403761386871338
              },
              {
                "text": "seems",
                "logprob": -0.6697468757629395
              },
              {
                "text": "that",
                "logprob": -0.9228804111480713
              },
              {
                "text": "the",
                "logprob": -0.17488625645637512
              },
              {
                "text": "information",
                "logprob": -0.5251227617263794
              },
              {
                "text": "about",
                "logprob": -0.6342769861221313
              },
              {
                "text": "Arthur",
                "logprob": -0.026626212522387505
              },
              {
                "text": "Cow",
                "logprob": 0.0
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.6696625945623964,
              "max_token_negative_log_likelihood": 2.403761386871338,
              "predictive_entropy": 0.21831224206835032,
              "shannon_entropy": 0.8069778792859097
            }
          },
          {
            "text": "Arthur Cowell-Stepney used to",
            "logprob": -0.29941445588886495,
            "tokens": [
              {
                "text": "Arthur",
                "logprob": -0.21626147627830505
              },
              {
                "text": "Cow",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ell",
                "logprob": -8.344646857949556e-07
              },
              {
                "text": "-",
                "logprob": 0.0
              },
              {
                "text": "Step",
                "logprob": -1.4305104514278355e-06
              },
              {
                "text": "ney",
                "logprob": -5.960462772236497e-07
              },
              {
                "text": "used",
                "logprob": -0.08314916491508484
              },
              {
                "text": "to",
                "logprob": -7.152555099310121e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03742680605524029,
              "max_token_negative_log_likelihood": 0.21626147627830505,
              "predictive_entropy": 0.03134034667141705,
              "shannon_entropy": 0.15073597497542846
            }
          }
        ],
        "cached": false,
        "request_time": 1.0138919353485107,
        "request_datetime": 1755803187
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Dario Tamburrano used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Strasbourg"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Stra\u00dfburg"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Strassburg"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Schdroosburi"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Strossburi"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Strossburig"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Strosburi"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Strasburg"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Brussels"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Brussels City"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Brussels, Belgium"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bruxelles"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Brussel"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Stad Brussel"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Ville de Bruxelles"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "02"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "BXL"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Bru"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Brussels"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id944"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nDario Tamburrano used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Given the pattern in the information provided,",
            "logprob": -10.448176436126232,
            "tokens": [
              {
                "text": "Given",
                "logprob": -3.8880326747894287
              },
              {
                "text": "the",
                "logprob": -0.2552238404750824
              },
              {
                "text": "pattern",
                "logprob": -0.5198135375976562
              },
              {
                "text": "in",
                "logprob": -2.000429153442383
              },
              {
                "text": "the",
                "logprob": -0.05265749990940094
              },
              {
                "text": "information",
                "logprob": -3.4745824337005615
              },
              {
                "text": "provided",
                "logprob": -0.18141211569309235
              },
              {
                "text": ",",
                "logprob": -0.07602518051862717
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.3060219609178603,
              "max_token_negative_log_likelihood": 3.8880321979522705,
              "predictive_entropy": 0.15455578174442053,
              "shannon_entropy": 1.0212375670671463
            }
          },
          {
            "text": "Dario Tamburrano used to work",
            "logprob": -0.4827596201275455,
            "tokens": [
              {
                "text": "D",
                "logprob": -0.32553261518478394
              },
              {
                "text": "ario",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Tamb",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "ur",
                "logprob": 0.0
              },
              {
                "text": "rano",
                "logprob": -1.0013530300057027e-05
              },
              {
                "text": "used",
                "logprob": -0.1570175737142563
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.0001971527235582471
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.060344946211563055,
              "max_token_negative_log_likelihood": 0.32553261518478394,
              "predictive_entropy": 0.04618644284607498,
              "shannon_entropy": 0.20969717631453477
            }
          },
          {
            "text": "Dario Tamburrano used to work",
            "logprob": -0.4827596201275455,
            "tokens": [
              {
                "text": "D",
                "logprob": -0.32553261518478394
              },
              {
                "text": "ario",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Tamb",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "ur",
                "logprob": 0.0
              },
              {
                "text": "rano",
                "logprob": -1.0013530300057027e-05
              },
              {
                "text": "used",
                "logprob": -0.1570175737142563
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.0001971527235582471
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.060344946211563055,
              "max_token_negative_log_likelihood": 0.32553261518478394,
              "predictive_entropy": 0.04618644284607498,
              "shannon_entropy": 0.20969717631453477
            }
          },
          {
            "text": "Dario Tamburrano used to work",
            "logprob": -0.4827596201275455,
            "tokens": [
              {
                "text": "D",
                "logprob": -0.32553261518478394
              },
              {
                "text": "ario",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Tamb",
                "logprob": -1.9073468138230965e-06
              },
              {
                "text": "ur",
                "logprob": 0.0
              },
              {
                "text": "rano",
                "logprob": -1.0013530300057027e-05
              },
              {
                "text": "used",
                "logprob": -0.1570175737142563
              },
              {
                "text": "to",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "work",
                "logprob": -0.0001971527235582471
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.060344946211563055,
              "max_token_negative_log_likelihood": 0.32553261518478394,
              "predictive_entropy": 0.04618644284607498,
              "shannon_entropy": 0.20969717631453477
            }
          },
          {
            "text": "It seems that your statement about Dario",
            "logprob": -8.933164803544052,
            "tokens": [
              {
                "text": "It",
                "logprob": -1.8880326747894287
              },
              {
                "text": "seems",
                "logprob": -0.6481377482414246
              },
              {
                "text": "that",
                "logprob": -0.8785184621810913
              },
              {
                "text": "your",
                "logprob": -3.0701239109039307
              },
              {
                "text": "statement",
                "logprob": -1.5577423572540283
              },
              {
                "text": "about",
                "logprob": -0.8876503705978394
              },
              {
                "text": "D",
                "logprob": -0.002959160367026925
              },
              {
                "text": "ario",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.1166455178172345,
              "max_token_negative_log_likelihood": 3.0701234340667725,
              "predictive_entropy": 0.22857733769342303,
              "shannon_entropy": 0.9889824492045989
            }
          }
        ],
        "cached": false,
        "request_time": 1.0135626792907715,
        "request_datetime": 1755803187
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Louis Eisenmann used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Love"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paris"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Gay Paree"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Lutetia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Paris, France"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "The City of Light"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Parisians"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Prague"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Praha"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Hlavn\u00ed m\u011bsto Praha"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Prague"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Praguer"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id969"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nLouis Eisenmann used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Louis Eisenmann used to work in Paris",
            "logprob": -0.7594771477232598,
            "tokens": [
              {
                "text": "Louis",
                "logprob": -0.02037009410560131
              },
              {
                "text": "Eisen",
                "logprob": 0.0
              },
              {
                "text": "mann",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "used",
                "logprob": -0.19191056489944458
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00016223068814724684
              },
              {
                "text": "in",
                "logprob": -0.00010561384988250211
              },
              {
                "text": "Paris",
                "logprob": -0.5469281673431396
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09493465397191869,
              "max_token_negative_log_likelihood": 0.5469282269477844,
              "predictive_entropy": 0.06189348221413127,
              "shannon_entropy": 0.3149248291360429
            }
          },
          {
            "text": "Louis Eisenmann used to work in Paris",
            "logprob": -0.7594771477232598,
            "tokens": [
              {
                "text": "Louis",
                "logprob": -0.02037009410560131
              },
              {
                "text": "Eisen",
                "logprob": 0.0
              },
              {
                "text": "mann",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "used",
                "logprob": -0.19191056489944458
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00016223068814724684
              },
              {
                "text": "in",
                "logprob": -0.00010561384988250211
              },
              {
                "text": "Paris",
                "logprob": -0.5469281673431396
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09493465397191869,
              "max_token_negative_log_likelihood": 0.5469282269477844,
              "predictive_entropy": 0.06189348221413127,
              "shannon_entropy": 0.3149248291360429
            }
          },
          {
            "text": "Louis Eisenmann used to work in Paris",
            "logprob": -0.7594771477232598,
            "tokens": [
              {
                "text": "Louis",
                "logprob": -0.02037009410560131
              },
              {
                "text": "Eisen",
                "logprob": 0.0
              },
              {
                "text": "mann",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "used",
                "logprob": -0.19191056489944458
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00016223068814724684
              },
              {
                "text": "in",
                "logprob": -0.00010561384988250211
              },
              {
                "text": "Paris",
                "logprob": -0.5469281673431396
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09493465397191869,
              "max_token_negative_log_likelihood": 0.5469282269477844,
              "predictive_entropy": 0.06189348221413127,
              "shannon_entropy": 0.3149248291360429
            }
          },
          {
            "text": "Louis Eisenmann used to work in Paris",
            "logprob": -0.7594771477232598,
            "tokens": [
              {
                "text": "Louis",
                "logprob": -0.02037009410560131
              },
              {
                "text": "Eisen",
                "logprob": 0.0
              },
              {
                "text": "mann",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "used",
                "logprob": -0.19191056489944458
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00016223068814724684
              },
              {
                "text": "in",
                "logprob": -0.00010561384988250211
              },
              {
                "text": "Paris",
                "logprob": -0.5469281673431396
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09493465397191869,
              "max_token_negative_log_likelihood": 0.5469282269477844,
              "predictive_entropy": 0.06189348221413127,
              "shannon_entropy": 0.3149248291360429
            }
          },
          {
            "text": "Louis Eisenmann used to work in Paris",
            "logprob": -0.7594771477232598,
            "tokens": [
              {
                "text": "Louis",
                "logprob": -0.02037009410560131
              },
              {
                "text": "Eisen",
                "logprob": 0.0
              },
              {
                "text": "mann",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "used",
                "logprob": -0.19191056489944458
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -0.00016223068814724684
              },
              {
                "text": "in",
                "logprob": -0.00010561384988250211
              },
              {
                "text": "Paris",
                "logprob": -0.5469281673431396
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.09493465397191869,
              "max_token_negative_log_likelihood": 0.5469282269477844,
              "predictive_entropy": 0.06189348221413127,
              "shannon_entropy": 0.3149248291360429
            }
          }
        ],
        "cached": false,
        "request_time": 1.00838041305542,
        "request_datetime": 1755803187
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Lazar'Khidekel used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Saint Petersburg"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "St. Petersburg"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Petrograd"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Leningrad"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Petersburg"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Sankt-Peterburg"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "St Petersburg"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "St Petersburger"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "SPb"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id887"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nLazar'Khidekel used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Lazar'Khidekel used to",
            "logprob": -0.7059742802690536,
            "tokens": [
              {
                "text": "Laz",
                "logprob": -0.117014080286026
              },
              {
                "text": "ar",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "'",
                "logprob": -0.0009386900928802788
              },
              {
                "text": "K",
                "logprob": -3.8265450712060556e-05
              },
              {
                "text": "hide",
                "logprob": -3.635817120084539e-05
              },
              {
                "text": "kel",
                "logprob": -0.00010501786891836673
              },
              {
                "text": "used",
                "logprob": -0.58784019947052
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08824679072647434,
              "max_token_negative_log_likelihood": 0.5878402590751648,
              "predictive_entropy": 0.05397150384155225,
              "shannon_entropy": 0.23440954134579783
            }
          },
          {
            "text": "Lazar'Khidekel, also",
            "logprob": -4.30572968664876,
            "tokens": [
              {
                "text": "Laz",
                "logprob": -0.117014080286026
              },
              {
                "text": "ar",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "'",
                "logprob": -0.0009386900928802788
              },
              {
                "text": "K",
                "logprob": -3.8265450712060556e-05
              },
              {
                "text": "hide",
                "logprob": -3.635817120084539e-05
              },
              {
                "text": "kel",
                "logprob": -0.00010501786891836673
              },
              {
                "text": ",",
                "logprob": -1.27534019947052
              },
              {
                "text": "also",
                "logprob": -2.9122555255889893
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.538216179271032,
              "max_token_negative_log_likelihood": 2.91225528717041,
              "predictive_entropy": 0.0774687016185851,
              "shannon_entropy": 0.5527423609380548
            }
          },
          {
            "text": "Lazar'Khidekel used to",
            "logprob": -0.7059742802690536,
            "tokens": [
              {
                "text": "Laz",
                "logprob": -0.117014080286026
              },
              {
                "text": "ar",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "'",
                "logprob": -0.0009386900928802788
              },
              {
                "text": "K",
                "logprob": -3.8265450712060556e-05
              },
              {
                "text": "hide",
                "logprob": -3.635817120084539e-05
              },
              {
                "text": "kel",
                "logprob": -0.00010501786891836673
              },
              {
                "text": "used",
                "logprob": -0.58784019947052
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.08824679072647434,
              "max_token_negative_log_likelihood": 0.5878402590751648,
              "predictive_entropy": 0.05397150384155225,
              "shannon_entropy": 0.23440954134579783
            }
          },
          {
            "text": "Lazar'Khidekel is a",
            "logprob": -4.597839116485034,
            "tokens": [
              {
                "text": "Laz",
                "logprob": -0.117014080286026
              },
              {
                "text": "ar",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "'",
                "logprob": -0.0009386900928802788
              },
              {
                "text": "K",
                "logprob": -3.8265450712060556e-05
              },
              {
                "text": "hide",
                "logprob": -3.635817120084539e-05
              },
              {
                "text": "kel",
                "logprob": -0.00010501786891836673
              },
              {
                "text": "is",
                "logprob": -3.8690900802612305
              },
              {
                "text": "a",
                "logprob": -0.610615074634552
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5747298207476632,
              "max_token_negative_log_likelihood": 3.8690896034240723,
              "predictive_entropy": 0.06469525860515546,
              "shannon_entropy": 0.45652161430166416
            }
          },
          {
            "text": "Lazar'Khidekel seems to",
            "logprob": -4.123460072458897,
            "tokens": [
              {
                "text": "Laz",
                "logprob": -0.117014080286026
              },
              {
                "text": "ar",
                "logprob": -1.5497195136049413e-06
              },
              {
                "text": "'",
                "logprob": -0.0009386900928802788
              },
              {
                "text": "K",
                "logprob": -3.8265450712060556e-05
              },
              {
                "text": "hide",
                "logprob": -3.635817120084539e-05
              },
              {
                "text": "kel",
                "logprob": -0.00010501786891836673
              },
              {
                "text": "seems",
                "logprob": -3.9628400802612305
              },
              {
                "text": "to",
                "logprob": -0.042486030608415604
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.5154324514202671,
              "max_token_negative_log_likelihood": 3.9628396034240723,
              "predictive_entropy": 0.02765751441833686,
              "shannon_entropy": 0.25732175524876766
            }
          }
        ],
        "cached": false,
        "request_time": 1.0082159042358398,
        "request_datetime": 1755803187
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Brent Follett used to work in"
        },
        "references": [
          {
            "output": {
              "text": "London"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, United Kingdom"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London, England"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Modern Babylon"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London UK"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "London U.K."
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id364"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nBrent Follett used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Brent Follett used to work in",
            "logprob": -0.28427236068452544,
            "tokens": [
              {
                "text": "Br",
                "logprob": -0.22409629821777344
              },
              {
                "text": "ent",
                "logprob": 0.0
              },
              {
                "text": "Fol",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "lett",
                "logprob": -2.682172998902388e-05
              },
              {
                "text": "used",
                "logprob": -0.05997198447585106
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.941560711013153e-05
              },
              {
                "text": "in",
                "logprob": -7.760223525110632e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03553404809509075,
              "max_token_negative_log_likelihood": 0.22409632802009583,
              "predictive_entropy": 0.02947393374824614,
              "shannon_entropy": 0.15488775368533325
            }
          },
          {
            "text": "Brent Follett used to work in",
            "logprob": -0.28427236068452544,
            "tokens": [
              {
                "text": "Br",
                "logprob": -0.22409629821777344
              },
              {
                "text": "ent",
                "logprob": 0.0
              },
              {
                "text": "Fol",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "lett",
                "logprob": -2.682172998902388e-05
              },
              {
                "text": "used",
                "logprob": -0.05997198447585106
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.941560711013153e-05
              },
              {
                "text": "in",
                "logprob": -7.760223525110632e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03553404809509075,
              "max_token_negative_log_likelihood": 0.22409632802009583,
              "predictive_entropy": 0.02947393374824614,
              "shannon_entropy": 0.15488775368533325
            }
          },
          {
            "text": "Brent Follett used to work in",
            "logprob": -0.28427236068452544,
            "tokens": [
              {
                "text": "Br",
                "logprob": -0.22409629821777344
              },
              {
                "text": "ent",
                "logprob": 0.0
              },
              {
                "text": "Fol",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "lett",
                "logprob": -2.682172998902388e-05
              },
              {
                "text": "used",
                "logprob": -0.05997198447585106
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.941560711013153e-05
              },
              {
                "text": "in",
                "logprob": -7.760223525110632e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03553404809509075,
              "max_token_negative_log_likelihood": 0.22409632802009583,
              "predictive_entropy": 0.02947393374824614,
              "shannon_entropy": 0.15488775368533325
            }
          },
          {
            "text": "Brent Follett used to work in",
            "logprob": -0.28427236068452544,
            "tokens": [
              {
                "text": "Br",
                "logprob": -0.22409629821777344
              },
              {
                "text": "ent",
                "logprob": 0.0
              },
              {
                "text": "Fol",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "lett",
                "logprob": -2.682172998902388e-05
              },
              {
                "text": "used",
                "logprob": -0.05997198447585106
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.941560711013153e-05
              },
              {
                "text": "in",
                "logprob": -7.760223525110632e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03553404809509075,
              "max_token_negative_log_likelihood": 0.22409632802009583,
              "predictive_entropy": 0.02947393374824614,
              "shannon_entropy": 0.15488775368533325
            }
          },
          {
            "text": "Brent Follett used to work in",
            "logprob": -0.28427236068452544,
            "tokens": [
              {
                "text": "Br",
                "logprob": -0.22409629821777344
              },
              {
                "text": "ent",
                "logprob": 0.0
              },
              {
                "text": "Fol",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "lett",
                "logprob": -2.682172998902388e-05
              },
              {
                "text": "used",
                "logprob": -0.05997198447585106
              },
              {
                "text": "to",
                "logprob": 0.0
              },
              {
                "text": "work",
                "logprob": -9.941560711013153e-05
              },
              {
                "text": "in",
                "logprob": -7.760223525110632e-05
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.03553404809509075,
              "max_token_negative_log_likelihood": 0.22409632802009583,
              "predictive_entropy": 0.02947393374824614,
              "shannon_entropy": 0.15488775368533325
            }
          }
        ],
        "cached": false,
        "request_time": 1.0107028484344482,
        "request_datetime": 1755803188
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Czes\u0142aw Bia\u0142obrzeski used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Krak\u00f3w"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Cracow"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Krakow"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Royal City of Krak\u00f3w"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Royal Capital City of Krak\u00f3w"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Krakau"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Kroke"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Cracovie"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Cracovia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Krakov"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Krakiv"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Krakk\u00f3"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Krakova"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Krako"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Krakoy"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Krakuv"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Cracovian"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Warsaw"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Warszawa"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Varshe"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Warschau"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Varshava"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Var\u0161ava"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Vars\u00f3"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Varsavia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Varsovie"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Varsovia"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Var\u0161uva"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Warsaw, Poland"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Warsaw"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id782"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nCzes\u0142aw Bia\u0142obrzeski used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Czes\u0142aw Bia\u0142obrzes",
            "logprob": -0.022849293419731964,
            "tokens": [
              {
                "text": "C",
                "logprob": -0.02284237928688526
              },
              {
                "text": "zes",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "\u0142aw",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "B",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ia\u0142",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "ob",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "r",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "zes",
                "logprob": -2.3841830625315197e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0028561640072890526,
              "max_token_negative_log_likelihood": 0.022842397913336754,
              "predictive_entropy": 0.0027916813261548157,
              "shannon_entropy": 0.018664176470721827
            }
          },
          {
            "text": "Czes\u0142aw Bia\u0142obrzes",
            "logprob": -0.022849293419731964,
            "tokens": [
              {
                "text": "C",
                "logprob": -0.02284237928688526
              },
              {
                "text": "zes",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "\u0142aw",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "B",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ia\u0142",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "ob",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "r",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "zes",
                "logprob": -2.3841830625315197e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0028561640072890526,
              "max_token_negative_log_likelihood": 0.022842397913336754,
              "predictive_entropy": 0.0027916813261548157,
              "shannon_entropy": 0.018664176470721827
            }
          },
          {
            "text": "Czes\u0142aw Bia\u0142obrzes",
            "logprob": -0.022849293419731964,
            "tokens": [
              {
                "text": "C",
                "logprob": -0.02284237928688526
              },
              {
                "text": "zes",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "\u0142aw",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "B",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ia\u0142",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "ob",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "r",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "zes",
                "logprob": -2.3841830625315197e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0028561640072890526,
              "max_token_negative_log_likelihood": 0.022842397913336754,
              "predictive_entropy": 0.0027916813261548157,
              "shannon_entropy": 0.018664176470721827
            }
          },
          {
            "text": "Czes\u0142aw Bia\u0142obrzes",
            "logprob": -0.022849293419731964,
            "tokens": [
              {
                "text": "C",
                "logprob": -0.02284237928688526
              },
              {
                "text": "zes",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "\u0142aw",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "B",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ia\u0142",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "ob",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "r",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "zes",
                "logprob": -2.3841830625315197e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0028561640072890526,
              "max_token_negative_log_likelihood": 0.022842397913336754,
              "predictive_entropy": 0.0027916813261548157,
              "shannon_entropy": 0.018664176470721827
            }
          },
          {
            "text": "Czes\u0142aw Bia\u0142obrzes",
            "logprob": -0.022849293419731964,
            "tokens": [
              {
                "text": "C",
                "logprob": -0.02284237928688526
              },
              {
                "text": "zes",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "\u0142aw",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "B",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ia\u0142",
                "logprob": -2.264974000354414e-06
              },
              {
                "text": "ob",
                "logprob": -9.536738616588991e-07
              },
              {
                "text": "r",
                "logprob": -4.768370445162873e-07
              },
              {
                "text": "zes",
                "logprob": -2.3841830625315197e-06
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.0028561640072890526,
              "max_token_negative_log_likelihood": 0.022842397913336754,
              "predictive_entropy": 0.0027916813261548157,
              "shannon_entropy": 0.018664176470721827
            }
          }
        ],
        "cached": false,
        "request_time": 0.9288263320922852,
        "request_datetime": 1755803188
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "F\u00e1tima Aburto Baselga used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Madrid"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Madrid"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Madrid, Spain"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Madrilenian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id832"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nF\u00e1tima Aburto Baselga used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "F\u00e1tima Aburto Basel",
            "logprob": -0.1712420701005115,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.17113395035266876
              },
              {
                "text": "\u00e1t",
                "logprob": -6.747018051100895e-05
              },
              {
                "text": "ima",
                "logprob": 0.0
              },
              {
                "text": "Ab",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ur",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Bas",
                "logprob": -4.005352093372494e-05
              },
              {
                "text": "el",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.021405255807176005,
              "max_token_negative_log_likelihood": 0.17113392055034637,
              "predictive_entropy": 0.018040520685641326,
              "shannon_entropy": 0.09029393957425214
            }
          },
          {
            "text": "F\u00e1tima Aburto Basel",
            "logprob": -0.1712420701005115,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.17113395035266876
              },
              {
                "text": "\u00e1t",
                "logprob": -6.747018051100895e-05
              },
              {
                "text": "ima",
                "logprob": 0.0
              },
              {
                "text": "Ab",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ur",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Bas",
                "logprob": -4.005352093372494e-05
              },
              {
                "text": "el",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.021405255807176005,
              "max_token_negative_log_likelihood": 0.17113392055034637,
              "predictive_entropy": 0.018040520685641326,
              "shannon_entropy": 0.09029393957425214
            }
          },
          {
            "text": "F\u00e1tima Aburto Basel",
            "logprob": -0.1712420701005115,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.17113395035266876
              },
              {
                "text": "\u00e1t",
                "logprob": -6.747018051100895e-05
              },
              {
                "text": "ima",
                "logprob": 0.0
              },
              {
                "text": "Ab",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ur",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Bas",
                "logprob": -4.005352093372494e-05
              },
              {
                "text": "el",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.021405255807176005,
              "max_token_negative_log_likelihood": 0.17113392055034637,
              "predictive_entropy": 0.018040520685641326,
              "shannon_entropy": 0.09029393957425214
            }
          },
          {
            "text": "F\u00e1tima Aburto Basel",
            "logprob": -0.1712420701005115,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.17113395035266876
              },
              {
                "text": "\u00e1t",
                "logprob": -6.747018051100895e-05
              },
              {
                "text": "ima",
                "logprob": 0.0
              },
              {
                "text": "Ab",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ur",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Bas",
                "logprob": -4.005352093372494e-05
              },
              {
                "text": "el",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.021405255807176005,
              "max_token_negative_log_likelihood": 0.17113392055034637,
              "predictive_entropy": 0.018040520685641326,
              "shannon_entropy": 0.09029393957425214
            }
          },
          {
            "text": "F\u00e1tima Aburto Basel",
            "logprob": -0.1712420701005115,
            "tokens": [
              {
                "text": "F",
                "logprob": -0.17113395035266876
              },
              {
                "text": "\u00e1t",
                "logprob": -6.747018051100895e-05
              },
              {
                "text": "ima",
                "logprob": 0.0
              },
              {
                "text": "Ab",
                "logprob": -2.3841855067985307e-07
              },
              {
                "text": "ur",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "to",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Bas",
                "logprob": -4.005352093372494e-05
              },
              {
                "text": "el",
                "logprob": -1.1920928244535389e-07
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.021405255807176005,
              "max_token_negative_log_likelihood": 0.17113392055034637,
              "predictive_entropy": 0.018040520685641326,
              "shannon_entropy": 0.09029393957425214
            }
          }
        ],
        "cached": false,
        "request_time": 0.9311079978942871,
        "request_datetime": 1755803188
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "Jos\u00e9 Manuel Romay Beccar\u00eda used to work in"
        },
        "references": [
          {
            "output": {
              "text": "Madrid"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "City of Madrid"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Madrid, Spain"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "Madrilenian"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "test",
        "id": "id446"
      },
      "train_trial_index": 0,
      "request": {
        "model_deployment": "huggingface/phi-3.5-mini-instruct",
        "model": "microsoft/phi-3.5-mini-instruct",
        "embedding": false,
        "prompt": "Henry St. John used to work in Washington, D.C.\n\nBernard Joly used to work in Paris\n\nSir John Owen, 1st Baronet used to work in London\n\nAlejandro Carabias Icaza used to work in Mexico City\n\nVictor Leemans used to work in Strasbourg\n\nJos\u00e9 Manuel Romay Beccar\u00eda used to work in",
        "temperature": 1.0,
        "num_completions": 5,
        "top_k_per_token": 1,
        "max_tokens": 8,
        "stop_sequences": [
          "\n"
        ],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "Jos\u00e9 Manuel Romay Beccar\u00eda used",
            "logprob": -0.28917953415019326,
            "tokens": [
              {
                "text": "Jos\u00e9",
                "logprob": -0.22152528166770935
              },
              {
                "text": "Manuel",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Rom",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ay",
                "logprob": 0.0
              },
              {
                "text": "Be",
                "logprob": -8.4638240878121e-06
              },
              {
                "text": "cc",
                "logprob": 0.0
              },
              {
                "text": "ar\u00eda",
                "logprob": -0.004889436531811953
              },
              {
                "text": "used",
                "logprob": -0.06275611370801926
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.036147445211899054,
              "max_token_negative_log_likelihood": 0.22152531147003174,
              "predictive_entropy": 0.030165046332513157,
              "shannon_entropy": 0.1559873249555861
            }
          },
          {
            "text": "Jos\u00e9 Manuel Romay Beccar\u00eda used",
            "logprob": -0.28917953415019326,
            "tokens": [
              {
                "text": "Jos\u00e9",
                "logprob": -0.22152528166770935
              },
              {
                "text": "Manuel",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Rom",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ay",
                "logprob": 0.0
              },
              {
                "text": "Be",
                "logprob": -8.4638240878121e-06
              },
              {
                "text": "cc",
                "logprob": 0.0
              },
              {
                "text": "ar\u00eda",
                "logprob": -0.004889436531811953
              },
              {
                "text": "used",
                "logprob": -0.06275611370801926
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.036147445211899054,
              "max_token_negative_log_likelihood": 0.22152531147003174,
              "predictive_entropy": 0.030165046332513157,
              "shannon_entropy": 0.1559873249555861
            }
          },
          {
            "text": "Jos\u00e9 Manuel Romay Beccar\u00eda used",
            "logprob": -0.28917953415019326,
            "tokens": [
              {
                "text": "Jos\u00e9",
                "logprob": -0.22152528166770935
              },
              {
                "text": "Manuel",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Rom",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ay",
                "logprob": 0.0
              },
              {
                "text": "Be",
                "logprob": -8.4638240878121e-06
              },
              {
                "text": "cc",
                "logprob": 0.0
              },
              {
                "text": "ar\u00eda",
                "logprob": -0.004889436531811953
              },
              {
                "text": "used",
                "logprob": -0.06275611370801926
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.036147445211899054,
              "max_token_negative_log_likelihood": 0.22152531147003174,
              "predictive_entropy": 0.030165046332513157,
              "shannon_entropy": 0.1559873249555861
            }
          },
          {
            "text": "Jos\u00e9 Manuel Romay Beccar\u00eda used",
            "logprob": -0.28917953415019326,
            "tokens": [
              {
                "text": "Jos\u00e9",
                "logprob": -0.22152528166770935
              },
              {
                "text": "Manuel",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "Rom",
                "logprob": -1.1920928244535389e-07
              },
              {
                "text": "ay",
                "logprob": 0.0
              },
              {
                "text": "Be",
                "logprob": -8.4638240878121e-06
              },
              {
                "text": "cc",
                "logprob": 0.0
              },
              {
                "text": "ar\u00eda",
                "logprob": -0.004889436531811953
              },
              {
                "text": "used",
                "logprob": -0.06275611370801926
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 0.036147445211899054,
              "max_token_negative_log_likelihood": 0.22152531147003174,
              "predictive_entropy": 0.030165046332513157,
              "shannon_entropy": 0.1559873249555861
            }
          },
          {
            "text": "It appears that the sentence is incomplete when",
            "logprob": -12.886099740862846,
            "tokens": [
              {
                "text": "It",
                "logprob": -2.409025192260742
              },
              {
                "text": "appears",
                "logprob": -0.806869387626648
              },
              {
                "text": "that",
                "logprob": -0.17727607488632202
              },
              {
                "text": "the",
                "logprob": -0.13775376975536346
              },
              {
                "text": "sentence",
                "logprob": -2.2954821586608887
              },
              {
                "text": "is",
                "logprob": -1.8801146745681763
              },
              {
                "text": "incomplete",
                "logprob": -0.5267044901847839
              },
              {
                "text": "when",
                "logprob": -4.652873992919922
              }
            ],
            "metrics": {
              "sequence_negative_log_likelihood": 1.6107623148709536,
              "max_token_negative_log_likelihood": 4.6528730392456055,
              "predictive_entropy": 0.2148242644034326,
              "shannon_entropy": 1.1602144166827202
            }
          }
        ],
        "cached": false,
        "request_time": 0.9275491237640381,
        "request_datetime": 1755803188
      },
      "num_train_instances": 5,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    }
  ]
}