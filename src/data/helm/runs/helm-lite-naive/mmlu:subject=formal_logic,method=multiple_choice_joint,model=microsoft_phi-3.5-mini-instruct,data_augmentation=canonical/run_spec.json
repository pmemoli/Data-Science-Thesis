{
  "name": "mmlu:subject=formal_logic,method=multiple_choice_joint,model=microsoft_phi-3.5-mini-instruct,data_augmentation=canonical",
  "scenario_spec": {
    "class_name": "helm.benchmark.scenarios.mmlu_scenario.MMLUScenario",
    "args": {
      "subject": "formal_logic"
    }
  },
  "adapter_spec": {
    "method": "multiple_choice_joint",
    "global_prefix": "",
    "global_suffix": "",
    "instructions": "The following are multiple choice questions (with answers) about formal logic.\n",
    "input_prefix": "Question: ",
    "input_suffix": "\n",
    "reference_prefix": "A. ",
    "reference_suffix": "\n",
    "chain_of_thought_prefix": "",
    "chain_of_thought_suffix": "\n",
    "output_prefix": "Answer: ",
    "output_suffix": "\n",
    "instance_prefix": "\n",
    "substitutions": [],
    "max_train_instances": 5,
    "max_eval_instances": 100,
    "num_outputs": 5,
    "num_train_trials": 1,
    "num_trials": 1,
    "sample_train": true,
    "model_deployment": "huggingface/phi-3.5-mini-instruct",
    "model": "microsoft/phi-3.5-mini-instruct",
    "temperature": 0.0,
    "max_tokens": 1,
    "stop_sequences": [
      "\n"
    ],
    "multi_label": false
  },
  "metric_specs": [
    {
      "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
      "args": {
        "names": [
          "exact_match",
          "quasi_exact_match",
          "prefix_exact_match",
          "quasi_prefix_exact_match"
        ]
      }
    },
    {
      "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
      "args": {}
    },
    {
      "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
      "args": {}
    }
  ],
  "data_augmenter_spec": {
    "perturbation_specs": [
      {
        "class_name": "helm.benchmark.augmentations.mild_mix_perturbation.MildMixPerturbation",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.augmentations.dialect_perturbation.DialectPerturbation",
        "args": {
          "prob": 1.0,
          "source_class": "SAE",
          "target_class": "AAVE",
          "mapping_file_path": null
        }
      },
      {
        "class_name": "helm.benchmark.augmentations.gender_perturbation.GenderPerturbation",
        "args": {
          "mode": "pronouns",
          "prob": 1.0,
          "source_class": "male",
          "target_class": "female",
          "mapping_file_path": null,
          "mapping_file_genders": null,
          "bidirectional": false
        }
      },
      {
        "class_name": "helm.benchmark.augmentations.person_name_perturbation.PersonNamePerturbation",
        "args": {
          "prob": 1.0,
          "source_class": {
            "race": "white_american"
          },
          "target_class": {
            "race": "black_american"
          },
          "name_file_path": null,
          "person_name_type": "first_name",
          "preserve_gender": true
        }
      }
    ],
    "should_augment_train_instances": false,
    "should_include_original_train": true,
    "should_skip_unchanged_train": true,
    "should_augment_eval_instances": true,
    "should_include_original_eval": true,
    "should_skip_unchanged_eval": true,
    "seeds_per_instance": 1
  },
  "groups": [
    "mmlu"
  ]
}