scenario,run,domain,benchmark,sequence_negative_log_likelihood,auroc_sequence_negative_log_likelihood,max_token_negative_log_likelihood,auroc_max_token_negative_log_likelihood,predictive_entropy,auroc_predictive_entropy,shannon_entropy,auroc_shannon_entropy,model
gsm,"gsm:model=microsoft_phi-3.5-mini-instruct,stop=none,max_train_instances=0",mathematical_reasoning,0.826666666666667,0.139459887354324,0.724255583126551,4.16639575401942,0.678349875930521,0.0429976737330252,0.693548387096774,0.137643363554768,0.720223325062035,microsoft_phi-3.5-mini-instruct
math,math (rather easy),mathematical_reasoning,0.86046511627907,0.159779321172,0.400900900900901,4.29734446281611,0.509009009009009,0.0457121366522392,0.400900900900901,0.15181168534913,0.387387387387387,microsoft_phi-3.5-mini-instruct
mmlu,"mmlu:subject=abstract_algebra,method=multiple_choice_joint,model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",knowledge_qa,0.594594594594595,0.451088126149029,0.625589225589226,7.20728321547981,0.565993265993266,0.0949360313643333,0.576094276094276,0.449047945631874,0.619191919191919,microsoft_phi-3.5-mini-instruct
mmlu,"mmlu:subject=college_chemistry,method=multiple_choice_joint,model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",knowledge_qa,0.546296296296296,0.469444370308237,0.548253199584919,6.74584673289899,0.567277758561052,0.0965289427265022,0.526807333102733,0.46661100946787,0.557938429609132,microsoft_phi-3.5-mini-instruct
mmlu,"mmlu:subject=computer_security,method=multiple_choice_joint,model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",knowledge_qa,0.747747747747748,0.619180970960951,0.573149741824441,6.79434656022905,0.407917383820998,0.122707205186116,0.538726333907057,0.626466468880529,0.623493975903614,microsoft_phi-3.5-mini-instruct
mmlu,"mmlu:subject=econometrics,method=multiple_choice_joint,model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",knowledge_qa,0.53968253968254,0.603627092864133,0.578346855983773,7.41196978470636,0.530679513184584,0.114944532831483,0.547667342799189,0.595326406665202,0.590770791075051,microsoft_phi-3.5-mini-instruct
mmlu,"mmlu:subject=us_foreign_policy,method=multiple_choice_joint,model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",knowledge_qa,0.783783783783784,0.63651280470184,0.593390804597701,7.00523950387766,0.580459770114943,0.118935295602076,0.563697318007663,0.633896527195458,0.602011494252874,microsoft_phi-3.5-mini-instruct
narrative_qa,"narrative_qa:model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",knowledge_qa,0.913333333333333,0.199290817577053,0.743402582818641,1.06949817793229,0.711959573273442,0.0521594578744167,0.765300393037619,0.188004837680858,0.773161145423919,microsoft_phi-3.5-mini-instruct
legalbench,"legalbench:subset=abercrombie,model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",specialized_domains,0.48421052631579,0.479057123328438,0.536379769299024,6.75954844073245,0.555456965394854,0.104641155117679,0.512422360248447,0.47347962311211,0.535048802129547,microsoft_phi-3.5-mini-instruct
legalbench,"legalbench:subset=corporate_lobbying,model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",specialized_domains,0.486666666666667,0.725466547478918,0.614481409001957,7.00311109781265,0.504358655043587,0.125649693474822,0.61679416473937,0.719893393084855,0.626578900551503,microsoft_phi-3.5-mini-instruct
legalbench,"legalbench:subset=function_of_decision_section,model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",specialized_domains,0.273333333333333,0.652778138276101,0.511747594540166,7.15176197528839,0.517117923472813,0.125023742918333,0.52539718057731,0.645720917346365,0.493846498098008,microsoft_phi-3.5-mini-instruct
legalbench,"legalbench:subset=international_citizenship_questions,model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",specialized_domains,0.486666666666667,0.756868688395793,0.606831524639744,7.6480202738444,0.590108521615371,0.129478375774814,0.657000533712862,0.756127821281469,0.636363636363636,microsoft_phi-3.5-mini-instruct
legalbench,"legalbench:subset=proa,model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",specialized_domains,0.873684210526316,0.594598175038153,0.632530120481928,6.80696411634746,0.330321285140562,0.117183652999337,0.649598393574297,0.58831592847357,0.608433734939759,microsoft_phi-3.5-mini-instruct
med_qa,"med_qa:model=microsoft_phi-3.5-mini-instruct,max_train_instances=0",specialized_domains,0.606666666666667,0.566464912002077,0.541255354814677,7.1728641351064,0.490221642764016,0.10978093902465,0.5356677221084,0.568951848546363,0.549823058297635,microsoft_phi-3.5-mini-instruct
